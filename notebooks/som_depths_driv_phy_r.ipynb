{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn_som.som import SOM\n",
    "import salishsea_tools.viz_tools as sa_vi\n",
    "from sklearn import preprocessing\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets_preparation(i):\n",
    "\n",
    "    ds_name = ('/results2/SalishSea/nowcast-green.202111/' + i + '/SalishSea_1d_' + '2022'+ str(dict_month[i[2:5]])+str(i[0:2]) + '_' + '2022'+ str(dict_month[i[2:5]]) + str(i[0:2]) + '_grid_T.nc')\n",
    "    \n",
    "    ds_bio_name = ('/results2/SalishSea/nowcast-green.202111/' + i + '/SalishSea_1d_' + '2022'+ str(dict_month[i[2:5]])+str(i[0:2]) + '_' + '2022'+ str(dict_month[i[2:5]]) + str(i[0:2]) + '_biol_T.nc')\n",
    "    \n",
    "    ds = xr.open_dataset (ds_name)\n",
    "    ds_bio = xr. open_dataset (ds_bio_name)\n",
    "\n",
    "    # Variable selection\n",
    "    temp = ds.votemper\n",
    "    saline = ds.vosaline\n",
    "    date = pd.DatetimeIndex(ds['time_counter'].values)\n",
    "\n",
    "    # Phytoplankton variables\n",
    "    flag = ds_bio.flagellates\n",
    "    diat = ds_bio.diatoms\n",
    "\n",
    "    # Open the mesh mask\n",
    "    mesh = xr.open_dataset('/home/sallen/MEOPAR/grid/mesh_mask202108.nc')\n",
    "    mask = mesh.tmask.to_numpy()\n",
    "    \n",
    "    return (ds, temp, saline, date, mask, flag, diat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking (depth, temp, saline, mask, flag, diat):\n",
    "\n",
    "    temp = temp.where(mask[0,depth]==1)\n",
    "    saline = saline.where(mask[0,depth]==1)\n",
    "\n",
    "    flag = flag.where(mask[0,depth]==1)\n",
    "    diat = diat.where(mask[0,depth]==1)\n",
    "\n",
    "    return (temp, saline, flag, diat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def som (depth, temp, saline):\n",
    "    \n",
    "    # Post processing \n",
    "    inputs = np.stack((temp[0,depth].values.flatten(), saline[0,depth].values.flatten()))\n",
    "    indx = np.argwhere(~np.isnan(inputs[0]) & ~np.isnan(inputs[1])) \n",
    "    inputs2 = inputs[:,indx[:,0]]\n",
    "    inputs3 = preprocessing.normalize(inputs2, norm= 'max')\n",
    "    inputs3 = inputs3.transpose()\n",
    "\n",
    "    # SOM\n",
    "    temp_som = SOM(m=3, n=2, dim= inputs3[0,:].size, lr = 0.1)\n",
    "    temp_som.fit(inputs3, epochs = 5)\n",
    "    predictions = temp_som.predict(inputs3)\n",
    "\n",
    "    # Post processing\n",
    "    unique, counts = np.unique(predictions, return_counts=True)\n",
    "    indx2 = np.full(inputs[0,:].size,np.nan)\n",
    "    indx2[indx[:,0]] = predictions\n",
    "    clusters = np.reshape(indx2,(898,398))   \n",
    "\n",
    "    return (unique, counts, inputs2.transpose(), predictions, clusters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printing (inputs, predictions, unique, counts):\n",
    "\n",
    "    # Preparation of the dataframe\n",
    "    d = {'temperature': inputs[:,0], 'salinity': inputs[:,1], 'cluster': predictions}\n",
    "    df = pd.DataFrame(d) \n",
    "\n",
    "    # Calculating the metrics\n",
    "    mean_temp = np.round(df.groupby('cluster')['temperature'].mean(), 2)\n",
    "    mean_sal = np.round(df.groupby('cluster')['salinity'].mean(), 2)\n",
    "    min_temp = np.round(df.groupby('cluster')['temperature'].min(), 2)\n",
    "    max_temp = np.round(df.groupby('cluster')['temperature'].max(), 2)\n",
    "    min_sal = np.round(df.groupby('cluster')['salinity'].min(), 2)\n",
    "    max_sal = np.round(df.groupby('cluster')['salinity'].max(), 2)\n",
    "\n",
    "    # Printing\n",
    "    lines = []\n",
    "    for i in unique:\n",
    "        lines.append(['The amount of grid boxes for cluster ' + str(i), ' is ' + str(counts[i]),'\\n'])\n",
    "\n",
    "        lines.append(['The minimum temperature for cluster '+ str(i), ' is ' + str(min_temp[i]), ' degrees Celsius'])\n",
    "        lines.append(['The maximum temperature for cluster '+ str(i), ' is ' + str(max_temp[i]), ' degrees Celsius'])\n",
    "        lines.append(['The mean temperature for cluster '+ str(i), ' is ' + str(mean_temp[i]), ' degrees Celsius', '\\n'])\n",
    "\n",
    "        lines.append(['The minimum salinity for cluster '+ str(i), ' is ' + str(min_sal[i]), ' g/kg'])\n",
    "        lines.append(['The maximum salinity for cluster '+ str(i), ' is ' + str(max_sal[i]), ' g/kg'])\n",
    "        lines.append(['The mean salinity for cluster '+ str(i), ' is ' + str(mean_sal[i]), ' g/kg', '\\n'*2])\n",
    "    \n",
    "    f = open(\"Statistics_\" + str(np.round(ds['deptht'][depth].values,2)) + 'm.txt', \"a\")\n",
    "    for line in lines:\n",
    "          f.writelines(line)\n",
    "          f.write('\\n')\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting (depth, clusters, unique, flag, diat):\n",
    "\n",
    "    # Preparation of the dataarray \n",
    "    map = xr.DataArray(clusters,\n",
    "                    coords = {'y': flag[0,depth].y, 'x': flag[0,depth].x},\n",
    "                    dims = ['y','x'],\n",
    "                    attrs=dict(description=\"Clusters of the performed self organizing map algorithm\",\n",
    "                                long_name =\"Cluster\",\n",
    "                                units=\"count\"),\n",
    "                    ) \n",
    "\n",
    "    cmap = plt.get_cmap('tab10', unique.max()+1)\n",
    "    cmap.set_bad('gray')\n",
    "    fig, ax = plt.subplots(2,2, figsize=(10, 15))\n",
    "    clus = map.plot.pcolormesh(ax=ax[0,0], cmap=cmap, vmin = unique.min(), vmax = unique.max()+1, add_colorbar=False)\n",
    "\n",
    "    cbar = fig.colorbar(clus, ticks = unique+0.5) \n",
    "    cbar.set_ticklabels(unique)\n",
    "    cbar.set_label('Clusters [count]')\n",
    "    \n",
    "    plt.subplots_adjust(left=0.1,\n",
    "        bottom=0.1, \n",
    "        right=0.9, \n",
    "        top=0.95, \n",
    "        wspace=0.15, \n",
    "        hspace=0.15)\n",
    "        \n",
    "    cmap = plt.get_cmap('cubehelix')\n",
    "    cmap.set_bad('gray')\n",
    "    flag[0,depth].plot.pcolormesh(ax=ax[0,1], cmap=cmap) \n",
    "    diat[0,depth].plot.pcolormesh(ax=ax[1,0], cmap=cmap) \n",
    "\n",
    "    sa_vi.set_aspect(ax[0,0])\n",
    "    sa_vi.set_aspect(ax[0,1])\n",
    "    sa_vi.set_aspect(ax[1,0])\n",
    "\n",
    "    ax[0,0].title.set_text('Clustering')\n",
    "    ax[0,1].title.set_text('Flaggelates')\n",
    "    ax[1,0].title.set_text('Diatoms')\n",
    "\n",
    "    if date[0].month < 10:\n",
    "        month = '0' + str(date[0].month)\n",
    "    else:\n",
    "        month = str(date[0].month)\n",
    "\n",
    "    if date[0].day < 10:\n",
    "        day = '0' + str(date[0].day)  \n",
    "    else:\n",
    "        day = str(date[0].day) \n",
    "\n",
    "    fig.suptitle('Depth: ' + str(np.round(ds['deptht'][depth].values,2)) + ' meters, ' + str(date[0].year) + '/' + month + '/' + day)\n",
    "\n",
    "    fig.savefig('Depth_' + str(np.round(ds['deptht'][depth].values,2))+ '.png')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main FOR Loop From Where All Functions are Called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01apr22']\n",
      "['01mar22']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m depth \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m     31\u001b[0m     temp, saline, flag, diat \u001b[38;5;241m=\u001b[39m masking(depth, temp, saline, mask, flag, diat)\n\u001b[0;32m---> 32\u001b[0m     unique, counts, inputs, predictions, clusters \u001b[38;5;241m=\u001b[39m \u001b[43msom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     printing(inputs, predictions, unique, counts)\n\u001b[1;32m     34\u001b[0m     plotting (depth, clusters, unique, flag, diat)\n",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m, in \u001b[0;36msom\u001b[0;34m(depth, temp, saline)\u001b[0m\n\u001b[1;32m     11\u001b[0m temp_som \u001b[38;5;241m=\u001b[39m SOM(m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m inputs3[\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;241m.\u001b[39msize, lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m     12\u001b[0m temp_som\u001b[38;5;241m.\u001b[39mfit(inputs3, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtemp_som\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Post processing\u001b[39;00m\n\u001b[1;32m     16\u001b[0m unique, counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(predictions, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/conda_envs/analysis-ilias/lib/python3.11/site-packages/sklearn_som/som.py:205\u001b[0m, in \u001b[0;36mSOM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX should have two dimensions, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis SOM has dimesnion \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Received input with dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 205\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_bmu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labels\n",
      "File \u001b[0;32m~/conda_envs/analysis-ilias/lib/python3.11/site-packages/sklearn_som/som.py:205\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX should have two dimensions, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis SOM has dimesnion \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Received input with dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 205\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_bmu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X])\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labels\n",
      "File \u001b[0;32m~/conda_envs/analysis-ilias/lib/python3.11/site-packages/sklearn_som/som.py:73\u001b[0m, in \u001b[0;36mSOM._find_bmu\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03mFind the index of the best matching unit for the input vector x.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Stack x to have one row per weight\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m x_stack \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Calculate distance between x and each weight\u001b[39;00m\n\u001b[1;32m     75\u001b[0m distance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(x_stack \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/conda_envs/analysis-ilias/lib/python3.11/site-packages/numpy/core/shape_base.py:456\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    454\u001b[0m sl \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m),) \u001b[38;5;241m*\u001b[39m axis \u001b[38;5;241m+\u001b[39m (_nx\u001b[38;5;241m.\u001b[39mnewaxis,)\n\u001b[1;32m    455\u001b[0m expanded_arrays \u001b[38;5;241m=\u001b[39m [arr[sl] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_arrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parent_dir = '/data/ibougoudis/MOAD/analysis-ilias/notebooks/som_depths_driv_phy_r'\n",
    "os.makedirs(parent_dir, exist_ok= True)\n",
    "\n",
    "dict_month = {'jan': '01',\n",
    "         'feb': '02',\n",
    "         'mar': '03',\n",
    "         'apr': '04',\n",
    "         'may': '05',\n",
    "         'jun': '06',\n",
    "         'jul': '07',\n",
    "         'aug': '08',\n",
    "         'sep': '09',\n",
    "         'oct': '10',\n",
    "         'nov': '11',\n",
    "         'dec': '12'}\n",
    "\n",
    "path = os.listdir('/results2/SalishSea/nowcast-green.202111/')\n",
    "\n",
    "folders = [x for x in path if (x[5]=='2') and (x[6]=='2') and (x[2:5]=='mar' or x[2:5]=='apr' or x[2:5] == 'may')]\n",
    "folders.sort()\n",
    "\n",
    "for i in folders:\n",
    "\n",
    "    os.makedirs(os.path.join(parent_dir, i), exist_ok= True) \n",
    "    os.chdir(os.path.join(parent_dir, i))\n",
    "\n",
    "    ds, temp, saline, date, mask, flag, diat = datasets_preparation(i)\n",
    "\n",
    "    for depth in range (0, 10):\n",
    "\n",
    "        temp, saline, flag, diat = masking(depth, temp, saline, mask, flag, diat)\n",
    "        unique, counts, inputs, predictions, clusters = som(depth, temp, saline)\n",
    "        printing(inputs, predictions, unique, counts)\n",
    "        plotting (depth, clusters, unique, flag, diat)\n",
    "    \n",
    "    print([i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis-ilias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
