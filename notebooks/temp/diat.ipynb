{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to reproduce years based on a model trained with random points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error as rmse\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import dill\n",
    "import random\n",
    "\n",
    "import salishsea_tools.viz_tools as sa_vi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets_preparation(dataset, dataset2):\n",
    "    \n",
    "    drivers = np.stack([np.ravel(dataset['Temperature_(0m-15m)']),\n",
    "        np.ravel(dataset['Temperature_(15m-100m)']), \n",
    "        np.ravel(dataset['Salinity_(0m-15m)']),\n",
    "        np.ravel(dataset['Salinity_(15m-100m)']),\n",
    "        np.ravel(dataset2['Summation_of_solar_radiation']),\n",
    "        np.ravel(dataset2['Mean_wind_speed']),\n",
    "        np.ravel(dataset2['Mean_air_temperature']),\n",
    "        np.tile(np.repeat(dataset.y, len(dataset.x)), len(dataset.time_counter)),\n",
    "        np.tile(dataset.x, len(dataset.time_counter)*len(dataset.y)),\n",
    "        np.repeat(dataset.time_counter.dt.month, len(dataset.x)*len(dataset.y)),\n",
    "        np.repeat(dataset.time_counter.dt.day, len(dataset.x)*len(dataset.y))\n",
    "        ])\n",
    "\n",
    "    indx = np.where(~np.isnan(drivers).any(axis=0))\n",
    "    drivers = drivers[:,indx[0]]\n",
    "\n",
    "    diat = np.ravel(dataset['Diatom'])\n",
    "    diat = diat[indx[0]]\n",
    "\n",
    "    return(drivers, diat, indx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor (inputs, targets):\n",
    "    \n",
    "    inputs = inputs.transpose()\n",
    "\n",
    "    model = TransformedTargetRegressor(regressor=make_pipeline(ColumnTransformer(\n",
    "            transformers=[(\"temporal\", OneHotEncoder(), [9,10])],remainder=StandardScaler()),\n",
    "            MLPRegressor(alpha=0.001, learning_rate='invscaling', epsilon=1e-07, max_iter=500)), \n",
    "            transformer=QuantileTransformer())\n",
    "    regr = BaggingRegressor(model, n_estimators=10, n_jobs=-1).fit(inputs,targets)\n",
    "    \n",
    "    return(regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressor 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor2 (inputs, targets, variable_name):\n",
    "\n",
    "    inputs2 = inputs.transpose()\n",
    "\n",
    "    outputs_test = regr.predict(inputs2)\n",
    "   \n",
    "    m = scatter_plot(targets, outputs_test, variable_name) \n",
    "    r = np.round(np.corrcoef(targets, outputs_test)[0][1],3)\n",
    "    rms = rmse(targets, outputs_test)\n",
    "\n",
    "    return (r, rms, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressor 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor3 (inputs, targets):\n",
    "  \n",
    "    inputs2 = inputs.transpose()\n",
    "\n",
    "    outputs_test = regr.predict(inputs2)\n",
    "    ave = np.nanmean(outputs_test)\n",
    "   \n",
    "    # compute slope m and intercept b\n",
    "    m, b = np.polyfit(targets, outputs_test, deg=1)\n",
    "    \n",
    "    r = np.round(np.corrcoef(targets, outputs_test)[0][1],3)\n",
    "    rms = rmse(targets, outputs_test)\n",
    "\n",
    "    return (r, rms, m, ave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressor 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor4 (inputs, targets, variable_name):\n",
    "\n",
    "    inputs2 = inputs.transpose()\n",
    "    \n",
    "    outputs = regr.predict(inputs2)\n",
    "\n",
    "    # Post processing\n",
    "    indx2 = np.full((len(diat_i.y)*len(diat_i.x)),np.nan)\n",
    "    indx2[indx[0]] = outputs\n",
    "    model = np.reshape(indx2,(len(diat_i.y),len(diat_i.x)))\n",
    "\n",
    "    m = scatter_plot(targets, outputs, variable_name + str(i.dt.date.values)) \n",
    "\n",
    "    # Preparation of the dataarray \n",
    "    model = xr.DataArray(model,\n",
    "        coords = {'y': diat_i.y, 'x': diat_i.x},\n",
    "        dims = ['y','x'],\n",
    "        attrs=dict( long_name = variable_name + \"Concentration\",\n",
    "        units=\"mmol m-2\"),)\n",
    "                        \n",
    "    plotting3(targets, model, diat_i, variable_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printing (targets, outputs, m):\n",
    "\n",
    "    print ('The amount of data points is', outputs.size)\n",
    "    print ('The slope of the best fitting line is ', np.round(m,3))\n",
    "    print ('The correlation coefficient is:', np.round(np.corrcoef(targets, outputs)[0][1],3))\n",
    "    print (' The root mean square error is:', rmse(targets,outputs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(targets, outputs, variable_name):\n",
    "\n",
    "    # compute slope m and intercept b\n",
    "    m, b = np.polyfit(targets, outputs, deg=1)\n",
    "\n",
    "    printing(targets, outputs, m)\n",
    "\n",
    "    fig, ax = plt.subplots(2, figsize=(5,10), layout='constrained')\n",
    "\n",
    "    ax[0].scatter(targets,outputs, alpha = 0.2, s = 10)\n",
    "\n",
    "    lims = [np.min([ax[0].get_xlim(), ax[0].get_ylim()]),\n",
    "        np.max([ax[0].get_xlim(), ax[0].get_ylim()])]\n",
    "\n",
    "    # plot fitted y = m*x + b\n",
    "    ax[0].axline(xy1=(0, b), slope=m, color='r')\n",
    "\n",
    "    ax[0].set_xlabel('targets')\n",
    "    ax[0].set_ylabel('outputs')\n",
    "    ax[0].set_xlim(lims)\n",
    "    ax[0].set_ylim(lims)\n",
    "    ax[0].set_aspect('equal')\n",
    "\n",
    "    ax[0].plot(lims, lims,linestyle = '--',color = 'k')\n",
    "\n",
    "    h = ax[1].hist2d(targets,outputs, bins=100, cmap='jet', \n",
    "        range=[lims,lims], cmin=0.1, norm='log')\n",
    "    \n",
    "    ax[1].plot(lims, lims,linestyle = '--',color = 'k')\n",
    "\n",
    "    # plot fitted y = m*x + b\n",
    "    ax[1].axline(xy1=(0, b), slope=m, color='r')\n",
    "\n",
    "    ax[1].set_xlabel('targets')\n",
    "    ax[1].set_ylabel('outputs')\n",
    "    ax[1].set_aspect('equal')\n",
    "\n",
    "    fig.colorbar(h[3],ax=ax[1], location='bottom')\n",
    "\n",
    "    fig.suptitle(variable_name)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return (m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(variable, name):\n",
    "\n",
    "    plt.plot(years,variable, marker = '.', linestyle = '')\n",
    "    plt.xlabel('Years')\n",
    "    plt.ylabel(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting2(variable,title):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    scatter= ax.scatter(dates,variable, marker='.', c=pd.DatetimeIndex(dates).month)\n",
    "\n",
    "    ax.legend(handles=scatter.legend_elements()[0], labels=['February','March','April'])\n",
    "    fig.suptitle('Daily ' + title + ' (15 Feb - 30 Apr)')\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting3(targets, model, variable, variable_name):\n",
    "\n",
    "    fig, ax = plt.subplots(2,2, figsize = (10,15))\n",
    "\n",
    "    cmap = plt.get_cmap('cubehelix')\n",
    "    cmap.set_bad('gray')\n",
    "\n",
    "    variable.plot(ax=ax[0,0], cmap=cmap, vmin = targets.min(), vmax =targets.max(), cbar_kwargs={'label': variable_name + ' Concentration  [mmol m-2]'})\n",
    "    model.plot(ax=ax[0,1], cmap=cmap, vmin = targets.min(), vmax = targets.max(), cbar_kwargs={'label': variable_name + ' Concentration  [mmol m-2]'})\n",
    "    ((variable-model) / variable * 100).plot(ax=ax[1,0], cmap=cmap, cbar_kwargs={'label': variable_name + ' Concentration  [percentage]'})\n",
    "\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "        bottom=0.1, \n",
    "        right=0.95, \n",
    "        top=0.95, \n",
    "        wspace=0.35, \n",
    "        hspace=0.35)\n",
    "\n",
    "    sa_vi.set_aspect(ax[0,0])\n",
    "    sa_vi.set_aspect(ax[0,1])\n",
    "    sa_vi.set_aspect(ax[1,0])\n",
    "\n",
    "\n",
    "    ax[0,0].title.set_text(variable_name + ' (targets)')\n",
    "    ax[0,1].title.set_text(variable_name + ' (outputs)')\n",
    "    ax[1,0].title.set_text('targets - outputs')\n",
    "    ax[1,1].axis('off')\n",
    "\n",
    "    fig.suptitle(str(i.dt.date.values))\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (Random Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('/data/ibougoudis/MOAD/files/integrated_original.nc')\n",
    "ds2 = xr.open_dataset('/data/ibougoudis/MOAD/files/external_inputs.nc')\n",
    "\n",
    "ds = ds.isel(time_counter = (np.arange(0, len(ds.time_counter),2)), \n",
    "    y=(np.arange(ds.y[0], ds.y[-1], 5)), \n",
    "    x=(np.arange(ds.x[0], ds.x[-1], 5)))\n",
    "\n",
    "ds2 = ds2.isel(time_counter = (np.arange(0, len(ds2.time_counter),2)), \n",
    "    y=(np.arange(ds2.y[0], ds2.y[-1], 5)), \n",
    "    x=(np.arange(ds2.x[0], ds2.x[-1], 5)))\n",
    "\n",
    "dataset = ds.sel(time_counter = slice('2007', '2020'))\n",
    "dataset2 = ds2.sel(time_counter = slice('2007', '2020'))\n",
    "\n",
    "drivers, diat, _ = datasets_preparation(dataset, dataset2)\n",
    "\n",
    "regr = regressor(drivers, diat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds = ds.sel(time_counter = slice('2021', '2023'))\n",
    "ds2 = ds2.sel(time_counter = slice('2021', '2023'))\n",
    "\n",
    "dates = pd.DatetimeIndex(ds['time_counter'].values)\n",
    "\n",
    "maps = random.sample(sorted(ds.time_counter),10)\n",
    "\n",
    "for i in tqdm(maps):\n",
    "\n",
    "    dataset = ds.sel(time_counter=slice(i,i))\n",
    "    dataset2 = ds2.sel(time_counter=slice(i,i))\n",
    "    drivers, diat, indx = datasets_preparation(dataset, dataset2)\n",
    "\n",
    "    diat_i = dataset['Diatom']\n",
    "\n",
    "    regressor4(drivers, diat, 'Diatom ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Years (Anually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range (2021,2024)\n",
    "\n",
    "for year in tqdm(range (2021,2024)):\n",
    "    \n",
    "    dataset = ds.sel(time_counter=str(year))\n",
    "    dataset2 = ds2.sel(time_counter=str(year))\n",
    "\n",
    "    drivers, diat, _ = datasets_preparation(dataset, dataset2)\n",
    "\n",
    "    r, rms, m = regressor2(drivers, diat, 'Diatom ' + str(year))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Years (Daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_all2 = np.array([])\n",
    "rms_all2 = np.array([])\n",
    "slope_all2 = np.array([])\n",
    "\n",
    "mean_meas = np.array([])\n",
    "mean_model = np.array([])\n",
    "\n",
    "for i in tqdm(ds.time_counter):\n",
    "    \n",
    "    dataset = ds.sel(time_counter=slice(i,i))\n",
    "    dataset2 = ds2.sel(time_counter=slice(i,i))\n",
    "\n",
    "    drivers, diat, _ = datasets_preparation(dataset, dataset2)\n",
    "    ave_meas = np.nanmean(diat)\n",
    "\n",
    "    r, rms, m, ave_model = regressor3(drivers, diat)\n",
    "\n",
    "    r_all2 = np.append(r_all2,r)\n",
    "    rms_all2 = np.append(rms_all2,rms)\n",
    "    slope_all2 = np.append(slope_all2,m)\n",
    "\n",
    "    mean_meas = np.append(mean_meas,ave_meas)\n",
    "    mean_model = np.append(mean_model,ave_model)\n",
    "\n",
    "plotting2(r_all2, 'Correlation Coefficients')\n",
    "plotting2(rms_all2, 'Root Mean Square Errors')\n",
    "plotting2(slope_all2, 'Slope of the best fitting line')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dates,(mean_meas), marker = '.', linestyle = '', label = 'measurements')\n",
    "plt.plot(dates,(mean_model), marker = '.', linestyle = '', label = 'model')\n",
    "plt.xlabel('Years')\n",
    "plt.ylabel('Diatom Concentration  [mmol m-2]')\n",
    "plt.suptitle('Daily Time-series')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis-ilias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
