{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to tune the hyperparameters of the model (Diatom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error as rmse\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets_preparation(dataset, dataset2):\n",
    "    \n",
    "    drivers = np.stack([np.ravel(dataset['Temperature_(0m-15m)']),\n",
    "        np.ravel(dataset['Temperature_(15m-100m)']), \n",
    "        np.ravel(dataset['Salinity_(0m-15m)']),\n",
    "        np.ravel(dataset['Salinity_(15m-100m)']),\n",
    "        np.ravel(dataset2['Summation_of_solar_radiation']),\n",
    "        np.ravel(dataset2['Mean_wind_speed']),\n",
    "        np.ravel(dataset2['Mean_air_temperature'])\n",
    "        ])\n",
    "    indx = np.where(~np.isnan(drivers).any(axis=0))\n",
    "    drivers = drivers[:,indx[0]]\n",
    "\n",
    "    diat = np.ravel(dataset['Diatom'])\n",
    "    diat = diat[indx[0]]\n",
    "\n",
    "    return(drivers, diat, indx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor (inputs, targets):\n",
    "\n",
    "    # Tuning of parameters      \n",
    "    params = {'n_neighbors':[3], 'weights':['distance'], 'leaf_size':[10], 'p':[1], 'metric':['cityblock']}                                        \n",
    "    scale = preprocessing.StandardScaler()                                                                               \n",
    "\n",
    "    inputs = inputs.transpose()\n",
    "    X_train, _, y_train, _ = train_test_split(inputs, targets, train_size=0.20)\n",
    "\n",
    "    inputs = scale.fit_transform(inputs)\n",
    "   \n",
    "    model = KNeighborsRegressor()\n",
    "\n",
    "    random_search = GridSearchCV(estimator=model, param_grid=params, scoring='r2',\n",
    "        cv=3, n_jobs=-1, verbose=3, pre_dispatch='2*n_jobs', return_train_score=True)\n",
    "\n",
    "    random_search.fit(X_train,y_train)\n",
    "\n",
    "    print('\\n', 'The best parameters are', random_search.best_params_)\n",
    "\n",
    "    return (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('/data/ibougoudis/MOAD/files/integrated_model_var_old.nc')\n",
    "ds2 = xr.open_dataset('/data/ibougoudis/MOAD/files/external_inputs.nc')\n",
    "\n",
    "ds = ds.isel(time_counter = (np.arange(0, len(ds.time_counter),2)), \n",
    "    y=(np.arange(ds.y[0], ds.y[-1], 5)), \n",
    "    x=(np.arange(ds.x[0], ds.x[-1], 5)))\n",
    "\n",
    "ds2 = ds2.isel(time_counter = (np.arange(0, len(ds2.time_counter),2)), \n",
    "    y=(np.arange(ds2.y[0], ds2.y[-1], 5)), \n",
    "    x=(np.arange(ds2.x[0], ds2.x[-1], 5)))\n",
    "\n",
    "dataset = ds.sel(time_counter = slice('2007', '2020'))\n",
    "dataset2 = ds2.sel(time_counter = slice('2007', '2020'))\n",
    "\n",
    "drivers, diat, _ = datasets_preparation(dataset, dataset2)\n",
    "\n",
    "# regr = regressor(drivers, diat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best parameters for each case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MLPRegressor(alpha=0.001, learning_rate='invscaling', tol=1e-06, epsilon=1e-07, power_t=1)\n",
    "# model = ExtraTreesRegressor(max_features='sqrt')\n",
    "# model = GradientBoostingRegressor(criterion='squared_error',learning_rate=0.5,subsample=0.5,min_samples_split=5,min_samples_leaf=6,max_depth=8,max_features='log2')\n",
    "# model = HistGradientBoostingRegressor(learning_rate=0.5, max_iter=400,max_leaf_nodes=None,min_samples_leaf=200,max_bins=100)\n",
    "# model = DecisionTreeRegressor(min_samples_leaf=15,min_samples_split=10)\n",
    "# model = KNeighborsRegressor(leaf_size=10, metric='cityblock', n_neighbors=3, p=1, weights='distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = drivers.transpose()\n",
    "targets = diat\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, targets, train_size=0.20)\n",
    "scale = preprocessing.StandardScaler()\n",
    "X_train_train=scale.fit_transform(X_train)\n",
    "X_test=scale.transform(X_test)\n",
    "\n",
    "model = MLPRegressor(alpha=0.001, learning_rate='invscaling', tol=1e-09, epsilon=1e-07)\n",
    "model = make_pipeline(StandardScaler(), model)\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5, n_jobs=-1, verbose=3)\n",
    "# regr = BaggingRegressor(model, n_estimators=12, n_jobs=8).fit(X_train,y_train)\n",
    "\n",
    "predictions=model.predict(X_test)\n",
    "RTWO=sklearn.metrics.r2_score(y_test,predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis-ilias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
