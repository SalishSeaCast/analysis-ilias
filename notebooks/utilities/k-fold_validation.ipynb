{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating training - testing performance based on k-fold validation (issue with high testing results when testing is from the same years as training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error as rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets_preparation(dataset, dataset2, name):\n",
    "    \n",
    "    x = np.tile(dataset.x, len(dataset.time_counter)*len(dataset.y))\n",
    "    y = np.tile(np.repeat(dataset.y, len(dataset.x)), len(dataset.time_counter))\n",
    "   \n",
    "    inputs = np.stack([\n",
    "        np.ravel(dataset2['Summation_of_solar_radiation']),\n",
    "        np.ravel(dataset2['Mean_wind_speed']),\n",
    "        np.ravel(dataset2['Mean_air_temperature']),\n",
    "        np.ravel(dataset2['Latitude']),\n",
    "        np.ravel(dataset2['Longitude']),\n",
    "        np.repeat(dataset.time_counter.dt.dayofyear, len(dataset.x)*len(dataset.y)),\n",
    "        ])\n",
    "\n",
    "    targets = np.ravel(dataset[name])\n",
    "    \n",
    "    indx = np.where(np.isfinite(targets) & (x>10) & ((x>100) | (y<880)))\n",
    "    inputs = inputs[:,indx[0]]\n",
    "    targets = targets[indx[0]]\n",
    "\n",
    "    inputs = inputs.transpose()\n",
    "\n",
    "    return(inputs, targets, indx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressor (Training with all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor (inputs, targets, table):\n",
    "\n",
    "    model = TransformedTargetRegressor(regressor=make_pipeline(ColumnTransformer(\n",
    "        transformers=[('drivers', StandardScaler(), [0,1,2]), ('spatial', KBinsDiscretizer(n_bins=255,encode='ordinal',strategy='quantile'), [3,4])],remainder='passthrough'),\n",
    "        HistGradientBoostingRegressor(categorical_features=[3,4,5])),\n",
    "        transformer=StandardScaler())\n",
    "    regr = BaggingRegressor(model, n_estimators=12, n_jobs=4).fit(inputs,targets)\n",
    "    \n",
    "    predictions = regr.predict(inputs)\n",
    "    \n",
    "    table[0,0] = np.round(np.corrcoef(predictions,targets)[0][1],3)\n",
    "    table[1,0] = rmse(predictions,targets)\n",
    "    m,_ = np.polyfit(targets, predictions, deg=1)\n",
    "    table[2,0] = np.round(m,3)\n",
    "\n",
    "    return(regr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressor (Training with 75%, testing with 25%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor2 (inputs, targets, table):\n",
    "\n",
    "    model = TransformedTargetRegressor(regressor=make_pipeline(ColumnTransformer(\n",
    "      transformers=[('drivers', StandardScaler(), [0,1,2]), ('spatial', KBinsDiscretizer(n_bins=155,encode='ordinal',strategy='uniform'), [3,4])],remainder='passthrough'),\n",
    "        HistGradientBoostingRegressor(categorical_features=[3,4,5])),\n",
    "        transformer=StandardScaler())\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(inputs, targets, test_size=0.25)\n",
    "    regr = BaggingRegressor(model, n_estimators=12, n_jobs=4).fit(X_train,y_train)\n",
    "\n",
    "    predictions = regr.predict(X_train)\n",
    "\n",
    "    table[0,2] = np.round(np.corrcoef(y_train,predictions)[0][1],3)\n",
    "    table[1,2] = rmse(y_train,predictions)\n",
    "    m,_ = np.polyfit(y_train,predictions, deg=1)\n",
    "    table[2,2] = np.round(m,3)\n",
    "    \n",
    "    predictions = regr.predict(X_test)\n",
    "\n",
    "    table[0,3] = np.round(np.corrcoef(y_test,predictions)[0][1],3)\n",
    "    table[1,3] = rmse(y_test,predictions)\n",
    "    m,_ = np.polyfit(y_test,predictions, deg=1)\n",
    "    table[2,3] = np.round(m,3)\n",
    "\n",
    "    return(regr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation (4 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor3 (inputs, targets, table):\n",
    "\n",
    "    model = TransformedTargetRegressor(regressor=make_pipeline(ColumnTransformer(\n",
    "        transformers=[('drivers', StandardScaler(), [0,1,2]), ('spatial', KBinsDiscretizer(n_bins=155,encode='ordinal',strategy='uniform'), [3,4])],remainder='passthrough'),\n",
    "        HistGradientBoostingRegressor(categorical_features=[3,4,5])),\n",
    "        transformer=StandardScaler())\n",
    "    \n",
    "    regr = BaggingRegressor(model, n_estimators=12, n_jobs=4)\n",
    "\n",
    "    kf = KFold(n_splits=4,shuffle=True)\n",
    "    predictions = cross_val_predict(regr, inputs, targets, cv=kf)\n",
    "    scores = cross_validate(regr, inputs, targets, cv=kf, scoring=('r2', 'neg_root_mean_squared_error'), return_train_score=True)\n",
    "\n",
    "    table[0,5:9] =  np.round(np.sqrt(np.abs(scores['train_r2'])),3)\n",
    "    table[1,5:9] =  np.abs(scores['train_neg_root_mean_squared_error'])\n",
    "\n",
    "    table[0,9:13] =  np.round(np.sqrt(np.abs(scores['test_r2'])),3)\n",
    "    table[1,9:13] =  np.abs(scores['test_neg_root_mean_squared_error'])\n",
    "\n",
    "    table[0,13] = np.round(np.corrcoef(predictions,targets)[0][1],3)\n",
    "    table[1,13] = rmse(predictions,targets)\n",
    "    m,_ = np.polyfit(targets, predictions, deg=1)\n",
    "    table[2,13] = np.round(m,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation (2021-2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation (ds,ds2,regr,name, table, i):\n",
    "\n",
    "    dataset = ds.sel(time_counter = slice('2021', '2024'))\n",
    "    dataset2 = ds2.sel(time_counter = slice('2021', '2024'))\n",
    "\n",
    "    inputs, targets, _ = datasets_preparation(dataset, dataset2,name)\n",
    "\n",
    "    predictions = regr.predict(inputs)\n",
    "\n",
    "    table[0,i] = np.round(np.corrcoef(predictions,targets)[0][1],3)\n",
    "    table[1,i] = rmse(predictions,targets)\n",
    "    m,_ = np.polyfit(targets, predictions, deg=1)\n",
    "    table[2,i] = np.round(m,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printing(table,criteria,categories,metric):\n",
    "\n",
    "    temp = pd.DataFrame(table.transpose(),columns=criteria,index=categories)\n",
    "    print(metric)\n",
    "    display(temp)\n",
    "    print ('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(name,table):\n",
    "\n",
    "    ds = xr.open_dataset('/data/ibougoudis/MOAD/files/integrated_original.nc')\n",
    "    ds2 = xr.open_dataset('/data/ibougoudis/MOAD/files/external_inputs.nc')\n",
    "\n",
    "    ds = ds.isel(y=(np.arange(ds.y[0], ds.y[-1], 5)), \n",
    "        x=(np.arange(ds.x[0], ds.x[-1], 5)))\n",
    "\n",
    "    ds2 = ds2.isel(y=(np.arange(ds2.y[0], ds2.y[-1], 5)), \n",
    "        x=(np.arange(ds2.x[0], ds2.x[-1], 5)))\n",
    "\n",
    "    dataset = ds.sel(time_counter = slice('2007', '2020'))\n",
    "    dataset2 = ds2.sel(time_counter = slice('2007', '2020'))\n",
    "\n",
    "    inputs, targets, _ = datasets_preparation(dataset, dataset2, name)\n",
    "\n",
    "    regr = regressor(inputs, targets, table)\n",
    "    evaluation(ds,ds2,regr,name,table,1)\n",
    "\n",
    "    regr2 = regressor2(inputs, targets, table)\n",
    "    evaluation(ds,ds2,regr2,name,table,4)\n",
    "\n",
    "    regressor3(inputs, targets, table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = ['r','rms','slope']\n",
    "categories = ['training with 100%', 'testing', 'training with 75%', 'testing with 25%', 'testing', '1st fold train','2nd fold train', '3rd fold train','4th fold train',\n",
    "    '1st fold test', '2nd fold test', '3rd fold test', '4th fold test', 'overall cross-val']\n",
    "\n",
    "diat = np.zeros((len(criteria),len(categories)))\n",
    "flag = np.zeros((len(criteria),len(categories)))\n",
    "diat_pr = np.zeros((len(criteria),len(categories)))\n",
    "flag_pr = np.zeros((len(criteria),len(categories)))\n",
    "\n",
    "training('Diatom',diat)\n",
    "# training('Flagellate',flag)\n",
    "# training('Diatom_Production_Rate',diat_pr)\n",
    "# training('Flagellate_Production_Rate',flag_pr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing (Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diatom\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>rms</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training with 100%</th>\n",
       "      <td>0.767</td>\n",
       "      <td>0.105953</td>\n",
       "      <td>0.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testing</th>\n",
       "      <td>0.612</td>\n",
       "      <td>0.130920</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training with 75%</th>\n",
       "      <td>0.764</td>\n",
       "      <td>0.106425</td>\n",
       "      <td>0.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testing with 25%</th>\n",
       "      <td>0.760</td>\n",
       "      <td>0.107410</td>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testing</th>\n",
       "      <td>0.610</td>\n",
       "      <td>0.131130</td>\n",
       "      <td>0.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st fold train</th>\n",
       "      <td>0.761</td>\n",
       "      <td>0.106378</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd fold train</th>\n",
       "      <td>0.762</td>\n",
       "      <td>0.106293</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd fold train</th>\n",
       "      <td>0.761</td>\n",
       "      <td>0.106475</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4th fold train</th>\n",
       "      <td>0.762</td>\n",
       "      <td>0.106244</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st fold test</th>\n",
       "      <td>0.759</td>\n",
       "      <td>0.107051</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd fold test</th>\n",
       "      <td>0.757</td>\n",
       "      <td>0.107106</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd fold test</th>\n",
       "      <td>0.757</td>\n",
       "      <td>0.107080</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4th fold test</th>\n",
       "      <td>0.756</td>\n",
       "      <td>0.107225</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall cross-val</th>\n",
       "      <td>0.760</td>\n",
       "      <td>0.107119</td>\n",
       "      <td>0.527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        r       rms  slope\n",
       "training with 100%  0.767  0.105953  0.533\n",
       "testing             0.612  0.130920  0.417\n",
       "training with 75%   0.764  0.106425  0.529\n",
       "testing with 25%    0.760  0.107410  0.525\n",
       "testing             0.610  0.131130  0.416\n",
       "1st fold train      0.761  0.106378  0.000\n",
       "2nd fold train      0.762  0.106293  0.000\n",
       "3rd fold train      0.761  0.106475  0.000\n",
       "4th fold train      0.762  0.106244  0.000\n",
       "1st fold test       0.759  0.107051  0.000\n",
       "2nd fold test       0.757  0.107106  0.000\n",
       "3rd fold test       0.757  0.107080  0.000\n",
       "4th fold test       0.756  0.107225  0.000\n",
       "overall cross-val   0.760  0.107119  0.527"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printing(diat,criteria, categories,'Diatom')\n",
    "# printing(flag,criteria, categories,'Flagellate')\n",
    "# printing(diat_pr,criteria, categories,'Diatom production rate')\n",
    "# printing(flag_pr,criteria, categories, 'Flagellate production rate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis-ilias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
