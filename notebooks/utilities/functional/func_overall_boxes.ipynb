{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall comparison of the models' performance (New Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dill\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printing(name,data,categories,boxnames):\n",
    "\n",
    "     temp = pd.DataFrame(data.transpose(),columns=boxnames,index=categories)\n",
    "     print(name)\n",
    "     display(temp)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing 2 (Anually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printing2(j,name,targets,predictions,years,categories,boxnames):\n",
    "\n",
    "     temp = pd.DataFrame(predictions.transpose(),columns=years,index=categories)\n",
    "     temp.loc['targets']=(targets.transpose())\n",
    "     print(name+ ' ' + boxnames[j])\n",
    "     display(temp)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting (name,quantity,categories,boxnames):\n",
    "\n",
    "    for i in range (0,len(categories)):\n",
    "        plt.plot(quantity[:,i],marker= '*', label=categories[i])\n",
    "\n",
    "    plt.xlabel('Regions')\n",
    "    plt.xticks(ticks=np.arange(0,len(quantity)), labels=boxnames)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.suptitle(name)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting 2 (Anually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting2(name,targets,predictions,years,categories,boxnames):\n",
    "\n",
    "    for j in range (0,len(predictions)):\n",
    "\n",
    "        printing2(j,'Summation',targets[j,:,0],predictions[j],years,categories,boxnames)\n",
    "\n",
    "        plt.plot(years,targets[j,:,0],marker = '*', label='targets',linewidth=1.5,color='k')\n",
    "        plt.plot(years,predictions[j],marker= '*', label=categories)\n",
    "        plt.xlabel('Years')\n",
    "        plt.suptitle(name+ ' ' + boxnames[j])\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Mean Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_mean_values(ticks,years,targets,predictions,categories,boxnames,type):\n",
    "\n",
    "    targets_masked = np.ma.array(targets)\n",
    "\n",
    "    predictions_masked = np.ma.array(predictions)\n",
    "\n",
    "    for year in years[:-1]:\n",
    "        targets_masked[ticks] = np.ma.masked\n",
    "        predictions_masked[ticks] = np.ma.masked\n",
    "\n",
    "    for i in range (0,targets.shape[-1]):\n",
    "\n",
    "        fig, _ = plt.subplots(figsize=(19,5))\n",
    "\n",
    "        plt.plot(targets_masked[:,i], label = 'targets', linewidth=1.5,color='k')\n",
    "\n",
    "        for j in range (0, len(categories)):\n",
    "            plt.plot(predictions_masked[:,i,j], label = categories[j])\n",
    "            plt.xlabel('Years')\n",
    "            plt.xticks(ticks,years)\n",
    "            plt.suptitle('Mean Concentrations [mmol m-2] '+ boxnames[i]+ ' ' +type)\n",
    "            plt.legend()\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "diat = '/data/ibougoudis/MOAD/files/results/Diatom/'\n",
    "flag = '/data/ibougoudis/MOAD/files/results/Flagellate/'\n",
    "\n",
    "years = np.array((2021,2022,2023,2024))\n",
    "\n",
    "variable = diat\n",
    "\n",
    "categories0 = os.listdir(variable) # All of them\n",
    "print(categories0)\n",
    "\n",
    "categories = ['func_reg_boxes_s1','func_reg_boxes_s17','func_reg_boxes_s18','func_reg_boxes_s20'] # What we actually want\n",
    "\n",
    "boxnames = ['SoG_north','SoG_center','Fraser_plume','SoG_south', 'Haro_Boundary', 'JdF_west', 'JdF_east', 'PS_all', 'PS_main']\n",
    "\n",
    "# Only to obtain dimensions - number of boxes\n",
    "with open(variable+categories[0] + '/targets-predictions.pkl', 'rb') as f:\n",
    "    metrics = dill.load(f)\n",
    "\n",
    "temp = metrics[0]\n",
    "\n",
    "r_train = np.zeros((temp.shape[2],len(categories)))\n",
    "rms_train = np.zeros((temp.shape[2],len(categories)))\n",
    "slope_train = np.zeros((temp.shape[2],len(categories)))\n",
    "r_train_season = np.zeros((temp.shape[2],len(categories)))\n",
    "slope_train_season = np.zeros((temp.shape[2],len(categories)))\n",
    "\n",
    "r_test = np.zeros((temp.shape[2],len(categories)))\n",
    "rms_test = np.zeros((temp.shape[2],len(categories)))\n",
    "slope_test = np.zeros((temp.shape[2],len(categories)))\n",
    "\n",
    "r_test_season = np.zeros((temp.shape[2],len(categories)))\n",
    "slope_test_season = np.zeros((temp.shape[2],len(categories)))\n",
    "\n",
    "targets_sum = np.zeros((temp.shape[2],len(years),len(categories)))\n",
    "predictions_sum = np.zeros((temp.shape[2],len(years),len(categories)))\n",
    "\n",
    "targets_mean =np.zeros((temp.shape[2],len(years),len(categories)))\n",
    "predictions_mean = np.zeros((temp.shape[2],len(years),len(categories)))\n",
    "\n",
    "targets_diff = np.zeros((temp.shape[0],temp.shape[1],temp.shape[2],len(categories)))\n",
    "predictions_diff = np.zeros((temp.shape[0],temp.shape[1],temp.shape[2],len(categories)))\n",
    "\n",
    "rss = np.zeros((temp.shape[2],len(categories)))\n",
    "\n",
    "predictions = np.zeros((temp.shape[0],temp.shape[1],temp.shape[2],len(categories)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(categories)):\n",
    "\n",
    "    with open(variable+categories[i] + '/train_metrics.pkl', 'rb') as f:\n",
    "        metrics = dill.load(f)\n",
    "\n",
    "    r_train[:,i] = metrics[0]\n",
    "    rms_train[:,i] = metrics[1]\n",
    "    slope_train[:,i] = metrics[2]\n",
    "\n",
    "    r_train_season[:,i] = metrics[3]\n",
    "    slope_train_season[:,i] = metrics[4]\n",
    "\n",
    "    season = metrics[5]\n",
    "\n",
    "    with open(variable+categories[i] + '/test_metrics.pkl', 'rb') as f:\n",
    "        metrics = dill.load(f)\n",
    "\n",
    "    r_test[:,i] = metrics[0]\n",
    "    rms_test[:,i] = metrics[1]\n",
    "    slope_test[:,i] = metrics[2]\n",
    "    r_test_season[:,i] = metrics[3]\n",
    "    slope_test_season[:,i] = metrics[4]\n",
    "\n",
    "    targets_sum[:,:,i] = metrics[5]\n",
    "    predictions_sum[:,:,i] = metrics[6]\n",
    "    targets_mean[:,:,i] = metrics[7]\n",
    "    predictions_mean[:,:,i] = metrics[8]\n",
    "\n",
    "    targets_diff = metrics[9]\n",
    "    predictions_diff[:,:,:,i] = metrics[10]\n",
    "\n",
    "    rss[:,i] = metrics[11]\n",
    "\n",
    "    with open(variable+categories[i] + '/targets-predictions.pkl', 'rb') as f:\n",
    "        metrics = dill.load(f)\n",
    "\n",
    "    targets = metrics[0]\n",
    "    predictions[:,:,:,i] = metrics[1]\n",
    "\n",
    "categories = ['default','no_air_temp','no_wind_s','no_wind_s+spec_hum'] # Names that we want\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-series Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_season = np.zeros(targets.shape)\n",
    "predictions_season = np.zeros(predictions.shape)\n",
    "\n",
    "for i in range (0,targets.shape[1]):\n",
    "    targets_season[:,i,:] = targets[:,i,:] -season.transpose()\n",
    "\n",
    "    for j in range (0, len(categories)):\n",
    "        predictions_season[:,i,:,j] = predictions[:,i,:,j] -season.transpose()\n",
    "\n",
    "ticks = []\n",
    "for i in range (0,targets.shape[0]*targets.shape[1],targets.shape[0]):\n",
    "    ticks.append(i)\n",
    "\n",
    "targets_season_new = np.reshape(targets_season,(temp.shape[0]*temp.shape[1],temp.shape[-1]),order='F')\n",
    "predictions_season_new = np.reshape(predictions_season,(predictions.shape[0]*predictions.shape[1],predictions.shape[2],predictions.shape[3]), order='F')\n",
    "                       \n",
    "targets_diff_new = np.reshape(targets_diff,(targets_diff.shape[0]*targets_diff.shape[1],targets_diff.shape[2]), order='F')\n",
    "predictions_diff_new = np.reshape(predictions_diff,(predictions_diff.shape[0]*predictions_diff.shape[1],predictions_diff.shape[2],predictions_diff.shape[3]), order='F')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printing('Correlation Coefficient (Training)',r_train,categories,boxnames)\n",
    "plotting('Correlation Coefficient (Training)',r_train,categories,boxnames)\n",
    "\n",
    "printing('Root Mean Square Error (Training)',rms_train,categories,boxnames)\n",
    "plotting('Root Mean Square Error (Training)',rms_train,categories,boxnames)\n",
    "\n",
    "printing('Slope of the Best Fitting Line (Training)',slope_train,categories,boxnames)\n",
    "plotting('Slope of the Best Fitting Line (Training)',slope_train,categories,boxnames)\n",
    "\n",
    "printing('Correlation Coefficient (Training, no Seasonality)',r_train_season,categories,boxnames)\n",
    "plotting('Correlation Coefficient (Training, no Seasonality)',r_train_season,categories,boxnames)\n",
    "\n",
    "printing('Slope of the Best Fitting Line (Training, no Seasonality)',slope_train_season,categories,boxnames)\n",
    "plotting('Slope of the Best Fitting Line (Training, no Seasonality)',slope_train_season,categories,boxnames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printing('Correlation Coefficient (Testing)',r_test,categories,boxnames)\n",
    "plotting('Correlation Coefficient (Testing)',r_test,categories,boxnames)\n",
    "\n",
    "printing('Root Mean Square Error (Testing)',rms_test,categories,boxnames)\n",
    "plotting('Root Mean Square Error (Testing)',rms_test,categories,boxnames)\n",
    "\n",
    "printing('Slope of the Best Fitting Line (Testing)',slope_test,categories,boxnames)\n",
    "plotting('Slope of the Best Fitting Line (Testing)',slope_test,categories,boxnames)\n",
    "\n",
    "printing('Correlation Coefficient (Testing, no Seasonality)',r_test_season,categories,boxnames)\n",
    "plotting('Correlation Coefficient (Testing, no Seasonality)',r_test_season,categories,boxnames)\n",
    "\n",
    "printing('Slope of the Best Fitting Line (Testing, no Seasonality)',slope_test_season,categories,boxnames)\n",
    "plotting('Slope of the Best Fitting Line (Testing, no Seasonality)',slope_test_season,categories,boxnames)\n",
    "\n",
    "printing('Sum of Squared Residuals (Testing)',rss,categories,boxnames)\n",
    "plotting('Sum of Squared Residuals (Testing)',rss,categories,boxnames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annual Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting2('Summation',targets_sum,predictions_sum,years,categories,boxnames)\n",
    "\n",
    "plotting2('Mean',targets_mean,predictions_mean,years,categories,boxnames)\n",
    "\n",
    "plotting_mean_values(ticks,years,targets_season_new,predictions_season_new,categories,boxnames, '')\n",
    "\n",
    "plotting_mean_values(ticks,years,targets_diff_new,predictions_diff_new,categories,boxnames, '(Differences)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis-ilias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
