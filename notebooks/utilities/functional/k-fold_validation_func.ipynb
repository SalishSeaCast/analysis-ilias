{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating training - testing performance based on k-fold validation - functional approach (issue with high testing results when testing is from the same years as training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chose a different regression model, due to incompatibility with some sklearn functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from skfda.representation.grid import FDataGrid\n",
    "from skfda.ml.regression import FPLSRegression\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error as rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets_preparation(dataset, dataset2, name):\n",
    "    \n",
    "    indx = np.where((dataset.time_counter.dt.month==2) & (dataset.time_counter.dt.day==29))\n",
    "    \n",
    "    targets = dataset[name].to_numpy().reshape(*dataset[name].to_numpy().shape[:1],-1)\n",
    "\n",
    "    day = np.repeat(dataset.time_counter.dt.dayofyear, len(dataset.x)*len(dataset.y))\n",
    "\n",
    "    inputs = np.stack([\n",
    "        dataset2['Summation_of_solar_radiation'].to_numpy().reshape(*dataset2['Summation_of_solar_radiation'].to_numpy().shape[:1],-1),\n",
    "        dataset2['Mean_wind_speed'].to_numpy().reshape(*dataset2['Mean_wind_speed'].to_numpy().shape[:1],-1),\n",
    "        dataset2['Mean_air_temperature'].to_numpy().reshape(*dataset2['Mean_air_temperature'].to_numpy().shape[:1],-1),\n",
    "        dataset2['Latitude'].to_numpy().reshape(*dataset2['Latitude'].to_numpy().shape[:1],-1),\n",
    "        dataset2['Longitude'].to_numpy().reshape(*dataset2['Longitude'].to_numpy().shape[:1],-1),\n",
    "        ])\n",
    "\n",
    "    # Deleting 29 of February\n",
    "    inputs = np.delete(inputs,indx,axis=1)\n",
    "    targets = np.delete(targets,indx,axis=0)\n",
    "\n",
    "    # Splitting in years\n",
    "    inputs = np.split(inputs,len(np.unique(dataset.time_counter.dt.year)),axis=1)\n",
    "    targets = np.split(targets,len(np.unique(dataset.time_counter.dt.year)),axis=0)\n",
    "\n",
    "    # Grouping all the years (amount of days for one year * amount of grid boxes)\n",
    "    inputs = np.concatenate(inputs,axis=2)\n",
    "    targets = np.concatenate(targets,axis=1)\n",
    "\n",
    "    x = np.tile(dataset.x, len(np.unique(dataset.time_counter.dt.year))*len(dataset.y))\n",
    "    y = np.tile(np.repeat(dataset.y, len(dataset.x)), len(np.unique(dataset.time_counter.dt.year)))\n",
    "\n",
    "    indx = np.where((~np.isnan(targets).any(axis=0))& (x>10) & ((x>100) | (y<880)))\n",
    "    inputs = inputs[:,:,indx[0]]\n",
    "    targets = targets[:,indx[0]]\n",
    "\n",
    "    return(inputs, targets, indx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_train(inputs,targets):\n",
    "\n",
    "    # Scaling the inputs\n",
    "    temp = np.reshape(inputs,(len(inputs),inputs.shape[1]*inputs.shape[2]))\n",
    "    temp = temp.transpose()\n",
    "    scaler_inputs = make_column_transformer((StandardScaler(), [0,1,2,3,4]))\n",
    "    temp = scaler_inputs.fit_transform(temp)\n",
    "    temp = temp.transpose()\n",
    "    inputs = np.reshape(temp,(len(inputs),inputs.shape[1],inputs.shape[2]))   \n",
    "    inputs = np.transpose(inputs,axes=(2,1,0))\n",
    "    \n",
    "    # Scaling the targets\n",
    "    scaler_targets = StandardScaler()\n",
    "    temp = np.ravel(targets)\n",
    "    temp = np.expand_dims(temp,-1)\n",
    "    temp = scaler_targets.fit_transform(temp)\n",
    "    targets = temp.reshape(targets.shape)\n",
    "\n",
    "    return(inputs,scaler_inputs,targets,scaler_targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling (Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_test(regr,inputs,scaler_inputs,targets,scaler_targets):\n",
    "\n",
    "    # Scaling the inputs\n",
    "    temp = np.reshape(inputs,(len(inputs),inputs.shape[1]*inputs.shape[2]))\n",
    "    temp = temp.transpose()\n",
    "    temp = scaler_inputs.transform(temp)\n",
    "    temp = temp.transpose()        \n",
    "    inputs = np.reshape(temp,(len(inputs),inputs.shape[1],inputs.shape[2]))\n",
    "        \n",
    "    inputs = np.transpose(inputs,axes=(2,1,0))\n",
    "    inputs = FDataGrid(data_matrix=inputs, grid_points=np.arange(0,len(targets)))\n",
    "\n",
    "    predictions = regr.predict(inputs)\n",
    "\n",
    "    # # Post-processing of predictions\n",
    "    # predictions = np.array(predictions.to_grid(np.arange(0,len(targets))).data_matrix)\n",
    "    # predictions = np.squeeze(predictions,2)\n",
    "\n",
    "    # Scaling the predictions\n",
    "    temp = np.ravel(predictions)\n",
    "    temp = np.expand_dims(temp,axis=-1)\n",
    "    temp = scaler_targets.inverse_transform(temp)\n",
    "    predictions = temp.reshape(predictions.shape)\n",
    "    predictions = predictions.transpose()\n",
    "\n",
    "    return(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressor (Training with all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor (inputs0, targets0, table):\n",
    "\n",
    "    inputs,scaler_inputs,targets,scaler_targets = scaling_train(inputs0,targets0)\n",
    "\n",
    "    # Final transformations\n",
    "    targets = targets.transpose()\n",
    "    inputs = FDataGrid(data_matrix=inputs, grid_points=np.arange(0,len(targets[0])))\n",
    "    # targets = FDataGrid(data_matrix=targets, grid_points=np.arange(0,len(targets[0])))\n",
    "\n",
    "    # Smoothing\n",
    "    # targets = targets.to_basis(FourierBasis(n_basis=5))\n",
    "\n",
    "    model = FPLSRegression(n_components=35)\n",
    "    regr = model.fit(inputs,targets)\n",
    "\n",
    "    predictions = scaling_test(regr,inputs0,scaler_inputs,targets0,scaler_targets)\n",
    "    \n",
    "    table[0,0] = np.round(np.corrcoef(np.ravel(predictions),np.ravel(targets0))[0][1],3)\n",
    "    table[1,0] = rmse(np.ravel(predictions),np.ravel(targets0))\n",
    "    m,_ = np.polyfit(np.ravel(targets0), np.ravel(predictions), deg=1)\n",
    "    table[2,0] = np.round(m,3)\n",
    "\n",
    "    return(regr,scaler_inputs,scaler_targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressor (Training with 75%, testing with 25%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor2 (inputs0, targets0, table):\n",
    "\n",
    "    X_train0, X_test0, y_train0, y_test0 = train_test_split(np.transpose(inputs0,(2,0,1)), targets0.transpose(), test_size=0.25)\n",
    "\n",
    "    X_train0 = np.transpose(X_train0,(1,2,0))\n",
    "    y_train0 = y_train0.transpose()\n",
    "\n",
    "    X_test0 = np.transpose(X_test0,(1,2,0))\n",
    "    y_test0 = y_test0.transpose()\n",
    "    \n",
    "    X_train,scaler_inputs,y_train,scaler_targets = scaling_train(X_train0,y_train0)\n",
    "\n",
    "    # Final transformations\n",
    "    y_train = y_train.transpose()\n",
    "    X_train = FDataGrid(data_matrix=X_train, grid_points=np.arange(0,len(y_train[0])))\n",
    "    # y_train = FDataGrid(data_matrix=y_train, grid_points=np.arange(0,len(y_train[0])))\n",
    "\n",
    "    # Smoothing\n",
    "    # targets = targets.to_basis(FourierBasis(n_basis=5))\n",
    "\n",
    "    model = FPLSRegression(n_components=35)\n",
    "    regr = model.fit(X_train,y_train)\n",
    "\n",
    "    predictions = scaling_test(regr,X_train0,scaler_inputs,y_train0,scaler_targets)\n",
    "\n",
    "    table[0,2] = np.round(np.corrcoef(np.ravel(y_train0),np.ravel(predictions))[0][1],3)\n",
    "    table[1,2] = rmse(np.ravel(y_train0),np.ravel(predictions))\n",
    "    m,_ = np.polyfit(np.ravel(y_train0),np.ravel(predictions), deg=1)\n",
    "    table[2,2] = np.round(m,3)\n",
    "    \n",
    "    predictions = scaling_test(regr,X_test0,scaler_inputs,y_test0,scaler_targets)\n",
    "\n",
    "    table[0,3] = np.round(np.corrcoef(np.ravel(y_test0),np.ravel(predictions))[0][1],3)\n",
    "    table[1,3] = rmse(np.ravel(y_test0),np.ravel(predictions))\n",
    "    m,_ = np.polyfit(np.ravel(y_test0),np.ravel(predictions), deg=1)\n",
    "    table[2,3] = np.round(m,3)\n",
    "\n",
    "    return(regr,scaler_inputs,scaler_targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation (4 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor3(inputs0, targets0, table):\n",
    "\n",
    "    inputs,scaler_inputs,targets,scaler_targets = scaling_train(inputs0,targets0)\n",
    "\n",
    "    # Final transformations\n",
    "    targets = targets.transpose()\n",
    "    inputs = FDataGrid(data_matrix=inputs, grid_points=np.arange(0,len(targets[0])))\n",
    "    # targets = FDataGrid(data_matrix=targets, grid_points=np.arange(0,len(targets[0])))\n",
    "\n",
    "    model = FPLSRegression(n_components=35)\n",
    "    regr = model\n",
    "\n",
    "    kf = KFold(n_splits=4,shuffle=True)\n",
    "    predictions = cross_val_predict(regr, inputs, targets, cv=kf)\n",
    "\n",
    "    # Scaling the predictions\n",
    "    temp = np.ravel(predictions)\n",
    "    temp = np.expand_dims(temp,axis=-1)\n",
    "    temp = scaler_targets.inverse_transform(temp)\n",
    "    predictions = temp.reshape(predictions.shape)\n",
    "    predictions = predictions.transpose()\n",
    "\n",
    "    table[0,13] = np.round(np.corrcoef(np.ravel(predictions),np.ravel(targets0))[0][1],3)\n",
    "    table[1,13] = rmse(np.ravel(predictions),np.ravel(targets0))\n",
    "    m,_ = np.polyfit(np.ravel(targets0), np.ravel(predictions), deg=1)\n",
    "    table[2,13] = np.round(m,3)\n",
    "\n",
    "    scores = cross_validate(regr, inputs, targets, cv=kf, scoring=('r2', 'neg_root_mean_squared_error'), return_train_score=True, return_estimator=True, return_indices=True)\n",
    "\n",
    "    predictions_train = np.zeros(targets0.shape)\n",
    "    predictions_test = np.zeros(targets0.shape)\n",
    "\n",
    "    for i in range (0, kf.get_n_splits()):\n",
    "\n",
    "        regr = scores['estimator'][i]\n",
    "        indx_train = scores['indices']['train'][i]\n",
    "        indx_test = scores['indices']['test'][i]\n",
    "\n",
    "        predictions_train[:,indx_train] = scaling_test(regr,inputs0[:,:,indx_train],scaler_inputs,targets0[:,indx_train],scaler_targets)\n",
    "        table[0,i+5] = np.round(np.corrcoef(np.ravel(predictions_train[:,indx_train]),np.ravel(targets0[:,indx_train]))[0][1],3)\n",
    "        table[1,i+5] = rmse(np.ravel(predictions_train[:,indx_train]),np.ravel(targets0[:,indx_train]))\n",
    "        m,_ = np.polyfit(np.ravel(targets0[:,indx_train]), np.ravel(predictions_train[:,indx_train]), deg=1)\n",
    "        table[2,i+5] = np.round(m,3)\n",
    "\n",
    "        predictions_test[:,indx_test] = scaling_test(regr,inputs0[:,:,indx_test],scaler_inputs,targets0[:,indx_test],scaler_targets)\n",
    "        table[0,i+9] = np.round(np.corrcoef(np.ravel(predictions_test[:,indx_test]),np.ravel(targets0[:,indx_test]))[0][1],3)\n",
    "        table[1,i+9] = rmse(np.ravel(predictions_test[:,indx_test]),np.ravel(targets0[:,indx_test]))\n",
    "        m,_ = np.polyfit(np.ravel(targets0[:,indx_test]), np.ravel(predictions_test[:,indx_test]), deg=1)\n",
    "        table[2,i+9] = np.round(m,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation (2021-2024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation (ds, ds2, regr, scaler_inputs, scaler_targets, name, table, i):\n",
    "\n",
    "    dataset = ds.sel(time_counter = slice('2021', '2024'))\n",
    "    dataset2 = ds2.sel(time_counter = slice('2021', '2024'))\n",
    "\n",
    "    inputs, targets, _ = datasets_preparation(dataset, dataset2, name)\n",
    "\n",
    "    predictions = scaling_test(regr,inputs,scaler_inputs,targets,scaler_targets)\n",
    "\n",
    "    table[0,i] = np.round(np.corrcoef(np.ravel(predictions),np.ravel(targets))[0][1],3)\n",
    "    table[1,i] = rmse(np.ravel(predictions),np.ravel(targets))\n",
    "    m,_ = np.polyfit(np.ravel(targets), np.ravel(predictions), deg=1)\n",
    "    table[2,i] = np.round(m,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printing(table,criteria,categories,metric):\n",
    "\n",
    "    temp = pd.DataFrame(table.transpose(),columns=criteria,index=categories)\n",
    "    print(metric)\n",
    "    display(temp)\n",
    "    print ('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(name,table):\n",
    "\n",
    "    ds = xr.open_dataset('/data/ibougoudis/MOAD/files/integrated_original.nc')\n",
    "    ds2 = xr.open_dataset('/data/ibougoudis/MOAD/files/external_inputs.nc')\n",
    "\n",
    "    ds = ds.isel(y=(np.arange(ds.y[0], ds.y[-1], 5)), \n",
    "        x=(np.arange(ds.x[0], ds.x[-1], 5)))\n",
    "\n",
    "    ds2 = ds2.isel(y=(np.arange(ds2.y[0], ds2.y[-1], 5)), \n",
    "        x=(np.arange(ds2.x[0], ds2.x[-1], 5)))\n",
    " \n",
    "    dataset = ds.sel(time_counter = slice('2007', '2020'))\n",
    "    dataset2 = ds2.sel(time_counter = slice('2007', '2020'))\n",
    "\n",
    "    inputs, targets, _ = datasets_preparation(dataset, dataset2, name)\n",
    "\n",
    "    regr,scaler_inputs,scaler_targets = regressor(inputs, targets, table)\n",
    "    evaluation(ds, ds2, regr, scaler_inputs, scaler_targets, name, table, 1)\n",
    "\n",
    "    regr2,scaler_inputs,scaler_targets = regressor2(inputs, targets, table)\n",
    "    evaluation(ds, ds2, regr2, scaler_inputs, scaler_targets, name, table, 4)\n",
    "\n",
    "    regressor3(inputs, targets, table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = ['r','rms','slope']\n",
    "categories = ['training with 100%', 'testing', 'training with 75%', 'testing with 25%', 'testing', '1st fold train','2nd fold train', '3rd fold train','4th fold train',\n",
    "    '1st fold test', '2nd fold test', '3rd fold test', '4th fold test', 'overall cross-val']\n",
    "\n",
    "diat = np.zeros((len(criteria),len(categories)))\n",
    "flag = np.zeros((len(criteria),len(categories)))\n",
    "diat_pr = np.zeros((len(criteria),len(categories)))\n",
    "flag_pr = np.zeros((len(criteria),len(categories)))\n",
    "\n",
    "training('Diatom',diat)\n",
    "training('Flagellate',flag)\n",
    "training('Diatom_Production_Rate',diat_pr)\n",
    "training('Flagellate_Production_Rate',flag_pr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing (Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diatom\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>rms</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training with 100%</th>\n",
       "      <td>0.823</td>\n",
       "      <td>0.093249</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testing</th>\n",
       "      <td>0.583</td>\n",
       "      <td>0.186537</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training with 75%</th>\n",
       "      <td>0.823</td>\n",
       "      <td>0.093195</td>\n",
       "      <td>0.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testing with 25%</th>\n",
       "      <td>0.822</td>\n",
       "      <td>0.093507</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testing</th>\n",
       "      <td>0.577</td>\n",
       "      <td>0.185476</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st fold train</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.093324</td>\n",
       "      <td>0.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd fold train</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.093093</td>\n",
       "      <td>0.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd fold train</th>\n",
       "      <td>0.823</td>\n",
       "      <td>0.093052</td>\n",
       "      <td>0.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4th fold train</th>\n",
       "      <td>0.822</td>\n",
       "      <td>0.093366</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st fold test</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.093196</td>\n",
       "      <td>0.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd fold test</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.093868</td>\n",
       "      <td>0.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd fold test</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.094035</td>\n",
       "      <td>0.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4th fold test</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.092970</td>\n",
       "      <td>0.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall cross-val</th>\n",
       "      <td>0.822</td>\n",
       "      <td>0.093515</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        r       rms  slope\n",
       "training with 100%  0.823  0.093249  0.677\n",
       "testing             0.583  0.186537  0.751\n",
       "training with 75%   0.823  0.093195  0.678\n",
       "testing with 25%    0.822  0.093507  0.675\n",
       "testing             0.577  0.185476  0.739\n",
       "1st fold train      0.824  0.093324  0.678\n",
       "2nd fold train      0.824  0.093093  0.678\n",
       "3rd fold train      0.823  0.093052  0.678\n",
       "4th fold train      0.822  0.093366  0.676\n",
       "1st fold test       0.821  0.093196  0.683\n",
       "2nd fold test       0.821  0.093868  0.673\n",
       "3rd fold test       0.821  0.094035  0.673\n",
       "4th fold test       0.825  0.092970  0.678\n",
       "overall cross-val   0.822  0.093515  0.677"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Flagellate\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>rms</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training with 100%</th>\n",
       "      <td>0.788</td>\n",
       "      <td>0.016969</td>\n",
       "      <td>0.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testing</th>\n",
       "      <td>0.297</td>\n",
       "      <td>0.032863</td>\n",
       "      <td>0.274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training with 75%</th>\n",
       "      <td>0.788</td>\n",
       "      <td>0.016988</td>\n",
       "      <td>0.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testing with 25%</th>\n",
       "      <td>0.786</td>\n",
       "      <td>0.016941</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testing</th>\n",
       "      <td>0.296</td>\n",
       "      <td>0.032649</td>\n",
       "      <td>0.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st fold train</th>\n",
       "      <td>0.788</td>\n",
       "      <td>0.016963</td>\n",
       "      <td>0.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd fold train</th>\n",
       "      <td>0.786</td>\n",
       "      <td>0.017041</td>\n",
       "      <td>0.618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd fold train</th>\n",
       "      <td>0.789</td>\n",
       "      <td>0.016925</td>\n",
       "      <td>0.622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4th fold train</th>\n",
       "      <td>0.789</td>\n",
       "      <td>0.016911</td>\n",
       "      <td>0.622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st fold test</th>\n",
       "      <td>0.785</td>\n",
       "      <td>0.017026</td>\n",
       "      <td>0.612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd fold test</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.016766</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd fold test</th>\n",
       "      <td>0.784</td>\n",
       "      <td>0.017144</td>\n",
       "      <td>0.617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4th fold test</th>\n",
       "      <td>0.783</td>\n",
       "      <td>0.017181</td>\n",
       "      <td>0.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall cross-val</th>\n",
       "      <td>0.786</td>\n",
       "      <td>0.017030</td>\n",
       "      <td>0.619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        r       rms  slope\n",
       "training with 100%  0.788  0.016969  0.620\n",
       "testing             0.297  0.032863  0.274\n",
       "training with 75%   0.788  0.016988  0.621\n",
       "testing with 25%    0.786  0.016941  0.624\n",
       "testing             0.296  0.032649  0.268\n",
       "1st fold train      0.788  0.016963  0.621\n",
       "2nd fold train      0.786  0.017041  0.618\n",
       "3rd fold train      0.789  0.016925  0.622\n",
       "4th fold train      0.789  0.016911  0.622\n",
       "1st fold test       0.785  0.017026  0.612\n",
       "2nd fold test       0.792  0.016766  0.625\n",
       "3rd fold test       0.784  0.017144  0.617\n",
       "4th fold test       0.783  0.017181  0.621\n",
       "overall cross-val   0.786  0.017030  0.619"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Diatom production rate\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>rms</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training with 100%</th>\n",
       "      <td>0.826</td>\n",
       "      <td>8.521344e-07</td>\n",
       "      <td>0.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testing</th>\n",
       "      <td>0.446</td>\n",
       "      <td>1.945298e-06</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training with 75%</th>\n",
       "      <td>0.825</td>\n",
       "      <td>8.536980e-07</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testing with 25%</th>\n",
       "      <td>0.828</td>\n",
       "      <td>8.474255e-07</td>\n",
       "      <td>0.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testing</th>\n",
       "      <td>0.444</td>\n",
       "      <td>1.945483e-06</td>\n",
       "      <td>0.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st fold train</th>\n",
       "      <td>0.825</td>\n",
       "      <td>8.530358e-07</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd fold train</th>\n",
       "      <td>0.826</td>\n",
       "      <td>8.504693e-07</td>\n",
       "      <td>0.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd fold train</th>\n",
       "      <td>0.825</td>\n",
       "      <td>8.529669e-07</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4th fold train</th>\n",
       "      <td>0.827</td>\n",
       "      <td>8.506161e-07</td>\n",
       "      <td>0.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st fold test</th>\n",
       "      <td>0.826</td>\n",
       "      <td>8.514574e-07</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd fold test</th>\n",
       "      <td>0.824</td>\n",
       "      <td>8.582420e-07</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd fold test</th>\n",
       "      <td>0.826</td>\n",
       "      <td>8.503396e-07</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4th fold test</th>\n",
       "      <td>0.822</td>\n",
       "      <td>8.585574e-07</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall cross-val</th>\n",
       "      <td>0.825</td>\n",
       "      <td>8.546510e-07</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        r           rms  slope\n",
       "training with 100%  0.826  8.521344e-07  0.682\n",
       "testing             0.446  1.945298e-06  0.475\n",
       "training with 75%   0.825  8.536980e-07  0.681\n",
       "testing with 25%    0.828  8.474255e-07  0.683\n",
       "testing             0.444  1.945483e-06  0.476\n",
       "1st fold train      0.825  8.530358e-07  0.681\n",
       "2nd fold train      0.826  8.504693e-07  0.682\n",
       "3rd fold train      0.825  8.529669e-07  0.681\n",
       "4th fold train      0.827  8.506161e-07  0.683\n",
       "1st fold test       0.826  8.514574e-07  0.681\n",
       "2nd fold test       0.824  8.582420e-07  0.679\n",
       "3rd fold test       0.826  8.503396e-07  0.685\n",
       "4th fold test       0.822  8.585574e-07  0.679\n",
       "overall cross-val   0.825  8.546510e-07  0.681"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Flagellate production rate\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>rms</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training with 100%</th>\n",
       "      <td>0.854</td>\n",
       "      <td>2.088482e-07</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testing</th>\n",
       "      <td>0.450</td>\n",
       "      <td>3.988428e-07</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training with 75%</th>\n",
       "      <td>0.854</td>\n",
       "      <td>2.089309e-07</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testing with 25%</th>\n",
       "      <td>0.854</td>\n",
       "      <td>2.090805e-07</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testing</th>\n",
       "      <td>0.451</td>\n",
       "      <td>3.997920e-07</td>\n",
       "      <td>0.404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st fold train</th>\n",
       "      <td>0.855</td>\n",
       "      <td>2.088131e-07</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd fold train</th>\n",
       "      <td>0.853</td>\n",
       "      <td>2.094207e-07</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd fold train</th>\n",
       "      <td>0.854</td>\n",
       "      <td>2.083048e-07</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4th fold train</th>\n",
       "      <td>0.855</td>\n",
       "      <td>2.084455e-07</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st fold test</th>\n",
       "      <td>0.851</td>\n",
       "      <td>2.094496e-07</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd fold test</th>\n",
       "      <td>0.856</td>\n",
       "      <td>2.074117e-07</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd fold test</th>\n",
       "      <td>0.854</td>\n",
       "      <td>2.108968e-07</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4th fold test</th>\n",
       "      <td>0.852</td>\n",
       "      <td>2.103030e-07</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall cross-val</th>\n",
       "      <td>0.853</td>\n",
       "      <td>2.094356e-07</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        r           rms  slope\n",
       "training with 100%  0.854  2.088482e-07  0.729\n",
       "testing             0.450  3.988428e-07  0.401\n",
       "training with 75%   0.854  2.089309e-07  0.729\n",
       "testing with 25%    0.854  2.090805e-07  0.732\n",
       "testing             0.451  3.997920e-07  0.404\n",
       "1st fold train      0.855  2.088131e-07  0.731\n",
       "2nd fold train      0.853  2.094207e-07  0.728\n",
       "3rd fold train      0.854  2.083048e-07  0.729\n",
       "4th fold train      0.855  2.084455e-07  0.730\n",
       "1st fold test       0.851  2.094496e-07  0.731\n",
       "2nd fold test       0.856  2.074117e-07  0.731\n",
       "3rd fold test       0.854  2.108968e-07  0.725\n",
       "4th fold test       0.852  2.103030e-07  0.727\n",
       "overall cross-val   0.853  2.094356e-07  0.729"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printing(diat,criteria, categories,'Diatom')\n",
    "printing(flag,criteria, categories,'Flagellate')\n",
    "printing(diat_pr,criteria, categories,'Diatom production rate')\n",
    "printing(flag_pr,criteria, categories, 'Flagellate production rate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis-ilias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
