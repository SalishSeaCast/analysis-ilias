{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error as rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets_preparation(dataset, dataset2, name):\n",
    "    \n",
    "    x = np.tile(dataset.x, len(dataset.time_counter)*len(dataset.y))\n",
    "    y = np.tile(np.repeat(dataset.y, len(dataset.x)), len(dataset.time_counter))\n",
    "   \n",
    "    inputs = np.stack([\n",
    "        np.ravel(dataset2['Summation_of_solar_radiation']),\n",
    "        np.ravel(dataset2['Mean_wind_speed']),\n",
    "        np.ravel(dataset2['Mean_air_temperature']),\n",
    "        y,\n",
    "        x,\n",
    "        np.repeat(dataset.time_counter.dt.dayofyear, len(dataset.x)*len(dataset.y)),\n",
    "        ])\n",
    "\n",
    "    targets = np.ravel(dataset[name])\n",
    "    \n",
    "    indx = np.where(np.isfinite(targets) & (x>10) & ((x>100) | (y<880)))\n",
    "    inputs = inputs[:,indx[0]]\n",
    "    targets = targets[indx[0]]\n",
    "\n",
    "    inputs = inputs.transpose()\n",
    "\n",
    "    return(inputs, targets, indx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressor (Training with all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor (inputs, targets, table):\n",
    "\n",
    "    model = TransformedTargetRegressor(regressor=make_pipeline(ColumnTransformer(\n",
    "        transformers=[('drivers', StandardScaler(), [0,1,2]), ],remainder='passthrough'),\n",
    "        HistGradientBoostingRegressor(categorical_features=[3,4,5],learning_rate=0.5)),\n",
    "        transformer=StandardScaler())\n",
    "    regr = BaggingRegressor(model, n_estimators=12, n_jobs=4)\n",
    "    \n",
    "    # predictions = regr.predict(inputs)\n",
    "    \n",
    "    # table[0,0] = np.round(np.corrcoef(predictions,targets)[0][1],3)\n",
    "    # table[1,0] = rmse(predictions,targets)\n",
    "    # m,_ = np.polyfit(targets, predictions, deg=1)\n",
    "    # table[2,0] = np.round(m,3)\n",
    "\n",
    "    return(regr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressor (Training with 75%, testing with 25%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor2 (inputs, targets, table):\n",
    "\n",
    "    model = TransformedTargetRegressor(regressor=make_pipeline(ColumnTransformer(\n",
    "        transformers=[('drivers', StandardScaler(), [0,1,2]), ],remainder='passthrough'),\n",
    "        HistGradientBoostingRegressor(categorical_features=[3,4,5],learning_rate=0.5)),\n",
    "        transformer=StandardScaler())\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(inputs, targets, test_size=0.25)\n",
    "    regr = BaggingRegressor(model, n_estimators=12, n_jobs=4).fit(X_train,y_train)\n",
    "\n",
    "    predictions = regr.predict(X_train)\n",
    "\n",
    "    table[0,2] = np.round(np.corrcoef(y_train,predictions)[0][1],3)\n",
    "    table[1,2] = rmse(y_train,predictions)\n",
    "    m,_ = np.polyfit(y_train,predictions, deg=1)\n",
    "    table[2,2] = np.round(m,3)\n",
    "    \n",
    "    predictions = regr.predict(X_test)\n",
    "\n",
    "    table[0,3] = np.round(np.corrcoef(y_test,predictions)[0][1],3)\n",
    "    table[1,3] = rmse(y_test,predictions)\n",
    "    m,_ = np.polyfit(y_test,predictions, deg=1)\n",
    "    table[2,3] = np.round(m,3)\n",
    "\n",
    "    return(regr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation (ds,ds2,regr,name, table, i):\n",
    "\n",
    "    dataset = ds.sel(time_counter = slice('2021', '2024'))\n",
    "    dataset2 = ds2.sel(time_counter = slice('2021', '2024'))\n",
    "\n",
    "    inputs, targets, _ = datasets_preparation(dataset, dataset2,name)\n",
    "\n",
    "    predictions = regr.predict(inputs)\n",
    "\n",
    "    table[0,i] = np.round(np.corrcoef(predictions,targets)[0][1],3)\n",
    "    table[1,i] = rmse(predictions,targets)\n",
    "    m,_ = np.polyfit(targets, predictions, deg=1)\n",
    "    table[2,i] = np.round(m,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printing(table,criteria,categories,metric):\n",
    "\n",
    "    temp = pd.DataFrame(table.transpose(),columns=criteria,index=categories)\n",
    "    print(metric)\n",
    "    display(temp)\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(name,table):\n",
    "\n",
    "    ds = xr.open_dataset('/data/ibougoudis/MOAD/files/integrated_original.nc')\n",
    "    ds2 = xr.open_dataset('/data/ibougoudis/MOAD/files/external_inputs.nc')\n",
    "\n",
    "    ds = ds.isel(time_counter = (np.arange(0, len(ds.time_counter),2)), \n",
    "        y=(np.arange(ds.y[0], ds.y[-1], 5)), \n",
    "        x=(np.arange(ds.x[0], ds.x[-1], 5)))\n",
    "\n",
    "    ds2 = ds2.isel(time_counter = (np.arange(0, len(ds2.time_counter),2)), \n",
    "        y=(np.arange(ds2.y[0], ds2.y[-1], 5)), \n",
    "        x=(np.arange(ds2.x[0], ds2.x[-1], 5)))\n",
    "\n",
    "    dataset = ds.sel(time_counter = slice('2007', '2020'))\n",
    "    dataset2 = ds2.sel(time_counter = slice('2007', '2020'))\n",
    "\n",
    "    inputs, targets, _ = datasets_preparation(dataset, dataset2, name)\n",
    "\n",
    "    regr = regressor(inputs, targets, table)\n",
    "    # evaluation(ds,ds2,regr,name,table,1)\n",
    "\n",
    "    # regr2 = regressor2(inputs, targets, table)\n",
    "    # evaluation(ds,ds2,regr2,name,table,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "ds = xr.open_dataset('/data/ibougoudis/MOAD/files/integrated_original.nc')\n",
    "ds2 = xr.open_dataset('/data/ibougoudis/MOAD/files/external_inputs.nc')\n",
    "\n",
    "ds = ds.isel(time_counter = (np.arange(0, len(ds.time_counter),2)), \n",
    "    y=(np.arange(ds.y[0], ds.y[-1], 5)), \n",
    "    x=(np.arange(ds.x[0], ds.x[-1], 5)))\n",
    "\n",
    "ds2 = ds2.isel(time_counter = (np.arange(0, len(ds2.time_counter),2)), \n",
    "    y=(np.arange(ds2.y[0], ds2.y[-1], 5)), \n",
    "    x=(np.arange(ds2.x[0], ds2.x[-1], 5)))\n",
    "\n",
    "dataset = ds.sel(time_counter = slice('2007', '2020'))\n",
    "dataset2 = ds2.sel(time_counter = slice('2007', '2020'))\n",
    "\n",
    "inputs, targets, _ = datasets_preparation(dataset, dataset2, 'Diatom_Production_Rate')\n",
    "\n",
    "regr = regressor(inputs, targets, 'Diatom_Production_Rate')\n",
    "# evaluation(ds,ds2,regr,name,table,1)\n",
    "\n",
    "# regr2 = regressor2(inputs, targets, table)\n",
    "# evaluation(ds,ds2,regr2,name,table,4)\n",
    "\n",
    "test = cross_val_predict(regr,inputs,targets,cv=4)\n",
    "scores = cross_validate(regr, inputs, targets, cv=4, scoring=('r2', 'neg_root_mean_squared_error'), return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([28.00581884, 27.50227785, 31.47984838, 15.18430567]),\n",
       " 'score_time': array([5.45695806, 5.44290614, 3.96375799, 5.62351942]),\n",
       " 'test_r2': array([0.76540508, 0.75882021, 0.70923635, 0.64670963]),\n",
       " 'train_r2': array([0.89467319, 0.89150881, 0.89964414, 0.90768806]),\n",
       " 'test_neg_root_mean_squared_error': array([-7.20394450e-07, -7.74626654e-07, -8.30629665e-07, -8.33086223e-07]),\n",
       " 'train_neg_root_mean_squared_error': array([-4.92702930e-07, -4.89198446e-07, -4.75879529e-07, -4.67593536e-07])}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8539627125646575"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.corrcoef(targets,test)[0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.23773701,  0.30103952,  0.18705661,  0.08482825, -0.10614982])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.726074190927017"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(scores['test_r2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = ['r','rms','slope']\n",
    "categories = ['training with 100%', 'testing', 'training with 75%', 'testing with 25%', 'testing']\n",
    "\n",
    "diat = np.zeros((len(criteria),len(categories)))\n",
    "flag = np.zeros((len(criteria),len(categories)))\n",
    "diat_pr = np.zeros((len(criteria),len(categories)))\n",
    "flag_pr = np.zeros((len(criteria),len(categories)))\n",
    "\n",
    "test = training('Diatom',diat)\n",
    "# training('Flagellate',flag)\n",
    "# training('Diatom_Production_Rate',diat_pr)\n",
    "# training('Flagellate_Production_Rate',flag_pr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing (Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printing(diat,criteria, categories,'Diatom')\n",
    "printing(flag,criteria, categories,'Flagellate')\n",
    "printing(diat_pr,criteria, categories,'Diatom production rate')\n",
    "printing(flag_pr,criteria, categories, 'Flagellate production rate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis-ilias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
