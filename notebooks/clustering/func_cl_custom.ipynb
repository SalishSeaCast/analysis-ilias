{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Clustering (For custom variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from skfda.ml.clustering import KMeans\n",
    "from skfda.representation.grid import FDataGrid\n",
    "\n",
    "import salishsea_tools.viz_tools as sa_vi\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore') # For the nan mean warning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drivers Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drivers_preparation(dataset):\n",
    "\n",
    "    inputs = np.stack([\n",
    "        dataset['Summation_of_solar_radiation'].to_numpy().reshape(*dataset['Summation_of_solar_radiation'].to_numpy().shape[:1],-1),\n",
    "        dataset['Mean_wind_speed'].to_numpy().reshape(*dataset['Mean_wind_speed'].to_numpy().shape[:1],-1),\n",
    "        dataset['Mean_air_temperature'].to_numpy().reshape(*dataset['Mean_air_temperature'].to_numpy().shape[:1],-1)\n",
    "        ])\n",
    "    \n",
    "    targets = dataset['Diatom'].to_numpy().reshape(*dataset['Summation_of_solar_radiation'].to_numpy().shape[:1],-1)\n",
    "\n",
    "    # Splitting in years\n",
    "    inputs = np.split(inputs,len(np.unique(dataset.time_counter.dt.year)),axis=1)\n",
    "    targets = np.split(targets,len(np.unique(dataset.time_counter.dt.year)),axis=0)\n",
    "\n",
    "    # Means\n",
    "    inputs = np.nanmean(inputs,axis=0)\n",
    "    targets = np.nanmean(targets,axis=0)\n",
    "\n",
    "    x =  np.tile(dataset.x, len(dataset.y))\n",
    "    y =  np.tile(np.repeat(dataset.y, len(dataset.x)),1)\n",
    "\n",
    "    indx = np.where((~np.isnan(targets).any(axis=0))& (x>10) & ((x>100) | (y<880))) # Target goes down to 100m\n",
    "    inputs = inputs[:,:,indx[0]]\n",
    "\n",
    "    # Scaling the inputs\n",
    "    temp = np.reshape(inputs,(len(inputs),inputs.shape[1]*inputs.shape[2]))\n",
    "    temp = temp.transpose()\n",
    "    scaler_inputs = make_column_transformer((MinMaxScaler(), [0,1,2]))\n",
    "    temp = scaler_inputs.fit_transform(temp)\n",
    "    temp = temp.transpose()\n",
    "    inputs = np.reshape(temp,(len(inputs),inputs.shape[1],inputs.shape[2])) \n",
    "\n",
    "    # Converting it to an appropriate format for functional clustering\n",
    "    inputs = np.transpose(inputs,axes=(2,1,0))\n",
    "    inputs2 = FDataGrid(inputs, np.arange(0,len(inputs[0])))\n",
    "\n",
    "    return(inputs2,indx)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targets Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def targets_preparation(dataset, name):\n",
    "    \n",
    "    targets = name.to_numpy().reshape(*name.to_numpy().shape[:1],-1)\n",
    "\n",
    "    # Splitting in years\n",
    "    targets = np.split(targets,len(np.unique(name.time_counter.dt.year)),axis=0)\n",
    "\n",
    "    # Means\n",
    "    targets = np.nanmean(targets,axis=0)\n",
    "\n",
    "    x =  np.tile(dataset.x, len(dataset.y))\n",
    "    y =  np.tile(np.repeat(dataset.y, len(dataset.x)),1)\n",
    "\n",
    "    indx = np.where((~np.isnan(targets).any(axis=0)) & (x>10) & ((x>100) | (y<880)))\n",
    "    targets = targets[:,indx[0]]\n",
    "\n",
    "    # Converting it to an appropriate format for functional clustering\n",
    "    targets = targets.transpose()\n",
    "    targets2 = FDataGrid(targets,np.arange(0,len(targets[0])))\n",
    "\n",
    "    return(targets2,indx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting (All Years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_all(name,clusters,unique,cluster_mean,counts,ind_cluster):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize =(5,9))\n",
    "    cmap = plt.get_cmap('tab20', unique.max()+1)\n",
    "    cmap.set_bad('gray')\n",
    "    clus = clusters.plot(ax=ax, cmap=cmap, vmin = unique.min(), vmax = unique.max()+1, add_colorbar=False)\n",
    "    cbar = fig.colorbar(clus, ticks = unique+0.5) \n",
    "    cbar.set_ticklabels(unique+1)\n",
    "    cbar.set_label('Clusters [count]')\n",
    "    ax.set_title('Functional Clustering for '+ name + ' (2007-2024)')\n",
    "    sa_vi.set_aspect(ax)\n",
    "    plt.show()\n",
    "\n",
    "    if name == 'drivers':\n",
    "        temp = np.vstack((counts,cluster_mean.transpose()))\n",
    "        temp = temp.reshape(4,len(unique))\n",
    "        temp = pd.DataFrame(temp.transpose(),columns=['counts','Summation of solar radiation', 'Mean wind speed', 'Mean Temperature'],index=unique+1)\n",
    "    else:\n",
    "        temp = np.concatenate((counts,cluster_mean))\n",
    "        temp = temp.reshape(2,len(unique))\n",
    "        temp = pd.DataFrame(temp.transpose(),columns=['counts','mean'],index=unique+1)\n",
    "    temp.index.name = 'Cluster'\n",
    "    temp['counts'] = temp['counts'].astype('Int64')\n",
    "\n",
    "    display(temp.transpose())\n",
    "\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(10, 15), layout='constrained')\n",
    "    axs[0, 0].plot(ind_cluster[0])\n",
    "    axs[0, 0].set_title('Cluster 1')\n",
    "\n",
    "    axs[0, 1].plot(ind_cluster[1])\n",
    "    axs[0, 1].set_title('Cluster 2')\n",
    "\n",
    "    axs[1, 0].plot(ind_cluster[2])\n",
    "    axs[1, 0].set_title('Cluster 3')\n",
    "\n",
    "    axs[1, 1].plot(ind_cluster[3])\n",
    "    axs[1, 1].set_title('Cluster 4')\n",
    "\n",
    "    axs[2, 0].plot(ind_cluster[4])\n",
    "    axs[2, 0].set_title('Cluster 5')\n",
    "    \n",
    "    axs[2, 1].plot(ind_cluster[5])\n",
    "    axs[2, 1].set_title('Cluster 6')\n",
    "\n",
    "    if name == 'drivers':\n",
    "        fig.legend(['Summation of solar radiation', 'Mean wind speed', 'Mean Temperature'], bbox_to_anchor=(1, 1), loc='center left')\n",
    "        \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(dataset,quant,indx,name):\n",
    "\n",
    "    # Training\n",
    "    kmeans = KMeans(n_clusters=6)\n",
    "    clusters = kmeans.fit_predict(quant)\n",
    "\n",
    "    # Sorting so that cluster 1 has the minimum mean target value, 6 the maximum\n",
    "\n",
    "        # Finding the mean of each cluster\n",
    "    if name == 'drivers':\n",
    "        cluster_mean_all = np.mean(kmeans.cluster_centers_.data_matrix,axis=1)\n",
    "        cluster_mean = cluster_mean_all[:,0]  # Sorted based on the first input\n",
    "    else:\n",
    "        cluster_mean = np.squeeze(np.mean(kmeans.cluster_centers_.data_matrix,axis=1))\n",
    "\n",
    "        # The index to sort the clusters\n",
    "    indx3 = np.argsort(np.argsort(cluster_mean)) # For the complete map we need the double np.argsort\n",
    "\n",
    "        # Sorting\n",
    "    for j in np.arange(0,len(np.unique(clusters))):\n",
    "        clusters = xr.where(kmeans.labels_==j, indx3[j], clusters)\n",
    "\n",
    "    unique, counts = np.unique(clusters, return_counts=True)\n",
    "    \n",
    "    # Creating the map\n",
    "    indx2 = np.full(len(dataset.y) * len(dataset.x),np.nan)\n",
    "    indx2[indx[0]] = clusters\n",
    "    clusters = np.reshape(indx2,(len(dataset.y),len(dataset.x))) \n",
    "    clusters2 = xr.DataArray(clusters,dims = ['y','x'])\n",
    "\n",
    "    # Obtaining & sorting the individual clusters\n",
    "    if name == 'drivers':\n",
    "        ind_cluster = kmeans.cluster_centers_.data_matrix[np.argsort(indx3)]\n",
    "    else:\n",
    "        ind_cluster = kmeans.cluster_centers_.data_matrix[np.argsort(indx3)]\n",
    "\n",
    "    # Sorting the mean values\n",
    "    if name == 'drivers':\n",
    "        cluster_mean = cluster_mean_all[np.argsort(cluster_mean)]\n",
    "    else:\n",
    "        cluster_mean = cluster_mean[np.argsort(cluster_mean)]\n",
    "\n",
    "    # cluster_mean = np.round(cluster_mean,3)\n",
    "\n",
    "    return(clusters2,unique,cluster_mean,counts,ind_cluster)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting (Clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_clusters(name,years,unique,clusters_mean,clusters_indiv,counts):\n",
    "\n",
    "    years2 = np.append(years,'2007-2024')\n",
    "    for i in unique:\n",
    "\n",
    "        if name == 'drivers':\n",
    "            temp = np.vstack((counts[:,i],clusters_mean[:,i,:].transpose()))\n",
    "            temp = temp.reshape(4,len(years2))\n",
    "            temp = pd.DataFrame(temp.transpose(),columns=['counts','Summation of solar radiation', 'Mean wind speed', 'Mean Temperature'],index=years2)\n",
    "        else:\n",
    "            temp = np.concatenate((counts[:,i],clusters_mean[:,i]))\n",
    "            temp = temp.reshape(2,len(years2))\n",
    "            temp = pd.DataFrame(temp.transpose(),columns=['counts','mean'],index=years2)\n",
    "            \n",
    "        temp.index.name = 'Year'\n",
    "        print ('Cluster '+ str(i+1))\n",
    "        temp['counts'] = temp['counts'].astype('Int64')\n",
    "        display(temp.transpose())\n",
    "\n",
    "        k,l = 0,0\n",
    "        fig, ax = plt.subplots(5, 4, figsize=(10, 15), layout='constrained')\n",
    "\n",
    "        for j in np.arange (0,len(years)):\n",
    "\n",
    "            if name == 'drivers':\n",
    "                ax[k, l].plot(clusters_indiv[j,:,i,:])\n",
    "                ax[k,l].set_ylim([np.min(clusters_indiv[:,:,i,:]) - 0.05*np.min(clusters_indiv[:,:,i,:]), np.max(clusters_indiv[:,:,i,:])+ 0.05*np.max(clusters_indiv[:,:,i,:])])\n",
    "            else:\n",
    "                ax[k, l].plot(clusters_indiv[:,j,i])\n",
    "                ax[k,l].set_ylim([np.min(clusters_indiv[:,:,i]) - 0.05*np.min(clusters_indiv[:,:,i]), np.max(clusters_indiv[:,:,i])+ 0.05*np.max(clusters_indiv[:,:,i])])\n",
    "            ax[k, l].set_title(str(years[j]))\n",
    "\n",
    "            l=l+1\n",
    "            if l==4:\n",
    "                l=0\n",
    "                k=k+1\n",
    "\n",
    "        ax[4,2].axis('off')\n",
    "        if name == 'drivers':\n",
    "            ax[4,3].plot(clusters_indiv[-1,:,i,:])\n",
    "            ax[4,3].set_ylim([np.min(clusters_indiv[:,:,i,:]) - 0.05*np.min(clusters_indiv[:,:,i,:]), np.max(clusters_indiv[:,:,i,:])+ 0.05*np.max(clusters_indiv[:,:,i,:])])\n",
    "            fig.legend(['Summation of solar radiation', 'Mean wind speed', 'Mean Temperature'], bbox_to_anchor=(1, 1), loc='center left')\n",
    "        else:\n",
    "            ax[4,3].plot(clusters_indiv[:,-1,i])\n",
    "            ax[4,3].set_ylim([np.min(clusters_indiv[:,:,i]) - 0.05*np.min(clusters_indiv[:,:,i]), np.max(clusters_indiv[:,:,i])+ 0.05*np.max(clusters_indiv[:,:,i])])\n",
    "        ax[4,3].set_title('2007-2024')  \n",
    "        fig.suptitle('Cluster '+ str(i+1))        \n",
    "                     \n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting (Maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_maps(name,years,unique,clusters):\n",
    "\n",
    "    fig, ax = plt.subplots(5, 4, figsize=(10, 22))\n",
    "\n",
    "    cmap = plt.get_cmap('tab20', unique.max()+1)\n",
    "    cmap.set_bad('gray')\n",
    "\n",
    "    k, l = 0, 0\n",
    "\n",
    "    for j in np.arange (0,len(years)):\n",
    "\n",
    "        clus = clusters[j].plot(ax=ax[k,l], cmap=cmap, vmin = unique.min(), vmax = unique.max()+1, add_colorbar=False)\n",
    "        ax[k,l].set_title(str(years[j]))\n",
    "\n",
    "        sa_vi.set_aspect(ax[k,l])\n",
    "\n",
    "        l=l+1\n",
    "        if l==4:\n",
    "\n",
    "            cbar = fig.colorbar(clus, ticks=unique+0.5, pad=0.08) \n",
    "            cbar.set_ticklabels(unique+1)\n",
    "            cbar.set_label('Clusters [count]')\n",
    "            l=0\n",
    "            k=k+1\n",
    "\n",
    "    ax[4,2].axis('off')\n",
    "\n",
    "    clus = clusters[-1].plot(ax=ax[4,3], cmap=cmap, vmin = unique.min(), vmax = unique.max()+1, add_colorbar=False)\n",
    "    cbar = fig.colorbar(clus, ticks=unique+0.5, pad=0.08) \n",
    "    cbar.set_ticklabels(unique+1)\n",
    "    cbar.set_label('Clusters [count]')\n",
    "    ax[4,3].set_title('2007-2024')\n",
    "    sa_vi.set_aspect(ax[4,3])\n",
    "\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    fig.suptitle('Functional Clustering for ' + str(name))\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drivers Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drivers_main(name, years, dataset, ds):\n",
    "     \n",
    "    drivers,indx = drivers_preparation(dataset)\n",
    "    clusters0, unique, clusters_mean0, counts0, clusters_indiv0 = clustering(dataset,drivers,indx,name)\n",
    "    plotting_all(name,clusters0,unique,clusters_mean0,counts0,clusters_indiv0)\n",
    "\n",
    "    clusters_indiv1 = np.zeros((clusters_indiv0.shape[2],clusters_indiv0.shape[1],len(years),len(unique))) \n",
    "\n",
    "    clusters_indiv2 = np.zeros((len(years),clusters_indiv0.shape[0],clusters_indiv0.shape[1],clusters_indiv0.shape[2])) \n",
    "    clusters2 =  np.zeros((len(years),clusters0.shape[0],clusters0.shape[1])) \n",
    "    counts2 = np.zeros((len(years),len(unique)))\n",
    "    clusters_mean2 = np.zeros((len(years),len(unique), clusters_mean0.shape[1]))\n",
    "\n",
    "    for i in range(0, len(years)):\n",
    "\n",
    "        dataset = ds.sel(time_counter = slice(str(years[i]), str(years[i])))\n",
    "        drivers, _ = drivers_preparation(dataset)\n",
    "\n",
    "        drivers1 = np.squeeze(drivers.data_matrix).transpose()\n",
    "        clusters1 = np.ravel(clusters0)[indx]\n",
    "\n",
    "        for j in unique:\n",
    "            temp = xr.where(clusters1==j, drivers1, np.nan)\n",
    "            clusters_indiv1[:,:,i,j] = np.nanmean(temp,axis=2)\n",
    "\n",
    "        clusters, _, clusters_mean, counts, clusters_indiv = clustering(dataset,drivers,indx,name) \n",
    "        clusters2[i,:,:] = clusters\n",
    "        clusters_mean2[i,:,:] = clusters_mean \n",
    "        counts2[i,:] = counts \n",
    "        clusters_indiv2[i,:,:,:] = clusters_indiv \n",
    "\n",
    "    clusters_mean1 = np.mean(clusters_indiv1,axis=1).transpose(1,2,0)\n",
    "    clusters_mean1 = np.round(np.append(clusters_mean1,np.expand_dims(clusters_mean0,0),axis=0),3)\n",
    "\n",
    "    clusters_indiv1 = clusters_indiv1.transpose(2,3,1,0)\n",
    "    clusters_indiv1 = np.append(clusters_indiv1,np.expand_dims(clusters_indiv0,0),axis=0).transpose(0,2,1,3)\n",
    "\n",
    "    clusters2 = xr.DataArray(clusters2,dims = ['years','y','x'])\n",
    "    clusters0 = xr.DataArray(clusters0,dims = ['y','x'])\n",
    "    clusters2 = xr.concat((clusters2,clusters0),'years')\n",
    "\n",
    "    clusters_mean2 = np.round(np.append(clusters_mean2,np.expand_dims(clusters_mean0,0),axis=0),3)\n",
    "    counts2 = np.append(counts2,np.expand_dims(counts0,0),axis=0)\n",
    "\n",
    "    clusters_indiv2 = np.append(clusters_indiv2,np.expand_dims(clusters_indiv0,0),axis=0).transpose(0,2,1,3)\n",
    "\n",
    "    return (name, years, unique, clusters_mean1, clusters_indiv1, counts0, clusters2, clusters_mean2, clusters_indiv2, counts2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targets Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def targets_main(name, years, dataset, ds):\n",
    "\n",
    "    targets,indx = targets_preparation(dataset,name)\n",
    "    clusters0, unique, clusters_mean0, counts0, clusters_indiv0 = clustering(dataset,targets,indx,name)\n",
    "    plotting_all(name,clusters0,unique,clusters_mean0,counts0,clusters_indiv0)\n",
    "\n",
    "    clusters_indiv1 = np.zeros((clusters_indiv0.shape[1],len(years),len(unique)))\n",
    "\n",
    "    clusters_indiv2 = np.zeros((clusters_indiv0.shape[1],len(years),len(unique))).transpose(2,0,1) \n",
    "    clusters2 =  np.zeros((len(years),clusters0.shape[0],clusters0.shape[1])) \n",
    "    counts2 = np.zeros((len(years),len(unique)))\n",
    "    clusters_mean2 = np.zeros((len(years),len(unique)))\n",
    "\n",
    "    for i in range(0, len(years)):\n",
    "\n",
    "        dataset = ds.sel(time_counter = slice(str(years[i]), str(years[i])))\n",
    "        targets, _ = targets_preparation(dataset,name)\n",
    "\n",
    "        targets1 = np.squeeze(targets.data_matrix).transpose()\n",
    "        clusters1 = np.ravel(clusters0)[indx]\n",
    "\n",
    "        for j in unique:\n",
    "            temp = xr.where(clusters1==j, targets1, np.nan)\n",
    "            clusters_indiv1[:,i,j] = np.nanmean(temp,axis=1)\n",
    "\n",
    "        clusters, _, clusters_mean, counts, clusters_indiv = clustering(dataset,targets,indx,name) \n",
    "        clusters_indiv = np.squeeze(clusters_indiv,2)\n",
    "        clusters2[i,:,:] = clusters\n",
    "        clusters_mean2[i,:] = clusters_mean \n",
    "        counts2[i,:] = counts \n",
    "        clusters_indiv2[:,:,i] = clusters_indiv \n",
    "\n",
    "    clusters_mean1 = np.mean(clusters_indiv1,axis=0)\n",
    "    clusters_mean1 = np.append(clusters_mean1,np.expand_dims(clusters_mean0,0),axis=0)\n",
    "    clusters_indiv1 = np.append(clusters_indiv1,clusters_indiv0.transpose(1,2,0),axis=1)\n",
    "\n",
    "    clusters2 = xr.DataArray(clusters2,dims = ['years','y','x'])\n",
    "    clusters0 = xr.DataArray(clusters0,dims = ['y','x'])\n",
    "\n",
    "    clusters2 = xr.concat((clusters2,clusters0),'years')\n",
    "\n",
    "    clusters_mean2 = np.append(clusters_mean2,np.expand_dims(clusters_mean0,0),axis=0)\n",
    "    counts2 = np.append(counts2,np.expand_dims(counts0,0),axis=0)\n",
    "    clusters_indiv2 = clusters_indiv2.transpose(1,2,0)\n",
    "    clusters_indiv2 = np.append(clusters_indiv2,clusters_indiv0.transpose(1,2,0),axis=1)\n",
    "\n",
    "    return (name, years, unique, clusters_mean1, clusters_indiv1, counts0, clusters2, clusters_mean2, clusters_indiv2, counts2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0 variables: Clustering with all years\n",
    "## 1 variables: Yearly clusters, based on all years clustering\n",
    "## 2 variables: Yearly clusters, based on yearly clustering\n",
    "\n",
    "ds = xr.open_dataset('/data/ibougoudis/MOAD/files/inputs/feb_apr.nc')\n",
    "\n",
    "# ds = ds.isel(\n",
    "#     y=(np.arange(ds.y[0], ds.y[-1], 5)), \n",
    "#     x=(np.arange(ds.x[0], ds.x[-1], 5)))\n",
    "\n",
    "dataset = ds.sel(time_counter = slice('2007', '2024'))\n",
    "years = np.unique(dataset.time_counter.dt.year)\n",
    "\n",
    "name = 'Z1_Diat / Sum_grazing'\n",
    "\n",
    "if 'Production' in name:\n",
    "    pd.set_option('display.float_format', '{:.2E}'.format) # Only for the production rates\n",
    "\n",
    "new = dataset['Z1_Diatom'] / (dataset['Z1_Diatom'] + dataset['Z1_Flagellate'] + dataset['Z1_Pon'] + dataset['Z1_Z1'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets,indx = targets_preparation(dataset,new)\n",
    "clusters0, unique, clusters_mean0, counts0, clusters_indiv0 = clustering(dataset,targets,indx,name)\n",
    "plotting_all(name,clusters0,unique,clusters_mean0,counts0,clusters_indiv0)\n",
    "\n",
    "clusters_indiv1 = np.zeros((clusters_indiv0.shape[1],len(years),len(unique)))\n",
    "\n",
    "clusters_indiv2 = np.zeros((clusters_indiv0.shape[1],len(years),len(unique))).transpose(2,0,1) \n",
    "clusters2 =  np.zeros((len(years),clusters0.shape[0],clusters0.shape[1])) \n",
    "counts2 = np.zeros((len(years),len(unique)))\n",
    "clusters_mean2 = np.zeros((len(years),len(unique)))\n",
    "\n",
    "for i in range(0, len(years)):\n",
    "\n",
    "    new2 = new.sel(time_counter = slice(str(years[i]), str(years[i])))\n",
    "    targets, indx = targets_preparation(dataset,new2)\n",
    "\n",
    "    targets1 = np.squeeze(targets.data_matrix).transpose()\n",
    "    clusters1 = np.ravel(clusters0)[indx]\n",
    "\n",
    "    for j in unique:\n",
    "        temp = xr.where(clusters1==j, targets1, np.nan)\n",
    "        clusters_indiv1[:,i,j] = np.nanmean(temp,axis=1)\n",
    "\n",
    "    clusters, _, clusters_mean, counts, clusters_indiv = clustering(dataset,targets,indx,name) \n",
    "    clusters_indiv = np.squeeze(clusters_indiv,2)\n",
    "    clusters2[i,:,:] = clusters\n",
    "    clusters_mean2[i,:] = clusters_mean \n",
    "    counts2[i,:] = counts \n",
    "    clusters_indiv2[:,:,i] = clusters_indiv \n",
    "\n",
    "clusters_mean1 = np.mean(clusters_indiv1,axis=0)\n",
    "clusters_mean1 = np.append(clusters_mean1,np.expand_dims(clusters_mean0,0),axis=0)\n",
    "clusters_indiv1 = np.append(clusters_indiv1,clusters_indiv0.transpose(1,2,0),axis=1)\n",
    "\n",
    "clusters2 = xr.DataArray(clusters2,dims = ['years','y','x'])\n",
    "clusters0 = xr.DataArray(clusters0,dims = ['y','x'])\n",
    "\n",
    "clusters2 = xr.concat((clusters2,clusters0),'years')\n",
    "\n",
    "clusters_mean2 = np.append(clusters_mean2,np.expand_dims(clusters_mean0,0),axis=0)\n",
    "counts2 = np.append(counts2,np.expand_dims(counts0,0),axis=0)\n",
    "clusters_indiv2 = clusters_indiv2.transpose(1,2,0)\n",
    "clusters_indiv2 = np.append(clusters_indiv2,clusters_indiv0.transpose(1,2,0),axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual clusters based on all-years clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_clusters(name,years,unique,clusters_mean1,clusters_indiv1,np.reshape(np.tile(counts0,len(years)+1),(len(years)+1,len(unique))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual clusters based on yearly clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_maps(name,years,unique,clusters2)\n",
    "plotting_clusters(name,years,unique,clusters_mean2,clusters_indiv2,counts2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis-ilias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
