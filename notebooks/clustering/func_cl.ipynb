{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for functional clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skfda.ml.clustering import KMeans\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "from skfda.representation.grid import FDataGrid\n",
    "from skfda.representation.basis import FourierBasis, VectorValuedBasis\n",
    "\n",
    "import salishsea_tools.viz_tools as sa_vi\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('/data/ibougoudis/MOAD/files/integrated_original.nc')\n",
    "ds2 = xr.open_dataset('/data/ibougoudis/MOAD/files/external_inputs.nc')\n",
    "\n",
    "# ds = ds.isel(time_counter = (np.arange(0, len(ds.time_counter),2)), \n",
    "#     y=(np.arange(ds.y[0], ds.y[-1], 5)), \n",
    "#     x=(np.arange(ds.x[0], ds.x[-1], 5)))\n",
    "\n",
    "# ds2 = ds2.isel(time_counter = (np.arange(0, len(ds2.time_counter),2)), \n",
    "#     y=(np.arange(ds2.y[0], ds2.y[-1], 5)), \n",
    "#     x=(np.arange(ds2.x[0], ds2.x[-1], 5)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_clust_drivers_all():\n",
    " \n",
    "    dataset = ds.sel(time_counter = slice('2007', '2020'))\n",
    "    dataset2 = ds2.sel(time_counter = slice('2007', '2020'))\n",
    "\n",
    "    input = np.stack([np.reshape(np.ravel(dataset['Temperature_(0m-15m)']), (len(dataset.time_counter), len(dataset.y) * len(dataset.x))),\n",
    "        np.reshape(np.ravel(dataset['Temperature_(15m-100m)']), (len(dataset.time_counter), len(dataset.y) * len(dataset.x))),\n",
    "        np.reshape(np.ravel(dataset['Salinity_(0m-15m)']), (len(dataset.time_counter), len(dataset.y) * len(dataset.x))),\n",
    "        np.reshape(np.ravel(dataset['Salinity_(15m-100m)']), (len(dataset.time_counter), len(dataset.y) * len(dataset.x))),\n",
    "        np.reshape(np.ravel(dataset2['Summation_of_solar_radiation']), (len(dataset.time_counter), len(dataset.y) * len(dataset.x))),\n",
    "        np.reshape(np.ravel(dataset2['Mean_wind_speed']), (len(dataset.time_counter), len(dataset.y) * len(dataset.x))),\n",
    "        np.reshape(np.ravel(dataset2['Mean_air_temperature']), (len(dataset.time_counter), len(dataset.y) * len(dataset.x))),\n",
    "        ])\n",
    "\n",
    "    x =  np.tile(dataset.x, len(dataset.y))\n",
    "    y =  np.tile(np.repeat(dataset.y, len(dataset.x)),1)\n",
    "\n",
    "    indx = np.where((~np.isnan(input[1]).any(axis=0)) & (x>10) & ((x>100) | (y<880))) # input[1] because this variable is down to 100m\n",
    "    input =input[:,:,indx[0]]\n",
    "\n",
    "    # Transforming each variable individually\n",
    "    # input[0] = minmax_scale(input[0])\n",
    "    # input[1] = minmax_scale(input[1])\n",
    "    # input[2] = minmax_scale(input[2])\n",
    "    # input[3] = minmax_scale(input[3])\n",
    "    # input[4] = minmax_scale(input[4])\n",
    "    # input[5] = minmax_scale(input[5])\n",
    "    # input[6] = minmax_scale(input[6])\n",
    "\n",
    "    # Converting it to an appropriate format for functional clustering\n",
    "    input = np.transpose(input,axes=(2,1,0)) # this is the right shape for converting it to a functional variable\n",
    "    input2 = FDataGrid(input, np.arange(0,len(dataset.time_counter)))\n",
    "\n",
    "    # Training\n",
    "    n_clusters = 6\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(input2)\n",
    "    clusters = kmeans.predict(input2)\n",
    "\n",
    "    # Sorting so that cluster 1 has the minimum mean target value, 6 the maximum\n",
    "\n",
    "    # Finding the mean of each cluster\n",
    "    a = []\n",
    "    for j in range (0,6):\n",
    "        a.append(np.mean(input[np.where(kmeans.labels_==j),:,0])) # We do the sorting based on Temperature_(0m-15m)\n",
    "\n",
    "    # The index to sort the clusters\n",
    "    indx3 = np.argsort(np.argsort(a)) # For the complete map we need the double np.argsort\n",
    "\n",
    "    # First fwe define all as the first cluster\n",
    "    clusters = xr.where(kmeans.labels_==0, indx3[0], kmeans.labels_)\n",
    "    # Then we overwrite the second to last\n",
    "    for j in np.arange(1,6):\n",
    "\n",
    "        clusters = xr.where(kmeans.labels_==j, indx3[j], clusters)\n",
    "\n",
    "    unique, counts = np.unique(clusters, return_counts=True)\n",
    "\n",
    "    # Creating the map\n",
    "    indx2 = np.full(len(dataset.y) * len(dataset.x),np.nan)\n",
    "    indx2[indx[0]] = clusters\n",
    "    clusters = np.reshape(indx2,(len(dataset.y),len(dataset.x))) \n",
    "\n",
    "    # Preparation of the dataarray \n",
    "    clusters2 = xr.DataArray(clusters,\n",
    "        coords = {'y': dataset.y, 'x': dataset.x},\n",
    "        dims = ['y','x'],\n",
    "        attrs=dict(description=\"Clusters of the performed functional analysis algorithm\",\n",
    "        long_name =\"Cluster\",\n",
    "        units=\"count\"))\n",
    "\n",
    "    # Printing\n",
    "    for j in range (1,7):\n",
    "        print('The amount of points for cluster ' + str(j) + ' is: ' + str(counts[j-1]))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize =(5,9))\n",
    "\n",
    "    cmap = plt.get_cmap('tab20', unique.max()+1)\n",
    "    cmap.set_bad('gray')\n",
    "    clus = clusters2.plot(ax=ax, cmap=cmap, vmin = unique.min(), vmax = unique.max()+1, add_colorbar=False)\n",
    "\n",
    "    cbar = fig.colorbar(clus, ticks = unique+0.5) \n",
    "    cbar.set_ticklabels(unique+1)\n",
    "    cbar.set_label('Clusters [count]')\n",
    "    ax.set_title('Functional Clustering during 2007-2020 for Drivers')\n",
    "\n",
    "    sa_vi.set_aspect(ax)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Creating the individual clusters\n",
    "    basis_x = FourierBasis(domain_range=(0, len(dataset.time_counter)),n_basis=10)\n",
    "\n",
    "    basis = VectorValuedBasis(np.repeat(basis_x,7))\n",
    "\n",
    "    x = kmeans.cluster_centers_.to_basis(basis)\n",
    "    y = np.array(x.to_grid(np.arange(0,len(dataset.time_counter))).data_matrix)\n",
    "\n",
    "    indx3 = np.argsort(a) # For the individual maps we need a single np.argsort\n",
    "\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "    axs[0, 0].plot(y[indx3[0]])\n",
    "    axs[0, 0].set_title('Cluster 1')\n",
    "\n",
    "    axs[0, 1].plot(y[indx3[1]])\n",
    "    axs[0, 1].set_title('Cluster 2')\n",
    "\n",
    "    axs[1, 0].plot(y[indx3[2]])\n",
    "    axs[1, 0].set_title('Cluster 3')\n",
    "\n",
    "    axs[1, 1].plot(y[indx3[3]])\n",
    "    axs[1, 1].set_title('Cluster 4')\n",
    "\n",
    "    axs[2, 0].plot(y[indx3[4]])\n",
    "    axs[2, 0].set_title('Cluster 5')\n",
    "\n",
    "    axs[2, 1].plot(y[indx3[5]])\n",
    "    axs[2, 1].set_title('Cluster 6')\n",
    "\n",
    "    fig.legend(('Temperature_(0m-15m)','Temperature_(15m-100m)','Salinity_(0m-15m)',\n",
    "        'Salinity_(15m-100m)','Summation_of_solar_radiation',\n",
    "        'Mean_wind_speed','Mean_air_temperature'),loc=9)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_clust_drivers():\n",
    "\n",
    "    all = []\n",
    "    cluster1 = []\n",
    "    cluster2 = []\n",
    "    cluster3 = []\n",
    "    cluster4 = []\n",
    "    cluster5 = []\n",
    "    cluster6 = []\n",
    "    counts_all = []\n",
    "\n",
    "    for i in tqdm(np.arange(2007,2025)):\n",
    "    \n",
    "        dataset = ds.sel(time_counter = slice(str(i), str(i)))\n",
    "        dataset2 = ds2.sel(time_counter = slice(str(i), str(i)))\n",
    "\n",
    "        input = np.stack([np.reshape(np.ravel(dataset['Temperature_(0m-15m)']), (len(dataset.time_counter), len(dataset.y) * len(dataset.x))),\n",
    "            np.reshape(np.ravel(dataset['Temperature_(15m-100m)']), (len(dataset.time_counter), len(dataset.y) * len(dataset.x))),\n",
    "            np.reshape(np.ravel(dataset['Salinity_(0m-15m)']), (len(dataset.time_counter), len(dataset.y) * len(dataset.x))),\n",
    "            np.reshape(np.ravel(dataset['Salinity_(15m-100m)']), (len(dataset.time_counter), len(dataset.y) * len(dataset.x))),\n",
    "            np.reshape(np.ravel(dataset2['Summation_of_solar_radiation']), (len(dataset.time_counter), len(dataset.y) * len(dataset.x))),\n",
    "            np.reshape(np.ravel(dataset2['Mean_wind_speed']), (len(dataset.time_counter), len(dataset.y) * len(dataset.x))),\n",
    "            np.reshape(np.ravel(dataset2['Mean_air_temperature']), (len(dataset.time_counter), len(dataset.y) * len(dataset.x))),\n",
    "            ])\n",
    "\n",
    "        x =  np.tile(dataset.x, len(dataset.y))\n",
    "        y =  np.tile(np.repeat(dataset.y, len(dataset.x)),1)\n",
    "\n",
    "        indx = np.where((~np.isnan(input[1]).any(axis=0)) & (x>10) & ((x>100) | (y<880))) # input[1] because this variable is down to 100m\n",
    "        input =input[:,:,indx[0]]\n",
    "\n",
    "        # Transforming each variable individually\n",
    "        # input[0] = minmax_scale(input[0])\n",
    "        # input[1] = minmax_scale(input[1])\n",
    "        # input[2] = minmax_scale(input[2])\n",
    "        # input[3] = minmax_scale(input[3])\n",
    "        # input[4] = minmax_scale(input[4])\n",
    "        # input[5] = minmax_scale(input[5])\n",
    "        # input[6] = minmax_scale(input[6])\n",
    "\n",
    "        # Converting it to an appropriate format for functional clustering\n",
    "        input = np.transpose(input,axes=(2,1,0)) # this is the right shape for converting it to a functional variable\n",
    "        input2 = FDataGrid(input, np.arange(0,len(dataset.time_counter)))\n",
    "\n",
    "        # Training\n",
    "        n_clusters = 6\n",
    "        kmeans = KMeans(n_clusters=n_clusters)\n",
    "        kmeans.fit(input2)\n",
    "        clusters = kmeans.predict(input2)\n",
    "\n",
    "        # Sorting so that cluster 1 has the minimum mean target value, 6 the maximum\n",
    "\n",
    "        # Finding the mean of each cluster\n",
    "        a = []\n",
    "        for j in range (0,6):\n",
    "            a.append(np.mean(input[np.where(kmeans.labels_==j),:,0])) # We do the sorting based on Temperature_(0m-15m)\n",
    "\n",
    "        # The index to sort the clusters\n",
    "        indx3 = np.argsort(np.argsort(a)) # For the complete map we need the double np.argsort\n",
    "\n",
    "        # First fwe define all as the first cluster\n",
    "        clusters = xr.where(kmeans.labels_==0, indx3[0], kmeans.labels_)\n",
    "        # Then we overwrite the second to last\n",
    "        for j in np.arange(1,6):\n",
    "\n",
    "            clusters = xr.where(kmeans.labels_==j, indx3[j], clusters)\n",
    "        \n",
    "        unique, counts = np.unique(clusters, return_counts=True)\n",
    "\n",
    "        # Creating the map\n",
    "        indx2 = np.full(len(dataset.y) * len(dataset.x),np.nan)\n",
    "        indx2[indx[0]] = clusters\n",
    "        clusters = np.reshape(indx2,(len(dataset.y),len(dataset.x))) \n",
    "\n",
    "        # Preparation of the dataarray \n",
    "        clusters2 = xr.DataArray(clusters,\n",
    "            coords = {'y': dataset.y, 'x': dataset.x},\n",
    "            dims = ['y','x'],\n",
    "            attrs=dict(description=\"Clusters of the performed functional analysis algorithm\",\n",
    "            long_name =\"Cluster\",\n",
    "            units=\"count\"))\n",
    "        \n",
    "        all.append(clusters2)\n",
    "\n",
    "        counts_all.append(counts)\n",
    "\n",
    "        # Creating the individual clusters\n",
    "        basis_x = FourierBasis(domain_range=(0, len(dataset.time_counter)),n_basis=10)\n",
    "\n",
    "        basis = VectorValuedBasis(np.repeat(basis_x,7))\n",
    "\n",
    "        x = kmeans.cluster_centers_.to_basis(basis)\n",
    "        y = np.array(x.to_grid(np.arange(0,len(dataset.time_counter))).data_matrix)\n",
    "\n",
    "        indx3 = np.argsort(a) # For the individual maps we need a single np.argsort\n",
    "\n",
    "        cluster1.append(y[indx3[0]])\n",
    "        cluster2.append(y[indx3[1]])\n",
    "        cluster3.append(y[indx3[2]])\n",
    "        cluster4.append(y[indx3[3]])\n",
    "        cluster5.append(y[indx3[4]])\n",
    "        cluster6.append(y[indx3[5]])\n",
    "\n",
    "    return (all,cluster1,cluster2,cluster3,cluster4,cluster5,cluster6,counts_all,unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_clust_target_all():\n",
    "\n",
    "    names = ['Diatom', 'Flagellate', 'Diatom_Production_Rate', 'Flagellate_Production_Rate']\n",
    "    for name in names:\n",
    "\n",
    "        dataset = ds.sel(time_counter = slice('2007', '2020'))\n",
    "\n",
    "        input = np.reshape(np.ravel(dataset[name]), (len(dataset.time_counter), len(dataset.y) * len(dataset.x)))\n",
    "\n",
    "        x =  np.tile(dataset.x, len(dataset.y))\n",
    "        y =  np.tile(np.repeat(dataset.y, len(dataset.x)),1)\n",
    "\n",
    "        indx = np.where((~np.isnan(input).any(axis=0)) & (x>10) & ((x>100) | (y<880)))\n",
    "        input = input[:, indx[0]]\n",
    "\n",
    "        # input = minmax_scale(input)\n",
    "        input = input.transpose()\n",
    "\n",
    "        # Converting it to an appropriate format for functional clustering\n",
    "        input2 = FDataGrid(input, np.arange(0,len(dataset.time_counter)))\n",
    "\n",
    "        # Training\n",
    "        n_clusters = 6\n",
    "        kmeans = KMeans(n_clusters=n_clusters)\n",
    "        kmeans.fit(input2)\n",
    "        clusters = kmeans.predict(input2)\n",
    "\n",
    "        # Sorting so that cluster 1 has the minimum mean target value, 6 the maximum\n",
    "\n",
    "        # Finding the mean of each cluster\n",
    "        a = []\n",
    "        for j in range (0,6):\n",
    "            a.append(np.mean(input[np.where(kmeans.labels_==j)]))\n",
    "\n",
    "        # The index to sort the clusters\n",
    "        indx3 = np.argsort(np.argsort(a)) # For the complete map we need the double np.argsort\n",
    "\n",
    "        # First we define all as the first cluster\n",
    "        clusters = xr.where(kmeans.labels_==0, indx3[0], kmeans.labels_)\n",
    "        # Then we overwrite the second to last\n",
    "        for j in np.arange(1,6):\n",
    "\n",
    "            clusters = xr.where(kmeans.labels_==j, indx3[j], clusters)\n",
    "\n",
    "        unique, counts = np.unique(clusters, return_counts=True)\n",
    "        \n",
    "        # Creating the map\n",
    "        indx2 = np.full(len(dataset.y) * len(dataset.x),np.nan)\n",
    "        indx2[indx[0]] = clusters\n",
    "        clusters = np.reshape(indx2,(len(dataset.y),len(dataset.x))) \n",
    "\n",
    "        # Preparation of the dataarray \n",
    "        clusters2 = xr.DataArray(clusters,\n",
    "            coords = {'y': dataset.y, 'x': dataset.x},\n",
    "            dims = ['y','x'],\n",
    "            attrs=dict(description=\"Clusters of the performed functional analysis algorithm\",\n",
    "            long_name =\"Cluster\",\n",
    "            units=\"count\"))\n",
    "\n",
    "        # Printing\n",
    "        for j in range (1,7):\n",
    "            print('The amount of points for cluster '+str(j)+' is: '+str(counts[j-1])+' with a mean of: '+str(np.round(np.mean(a[np.argsort(a)[j-1]]),3)))\n",
    "        \n",
    "        # Plotting\n",
    "        fig, ax = plt.subplots(figsize =(5,9))\n",
    "\n",
    "        cmap = plt.get_cmap('tab20', unique.max()+1)\n",
    "        cmap.set_bad('gray')\n",
    "        clus = clusters2.plot(ax=ax, cmap=cmap, vmin = unique.min(), vmax = unique.max()+1, add_colorbar=False)\n",
    "\n",
    "        cbar = fig.colorbar(clus, ticks = unique+0.5) \n",
    "        cbar.set_ticklabels(unique+1)\n",
    "        cbar.set_label('Clusters [count]')\n",
    "        ax.set_title('Functional Clustering during 2007-2020 for '+ name)\n",
    "\n",
    "        sa_vi.set_aspect(ax)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        # Creating the individual clusters\n",
    "        y = np.array(kmeans.cluster_centers_.to_grid().data_matrix)\n",
    "\n",
    "        indx3 = np.argsort(a) # For the individual maps we need a single np.argsort\n",
    "\n",
    "        fig, axs = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "        axs[0, 0].plot(y[indx3[0]])\n",
    "        axs[0, 0].set_title('Cluster 1')\n",
    "\n",
    "        axs[0, 1].plot(y[indx3[1]])\n",
    "        axs[0, 1].set_title('Cluster 2')\n",
    "\n",
    "        axs[1, 0].plot(y[indx3[2]])\n",
    "        axs[1, 0].set_title('Cluster 3')\n",
    "\n",
    "        axs[1, 1].plot(y[indx3[3]])\n",
    "        axs[1, 1].set_title('Cluster 4')\n",
    "\n",
    "        axs[2, 0].plot(y[indx3[4]])\n",
    "        axs[2, 0].set_title('Cluster 5')\n",
    "\n",
    "        axs[2, 1].plot(y[indx3[5]])\n",
    "        axs[2, 1].set_title('Cluster 6')\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_clust_target(name):\n",
    "\n",
    "    all = []\n",
    "    cluster1 = []\n",
    "    cluster2 = []\n",
    "    cluster3 = []\n",
    "    cluster4 = []\n",
    "    cluster5 = []\n",
    "    cluster6 = []\n",
    "    counts_all = []\n",
    "\n",
    "    for i in tqdm(np.arange(2007,2025)):\n",
    "\n",
    "        dataset = ds.sel(time_counter = slice(str(i), str(i)))\n",
    "        \n",
    "        input = np.reshape(np.ravel(dataset[name]), (len(dataset.time_counter), len(dataset.y) * len(dataset.x)))\n",
    "\n",
    "        x =  np.tile(dataset.x, len(dataset.y))\n",
    "        y =  np.tile(np.repeat(dataset.y, len(dataset.x)),1)\n",
    "\n",
    "        indx = np.where((~np.isnan(input).any(axis=0)) & (x>10) & ((x>100) | (y<880)))\n",
    "        input = input[:, indx[0]]\n",
    "\n",
    "        # input = minmax_scale(input)\n",
    "        input = input.transpose()\n",
    "\n",
    "        # Converting it to an appropriate format for functional clustering\n",
    "        input2 = FDataGrid(input, np.arange(0,len(dataset.time_counter)))\n",
    "\n",
    "        # Training\n",
    "        n_clusters = 6\n",
    "        kmeans = KMeans(n_clusters=n_clusters)\n",
    "        kmeans.fit(input2)\n",
    "        clusters = kmeans.predict(input2)\n",
    "\n",
    "        # Sorting so that cluster 1 has the minimum mean target value, 6 the maximum\n",
    "\n",
    "        # Finding the mean of each cluster\n",
    "        a = []\n",
    "        for j in range (0,6):\n",
    "            a.append(np.mean(input[np.where(kmeans.labels_==j)]))\n",
    "\n",
    "        # The index to sort the clusters\n",
    "        indx3 = np.argsort(np.argsort(a)) # For the complete map we need the double np.argsort\n",
    "\n",
    "        # First we define all as the first cluster\n",
    "        clusters = xr.where(kmeans.labels_==0, indx3[0], kmeans.labels_)\n",
    "        # Then we overwrite the second to last\n",
    "        for j in np.arange(1,6):\n",
    "\n",
    "            clusters = xr.where(kmeans.labels_==j, indx3[j], clusters)\n",
    "\n",
    "        unique, counts = np.unique(clusters, return_counts=True)\n",
    "        \n",
    "        # Creating the map\n",
    "        indx2 = np.full(len(dataset.y) * len(dataset.x),np.nan)\n",
    "        indx2[indx[0]] = clusters\n",
    "        clusters = np.reshape(indx2,(len(dataset.y),len(dataset.x))) \n",
    "\n",
    "        # Preparation of the dataarray \n",
    "        clusters2 = xr.DataArray(clusters,\n",
    "            coords = {'y': dataset.y, 'x': dataset.x},\n",
    "            dims = ['y','x'],\n",
    "            attrs=dict(description=\"Clusters of the performed functional analysis algorithm\",\n",
    "            long_name =\"Cluster\",\n",
    "            units=\"count\"))\n",
    "\n",
    "        all.append(clusters2)\n",
    "        counts_all.append(counts)\n",
    "        \n",
    "        # Creating the individual clusters\n",
    "        y = np.array(kmeans.cluster_centers_.to_grid().data_matrix)\n",
    "        \n",
    "        indx3 = np.argsort(a) # For the individual maps we need a single np.argsort\n",
    "\n",
    "        cluster1.append(y[indx3[0]])\n",
    "        cluster2.append(y[indx3[1]])\n",
    "        cluster3.append(y[indx3[2]])\n",
    "        cluster4.append(y[indx3[3]])\n",
    "        cluster5.append(y[indx3[4]])\n",
    "        cluster6.append(y[indx3[5]])\n",
    "\n",
    "    return (all,cluster1,cluster2,cluster3,cluster4,cluster5,cluster6,counts_all,unique)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_drivers(clusters,clusters_ind,unique,counts_all):\n",
    "    \n",
    "    years = np.arange(2007,2025)\n",
    "\n",
    "    fig, ax = plt.subplots(5, 4, figsize=(10, 15))\n",
    "\n",
    "    cmap = plt.get_cmap('tab20', unique.max()+1)\n",
    "    cmap.set_bad('gray')\n",
    "\n",
    "    k=0\n",
    "    l=0\n",
    "\n",
    "    for j in np.arange (0,len(years)):\n",
    "\n",
    "        clus = clusters[j].plot(ax=ax[k,l], cmap=cmap, vmin = unique.min(), vmax = unique.max()+1, add_colorbar=False)\n",
    "\n",
    "        cbar = fig.colorbar(clus, ticks=unique+0.5, fraction=0.08, pad=0.08) \n",
    "        cbar.set_ticklabels(unique+1)\n",
    "        # cbar.set_label('Clusters [count]')\n",
    "        ax[k,l].set_title(str(years[j]))\n",
    "\n",
    "        sa_vi.set_aspect(ax[k,l])\n",
    "\n",
    "        l=l+1\n",
    "\n",
    "        if l==4:\n",
    "            l=0\n",
    "            k=k+1\n",
    "\n",
    "        # Printing\n",
    "        for i in unique:\n",
    "            print('The amount of points for cluster '+ str(i+1)+' for year '+str(years[j])+' is: '+str(counts_all[j][i]))\n",
    "        print('\\n')\n",
    "\n",
    "    ax[4,2].axis('off')\n",
    "    ax[4,3].axis('off')\n",
    "\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    fig.suptitle('Functional Clustering for Drivers')\n",
    "    plt.show()\n",
    "\n",
    "    for i in unique:\n",
    "\n",
    "        k=0\n",
    "        l=0\n",
    "\n",
    "        fig, ax = plt.subplots(5, 4, figsize=(10, 15))\n",
    "\n",
    "        for j in np.arange (0,len(years)):\n",
    "    \n",
    "            ax[k, l].plot(clusters_ind[i][j])\n",
    "            ax[k, l].set_title(str(years[j]))\n",
    "\n",
    "            l=l+1\n",
    "\n",
    "            if l==4:\n",
    "                l=0\n",
    "                k=k+1\n",
    "\n",
    "        ax[4,2].axis('off')\n",
    "        ax[4,3].axis('off')\n",
    "\n",
    "        fig.legend(('Temperature_(0m-15m)','Temperature_(15m-100m)','Salinity_(0m-15m)',\n",
    "        'Salinity_(15m-100m)','Summation_of_solar_radiation',\n",
    "        'Mean_wind_speed','Mean_air_temperature'),loc=4)\n",
    "\n",
    "        fig.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "        fig.suptitle('Cluster '+ str(i+1))\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_targets(name,clusters,clusters_ind,unique,counts_all):\n",
    "    \n",
    "    years = np.arange(2007,2025)\n",
    "\n",
    "    fig, ax = plt.subplots(5, 4, figsize=(10, 15))\n",
    "\n",
    "    cmap = plt.get_cmap('tab20', unique.max()+1)\n",
    "    cmap.set_bad('gray')\n",
    "\n",
    "    k=0\n",
    "    l=0\n",
    "\n",
    "    for j in np.arange (0,len(years)):\n",
    "\n",
    "        clus = clusters[j].plot(ax=ax[k,l], cmap=cmap, vmin = unique.min(), vmax = unique.max()+1, add_colorbar=False)\n",
    "\n",
    "        cbar = fig.colorbar(clus, ticks=unique+0.5, fraction=0.08, pad=0.08) \n",
    "        cbar.set_ticklabels(unique+1)\n",
    "        # cbar.set_label('Clusters [count]')\n",
    "        ax[k,l].set_title(str(years[j]))\n",
    "\n",
    "        sa_vi.set_aspect(ax[k,l])\n",
    "\n",
    "        l=l+1\n",
    "\n",
    "        if l==4:\n",
    "            l=0\n",
    "            k=k+1\n",
    "\n",
    "        # Printing\n",
    "        for i in unique:\n",
    "            print('The amount of points for cluster '+ str(i+1)+' for year '+str(years[j])+' is: '+str(counts_all[j][i])+\n",
    "                ' with a mean of: '+str(np.round(np.mean(clusters_ind[i][j]),3)))\n",
    "        print('\\n')\n",
    "\n",
    "    ax[4,2].axis('off')\n",
    "    ax[4,3].axis('off')\n",
    "\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    fig.suptitle('Functional Clustering for ' + str(name))\n",
    "    plt.show()\n",
    "\n",
    "    for i in unique:\n",
    "\n",
    "        k=0\n",
    "        l=0\n",
    "\n",
    "        fig, ax = plt.subplots(5, 4, figsize=(10, 15))\n",
    "\n",
    "        for j in np.arange (0,len(years)):\n",
    "    \n",
    "            ax[k, l].plot(clusters_ind[i][j])\n",
    "            ax[k, l].set_title(str(years[j]))\n",
    "\n",
    "            l=l+1\n",
    "\n",
    "            if l==4:\n",
    "                l=0\n",
    "                k=k+1\n",
    "\n",
    "        ax[4,2].axis('off')\n",
    "        ax[4,3].axis('off')\n",
    "\n",
    "        fig.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "        fig.suptitle('Cluster '+ str(i+1))\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2007 - 2020\n",
    "\n",
    "func_clust_drivers_all()\n",
    "\n",
    "func_clust_target_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every year individually (Drivers)\n",
    "\n",
    "clusters,cluster1,cluster2,cluster3,cluster4,cluster5,cluster6,counts_all,unique = func_clust_drivers()\n",
    "    \n",
    "clusters = xr.concat(clusters, dim='year')\n",
    "clusters_ind = []\n",
    "clusters_ind = ([cluster1,cluster2,cluster3,cluster4,cluster5,cluster6])\n",
    "plotting_drivers(clusters,clusters_ind,unique,counts_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every year individually (Targets)\n",
    "\n",
    "names = ['Diatom', 'Flagellate', 'Diatom_Production_Rate', 'Flagellate_Production_Rate']\n",
    "\n",
    "for name in (names):\n",
    "\n",
    "    clusters,cluster1,cluster2,cluster3,cluster4,cluster5,cluster6,counts_all,unique = func_clust_target(name)\n",
    "    clusters = xr.concat(clusters, dim='year')\n",
    "    clusters_ind = []\n",
    "    clusters_ind = ([cluster1,cluster2,cluster3,cluster4,cluster5,cluster6])\n",
    "    plotting_targets(name,clusters,clusters_ind,unique,counts_all)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis-ilias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
