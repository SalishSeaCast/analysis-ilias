{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import salishsea_tools.viz_tools as sa_vi\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets_preparation ():\n",
    "    \n",
    "    temp_i1 = (ds.votemper.where(mask==1)[0,0:15] * ds.e3t.where(mask==1)\n",
    "               [0,0:15]).sum('deptht', skipna = True, min_count = 15) / mesh.gdepw_0[0,15]\n",
    "\n",
    "    temp_i2 = (ds.votemper.where(mask==1)[0,15:27] * ds.e3t.where(mask==1)\n",
    "               [0,15:27]).sum('deptht', skipna = True, min_count = 12) / (mesh.gdepw_0[0,27] - mesh.gdepw_0[0,14])\n",
    "\n",
    "    saline_i1 = (ds.vosaline.where(mask==1)[0,0:15] * ds.e3t.where(mask==1)\n",
    "                 [0,0:15]).sum('deptht', skipna = True, min_count = 15) / mesh.gdepw_0[0,15]\n",
    "\n",
    "    saline_i2 = (ds.vosaline.where(mask==1)[0,15:27] * ds.e3t.where(mask==1)\n",
    "                 [0,15:27]).sum('deptht', skipna = True, min_count = 12) / (mesh.gdepw_0[0,27] - mesh.gdepw_0[0,14])\n",
    "\n",
    "    sil_i = (ds_bio.silicon.where(mask==1)[0,0:27] * ds.e3t.where(mask==1)\n",
    "             [0,0:27]).sum('deptht', skipna = True, min_count = 27) / mesh.gdepw_0[0,27]\n",
    "\n",
    "    nitr_i = (ds_bio.nitrate.where(mask==1)[0,0:27] * ds.e3t.where(mask==1)\n",
    "              [0,0:27]).sum('deptht', skipna = True, min_count = 27) / mesh.gdepw_0[0,27]\n",
    "\n",
    "    ammo_i = (ds_bio.ammonium.where(mask==1)[0,0:27] * ds.e3t.where(mask==1)\n",
    "              [0,0:27]).sum('deptht', skipna = True, min_count = 27) / mesh.gdepw_0[0,27]\n",
    "\n",
    "    diat_i = (ds_bio.diatoms.where(mask==1)[0,0:27] * ds.e3t.where(mask==1)\n",
    "              [0,0:27]).sum('deptht', skipna = True, min_count = 27) / mesh.gdepw_0[0,27]\n",
    "\n",
    "    flag_i = (ds_bio.flagellates.where(mask==1)[0,0:27] * ds.e3t.where(mask==1)\n",
    "              [0,0:27]).sum('deptht', skipna = True, min_count = 27) / mesh.gdepw_0[0,27]\n",
    "    \n",
    "    micro_i = (ds_bio.microzooplankton.where(mask==1)[0,0:27] * ds.e3t.where(mask==1)\n",
    "               [0,0:27]).sum('deptht', skipna = True, min_count = 27) / mesh.gdepw_0[0,27]\n",
    "\n",
    "    meso_i = (ds_bio.mesozooplankton.where(mask==1)[0,0:27] * ds.e3t.where(mask==1)\n",
    "              [0,0:27]).sum('deptht', skipna = True, min_count = 27) / mesh.gdepw_0[0,27]\n",
    "\n",
    "    return (temp_i1, temp_i2, saline_i1, saline_i2, sil_i, nitr_i, ammo_i, diat_i,  flag_i, micro_i, meso_i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor (inputs, targets, variable_name):\n",
    "\n",
    "    # Pre processing \n",
    "    indx = np.where(~np.isnan(inputs).any(axis=0))\n",
    "    inputs2 = inputs[:,indx[0]]\n",
    "    inputs2 = inputs2.transpose()\n",
    "\n",
    "    targets2 = targets[indx]\n",
    "    targets2 = np.ravel(targets2)\n",
    "\n",
    "    # Regressor\n",
    "    scale = preprocessing.StandardScaler()\n",
    "    inputs2 = scale.fit_transform(inputs2)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(inputs2, targets2, random_state=1)\n",
    "    regr = MLPRegressor(hidden_layer_sizes = 100, activation = 'relu', solver = 'adam', max_iter=1500, random_state=1, learning_rate_init=0.01).fit(X_train, y_train)\n",
    "    outputs_test = regr.predict(X_test)\n",
    "    outputs = regr.predict(inputs2)\n",
    "\n",
    "    scatter_plot(y_test, outputs_test, variable_name + ' (Testing dataset)')\n",
    "\n",
    "    # Post processing\n",
    "    indx2 = np.full(inputs[0,:].size,np.nan)\n",
    "    indx2[indx[0]] = outputs\n",
    "    model = np.reshape(indx2,(898,398)) \n",
    "\n",
    "    # Preparation of the dataarray \n",
    "    model = xr.DataArray(model,\n",
    "                    coords = {'y': temp_i1.y, 'x': temp_i1.x},\n",
    "                    dims = ['y','x'],\n",
    "                    attrs=dict( long_name = variable_name + \" Concentration\",\n",
    "                                units=\"mmol m-2\"),\n",
    "                        )\n",
    "\n",
    "    return (targets2, outputs, model, regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printing (targets, outputs, m):\n",
    "\n",
    "    print ('The slope of the best fitting line is ' + str(np.round(m,2)))\n",
    "    print ('The correlation coefficient is:', (r2_score(targets, outputs)))\n",
    "    print (' The root mean square error is:', np.round(mse(targets,outputs),2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(targets, outputs, variable_name):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.scatter(targets,outputs, alpha = 0.2, s = 10)\n",
    "    plt.xlabel('targets')\n",
    "    plt.ylabel('outputs')\n",
    "\n",
    "    # compute slope m and intercept b\n",
    "    m, b = np.polyfit(targets, outputs, deg=1)\n",
    "\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "    ]\n",
    "\n",
    "    # plot fitted y = m*x + b\n",
    "    plt.axline(xy1=(0, b), slope=m, color='r')\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "\n",
    "    ax.plot(lims, lims,linestyle = '--',color = 'k')\n",
    "\n",
    "    fig.suptitle(str(date.date[0]) + ', ' + variable_name)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    printing (targets, outputs, m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting (targets, outputs, model, variable, variable_name):\n",
    "\n",
    "    fig, ax = plt.subplots(2,2, figsize = (10,15))\n",
    "\n",
    "    cmap = plt.get_cmap('cubehelix')\n",
    "    cmap.set_bad('gray')\n",
    "\n",
    "    variable.plot(ax=ax[0,0], cmap=cmap, vmin = targets.min(), vmax =targets.max(), cbar_kwargs={'label': variable_name + ' Concentration  [mmol m-2]'})\n",
    "    model.plot(ax=ax[0,1], cmap=cmap, vmin = targets.min(), vmax = targets.max(), cbar_kwargs={'label': variable_name + ' Concentration  [mmol m-2]'})\n",
    "    ((variable-model) / variable * 100).plot(ax=ax[1,0], cmap=cmap, cbar_kwargs={'label': variable_name + ' Concentration  [percentage]'})\n",
    "\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "        bottom=0.1, \n",
    "        right=0.95, \n",
    "        top=0.95, \n",
    "        wspace=0.35, \n",
    "        hspace=0.35)\n",
    "\n",
    "    sa_vi.set_aspect(ax[0,0])\n",
    "    sa_vi.set_aspect(ax[0,1])\n",
    "    sa_vi.set_aspect(ax[1,0])\n",
    "\n",
    "\n",
    "    ax[0,0].title.set_text(variable_name + ' (targets)')\n",
    "    ax[0,1].title.set_text(variable_name + ' (outputs)')\n",
    "    ax[1,0].title.set_text('targets - outputs')\n",
    "    ax[1,1].axis('off')\n",
    "\n",
    "    fig.suptitle(str(date.date[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(variable, variable_name):\n",
    "\n",
    "    targets, outputs, model, reg = regressor(drivers, np.ravel(variable), variable_name)\n",
    "    scatter_plot(targets, outputs, variable_name)\n",
    "    plotting (targets, outputs, model, variable, variable_name)\n",
    "\n",
    "    return (reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary for Other Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary2(variable, variable_name, reg_variable):\n",
    "\n",
    "    targets, outputs, model= regressor2(drivers, np.ravel(variable), variable_name, reg_variable)\n",
    "    scatter_plot(targets, outputs, variable_name)\n",
    "    plotting (targets, outputs, model, variable, variable_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressor for Other Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor2 (inputs,targets, variable_name, reg_variable):\n",
    "    \n",
    "    # Pre processing \n",
    "    indx = np.where(~np.isnan(inputs).any(axis=0))\n",
    "    inputs2 = inputs[:,indx[0]]\n",
    "    inputs2 = inputs2.transpose()\n",
    "\n",
    "    targets2 = targets[indx]\n",
    "    targets2 = np.ravel(targets2)\n",
    "\n",
    "    # Regressor\n",
    "    scale = preprocessing.StandardScaler()\n",
    "    inputs2 = scale.fit_transform(inputs2)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(inputs2, targets2, random_state=1)\n",
    "    outputs_test = reg_variable.predict(X_test)\n",
    "    outputs = reg_variable.predict(inputs2)\n",
    "\n",
    "    scatter_plot(y_test, outputs_test, variable_name + ' (Testing dataset)')\n",
    "\n",
    "    # Post processing\n",
    "    indx2 = np.full(inputs[0,:].size,np.nan)\n",
    "    indx2[indx[0]] = outputs\n",
    "    model = np.reshape(indx2,(898,398)) \n",
    "\n",
    "    # Preparation of the dataarray \n",
    "    model = xr.DataArray(model,\n",
    "                    coords = {'y': temp_i1.y, 'x': temp_i1.x},\n",
    "                    dims = ['y','x'],\n",
    "                    attrs=dict( long_name = variable_name + \" Concentration\",\n",
    "                                units=\"mmol m-2\"),\n",
    "                        )\n",
    "\n",
    "    return (targets2, outputs, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and date\n",
    "ds = xr.open_dataset ('/results2/SalishSea/nowcast-green.202111/20mar22/SalishSea_1d_20220320_20220320_grid_T.nc')\n",
    "ds_bio = xr. open_dataset ('/results2/SalishSea/nowcast-green.202111/20mar22/SalishSea_1d_20220320_20220320_biol_T.nc')\n",
    "date = pd.DatetimeIndex(ds['time_counter'].values)\n",
    "\n",
    "# Open the mesh mask\n",
    "mesh = xr.open_dataset('/home/sallen/MEOPAR/grid/mesh_mask202108.nc')\n",
    "mask = mesh.tmask.to_numpy()\n",
    "\n",
    "temp_i1, temp_i2, saline_i1, saline_i2, sil_i, nitr_i, ammo_i, diat_i, flag_i, micro_i, meso_i = datasets_preparation()\n",
    "\n",
    "# Potential input variables\n",
    "drivers = np.stack([np.ravel(temp_i1), np.ravel(temp_i2), np.ravel(saline_i1), np.ravel(saline_i2)])\n",
    "nutrients = np.stack([np.ravel(sil_i), np.ravel(nitr_i), np.ravel(ammo_i)])\n",
    "phyto = np.stack([np.ravel(diat_i), np.ravel(flag_i)])\n",
    "zoo = np.stack([np.ravel(micro_i), np.ravel(meso_i)])\n",
    "\n",
    "reg_sil = summary (sil_i, 'Silicon')\n",
    "reg_nitr = summary (nitr_i, 'Nitrate')\n",
    "reg_ammo = summary (ammo_i, 'Ammonium')\n",
    "\n",
    "reg_diat = summary (diat_i, 'Diatom')\n",
    "reg_flag = summary (flag_i, 'Flagellate')\n",
    "\n",
    "reg_mic = summary (micro_i, 'Microzooplankton')\n",
    "reg_mes = summary (meso_i, 'Mesozooplankton')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and date\n",
    "ds = xr.open_dataset ('/results2/SalishSea/nowcast-green.202111/31mar22/SalishSea_1d_20220331_20220331_grid_T.nc')\n",
    "ds_bio = xr. open_dataset ('/results2/SalishSea/nowcast-green.202111/31mar22/SalishSea_1d_20220331_20220331_biol_T.nc')\n",
    "date = pd.DatetimeIndex(ds['time_counter'].values)\n",
    "\n",
    "temp_i1, temp_i2, saline_i1, saline_i2, sil_i, nitr_i, ammo_i, diat_i, flag_i, micro_i, meso_i = datasets_preparation()\n",
    "\n",
    "\n",
    "summary2 (sil_i, 'Silicon', reg_sil)\n",
    "summary2 (nitr_i, 'Nitrate', reg_nitr)\n",
    "summary2 (ammo_i, 'Ammonium', reg_ammo)\n",
    "\n",
    "summary2 (diat_i, 'Diatom', reg_diat)\n",
    "summary2 (flag_i, 'Flagellate', reg_flag)\n",
    "\n",
    "summary2 (micro_i, 'Microzooplankton', reg_mic)\n",
    "summary2 (meso_i, 'Mesozooplankton', reg_mes)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis-ilias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
