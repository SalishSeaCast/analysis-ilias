{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diatom Biomass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import dill # You might need to install this package - saving & loading of files\n",
    "from skfda import FDataGrid # You might need to install this package - format of functional regression files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Diatom\n",
      "period: jan_apr\n",
      "input_features: ['Summation_of_solar_radiation', 'Summation_of_longwave_radiation']\n",
      "n_intervals: 4\n",
      "lag: 29.75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name = 'Diatom'\n",
    "\n",
    "# Path of the files provided\n",
    "path = '/data/ibougoudis/MOAD/analysis-ilias/notebooks/temp/' + name + '_biomass/' # Change this to the relative path\n",
    "\n",
    "# Printing of the readme file\n",
    "readme = open(path + name[0:4].lower() + '_bio' + '_readme.txt', 'r')\n",
    "print(readme.read())\n",
    "\n",
    "f = open(path + name[0:4].lower() + '_bio' + '_regressor.pkl', 'rb')\n",
    "regr = dill.load(f)\n",
    "\n",
    "f = open(path + name[0:4].lower() + '_bio' + '_scaler_inputs.pkl', 'rb')\n",
    "scaler_inputs = dill.load(f)\n",
    "\n",
    "f = open(path + name[0:4].lower() + '_bio' + '_scaler_targets.pkl', 'rb')\n",
    "scaler_targets = dill.load(f)\n",
    "\n",
    "f = open(path + name[0:4].lower() + '_bio' + '_smoother.pkl', 'rb')\n",
    "smoother = dill.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(regr,inputs,scaler_inputs,scaler_targets,smoother):\n",
    "\n",
    "    # Scaling the inputs\n",
    "    inputs0 = inputs # keeping the shape\n",
    "    temp = np.reshape(inputs,(len(inputs),inputs.shape[1]*inputs.shape[2]), order='F')\n",
    "    temp = temp.transpose()\n",
    "    temp = scaler_inputs.transform(temp)\n",
    "    temp = temp.transpose()        \n",
    "    inputs = np.reshape(temp,(len(inputs),inputs.shape[1],inputs.shape[2]), order='F')\n",
    "        \n",
    "    inputs = np.transpose(inputs,axes=(2,1,0))\n",
    "    inputs = FDataGrid(data_matrix=inputs, grid_points=np.arange(0,inputs.shape[1]))\n",
    "\n",
    "    inputs = smoother.transform(inputs)\n",
    "\n",
    "    predictions = regr.predict(inputs)\n",
    "\n",
    "    # Post-processing of predictions\n",
    "    predictions = np.array(predictions.to_grid(np.arange(0,inputs0.shape[1])).data_matrix)\n",
    "    predictions = np.squeeze(predictions,2)\n",
    "\n",
    "    # Scaling the predictions\n",
    "    temp = np.reshape(predictions, (inputs0.shape[1]*inputs0.shape[2]), order='F')\n",
    "    temp = np.expand_dims(temp,axis=-1)\n",
    "    temp = scaler_targets.inverse_transform(temp)\n",
    "    predictions = temp.reshape(predictions.shape, order='F')\n",
    "    predictions = predictions.transpose()\n",
    "\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 120, 1)\n",
      "The 1 model output of Diatom:\n",
      "0.2086\n",
      "The 2 model output of Diatom:\n",
      "0.2039\n",
      "The 3 model output of Diatom:\n",
      "0.1978\n",
      "The 4 model output of Diatom:\n",
      "0.194\n",
      "The 5 model output of Diatom:\n",
      "0.192\n",
      "The 6 model output of Diatom:\n",
      "0.192\n",
      "The 7 model output of Diatom:\n",
      "0.1951\n",
      "The 8 model output of Diatom:\n",
      "0.1979\n",
      "The 9 model output of Diatom:\n",
      "0.1995\n",
      "The 10 model output of Diatom:\n",
      "0.2026\n"
     ]
    }
   ],
   "source": [
    "inputs = pd.read_excel(path + name[0:4].lower() + '_bio' +'_inputs.xlsx', sheet_name= name) # Excel file for this variable\n",
    "inputs = inputs.iloc[:,1:3].to_numpy()\n",
    "inputs = np.expand_dims(inputs, -1) # We do this because the regressor accepts arrays of shape (n_features, n_samples, 1)\n",
    "inputs = np.transpose(inputs,(1,0,2)) # We do this because the regressor accepts arrays of shape (n_features, n_samples, 1)\n",
    "\n",
    "indx = np.where(inputs[0,:,0] == -1)[0][0] # The first day for which we do not have measurements (07 Apr)\n",
    "\n",
    "print(inputs.shape)\n",
    "\n",
    "predictions = scaling(regr,inputs,scaler_inputs,scaler_targets,smoother)\n",
    "\n",
    "predictions = np.squeeze(predictions) # We do this to remove the 1 dimension\n",
    "\n",
    "predictions[indx:] = np.nan # to remove instances where we do not have input measurements (07 Apr onwards)\n",
    "\n",
    "for i in range (0, 10): # Printing the 10 first outputs\n",
    "\n",
    "    print('The ' + str(i+1) + ' model output of ' + name + ':')\n",
    "    print(np.round(predictions[i],4))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis-ilias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
