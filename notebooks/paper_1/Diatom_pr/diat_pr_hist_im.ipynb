{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Diatom production rate with Histogram-based Gradient Boosting Regression Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xskillscore as xs\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.feature_selection import r_regression\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error as rmse\n",
    "\n",
    "import os\n",
    "import lzma\n",
    "import dill\n",
    "\n",
    "import random\n",
    "\n",
    "import cmocean.cm as cm\n",
    "import salishsea_tools.viz_tools as sa_vi\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the training - testing datasets\n",
    "def datasets_preparation(dataset, name, inputs_names):\n",
    "\n",
    "    x = np.tile(dataset.x, len(dataset.time_counter)*len(dataset.y))\n",
    "    y = np.tile(np.repeat(dataset.y, len(dataset.x)), len(dataset.time_counter))\n",
    "\n",
    "    dayofyear = np.tile(np.arange(0,len(dataset.time_counter)//len(np.unique(dataset.time_counter.dt.year))), len(np.unique(dataset.time_counter.dt.year)))\n",
    "\n",
    "    inputs = []\n",
    "    \n",
    "    if 'Day_of_year' in inputs_names:   \n",
    "        for i in inputs_names[0:inputs_names.index('Day_of_year')]:\n",
    "            inputs.append(dataset[i].to_numpy().flatten())  \n",
    "\n",
    "        inputs.append(np.repeat(dayofyear, len(dataset.x)*len(dataset.y)))\n",
    "\n",
    "        for i in inputs_names[inputs_names.index('Day_of_year')+1:]:\n",
    "            inputs.append(dataset[i].to_numpy().flatten()) \n",
    "\n",
    "    else:        \n",
    "        for i in inputs_names:\n",
    "            inputs.append(dataset[i].to_numpy().flatten())\n",
    "\n",
    "    inputs = np.array(inputs)\n",
    "\n",
    "    targets = np.ravel(dataset[name])\n",
    "    \n",
    "    indx = np.where(np.isfinite(targets) & (x>10) & ((x>100) | (y<880)))\n",
    "    inputs = inputs[:,indx[0]]\n",
    "    targets = targets[indx[0]]\n",
    "\n",
    "    inputs = inputs.transpose()\n",
    "\n",
    "    return(inputs, targets, indx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor (inputs, targets, n_bins, drivers, spatial, inputs_names):\n",
    "\n",
    "    if spatial == []:\n",
    "        model = TransformedTargetRegressor(regressor=make_pipeline(ColumnTransformer(\n",
    "            transformers=[('drivers', StandardScaler(), np.arange(0,len(drivers)))], remainder='passthrough'),\n",
    "            HistGradientBoostingRegressor(categorical_features=[len(drivers)])),\n",
    "            transformer=StandardScaler())\n",
    "\n",
    "    else:\n",
    "        model = TransformedTargetRegressor(regressor=make_pipeline(ColumnTransformer(\n",
    "        transformers=[('drivers', StandardScaler(), np.arange(0,len(drivers))), \n",
    "            ('spatial', KBinsDiscretizer(n_bins=n_bins,encode='ordinal',strategy='quantile'), np.arange(inputs_names.index(spatial[0]),inputs_names.index(spatial[-1])+1))],\n",
    "            remainder='passthrough'),\n",
    "        HistGradientBoostingRegressor(categorical_features=np.arange(inputs_names.index(spatial[0]),len(inputs_names)))),\n",
    "        transformer=StandardScaler())\n",
    "    \n",
    "    regr = model.fit(inputs,targets)\n",
    "\n",
    "    r_inputs = np.round(r_regression(inputs,targets),2)\n",
    "\n",
    "    return(regr, r_inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance(dataset, regr, name, inputs_names):\n",
    "\n",
    "    inputs, targets, _ = datasets_preparation(dataset, name, inputs_names)\n",
    "\n",
    "    importances_all = permutation_importance(regr, inputs, targets, n_repeats=5, scoring=('r2','neg_root_mean_squared_error'))\n",
    "    inputs_names2 = ['SWR', 'LWR', 'TP', 'AP', 'AT', 'SH', 'WS', 'Lat', 'Lon', 'Day']\n",
    "\n",
    "    sorted_importances_idx = importances_all['r2'].importances_mean.argsort()\n",
    "    x = []\n",
    "    for i in range (0, len(inputs_names2)):\n",
    "        x.append(inputs_names2[sorted_importances_idx[i]])\n",
    "\n",
    "    r_importance = pd.Series(importances_all['r2'].importances_mean[sorted_importances_idx], index=x)\n",
    "   \n",
    "    sorted_importances_idx = importances_all['neg_root_mean_squared_error'].importances_mean.argsort()\n",
    "    x = []\n",
    "    for i in range (0, len(inputs_names2)):\n",
    "        x.append(inputs_names2[sorted_importances_idx[i]])\n",
    "\n",
    "    rms_importance = pd.Series(importances_all['neg_root_mean_squared_error'].importances_mean[sorted_importances_idx], index=x)\n",
    "    rms_importance = rms_importance / np.mean(targets) * 100\n",
    "\n",
    "    return(r_importance, rms_importance)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting (Regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(ax, corn, colour):\n",
    "\n",
    "    ax.plot([corn[2], corn[3], corn[3], corn[2], corn[2]], \n",
    "    [corn[0], corn[0], corn[1], corn[1], corn[0]], '-', color=colour)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Diatom_Production_Rate'\n",
    "units = '[mmol N / $m^2$ / $s$]'\n",
    "category = 'Production rates'\n",
    "\n",
    "filename = '/data/ibougoudis/MOAD/files/inputs/jan_mar.nc'\n",
    "\n",
    "drivers =  ['Summation_of_solar_radiation', 'Summation_of_longwave_radiation', 'Mean_precipitation', 'Mean_pressure', 'Mean_air_temperature', 'Mean_specific_humidity', 'Mean_wind_speed']\n",
    "spatial = ['Latitude', 'Longitude']\n",
    "day_input = ['Day_of_year']\n",
    "inputs_names = drivers + spatial + day_input\n",
    "\n",
    "n_bins = 255\n",
    "\n",
    "if filename[35:42] == 'jan_mar': # 75 days, 1st period\n",
    "    period = '(16 Jan - 31 Mar)'\n",
    "    id = '1'\n",
    "    months = ['January', 'February', 'March']\n",
    "\n",
    "elif filename[35:42] == 'jan_apr': # 120 days, 2nd period\n",
    "    period = '(01 Jan - 30 Apr)'\n",
    "    id = '2'\n",
    "    months = ['January', 'February', 'March', 'April']\n",
    "\n",
    "elif filename[35:42] == 'feb_apr': # 75 days, 3rd period\n",
    "    period = '(15 Feb - 30 Apr)'\n",
    "    id = '3'\n",
    "    months = ['February', 'March', 'April']\n",
    "\n",
    "elif filename[35:42] == 'apr_jun': # 76 days, 4th period\n",
    "    period = '(16 Apr - 30 Jun)'\n",
    "    id = '4'\n",
    "    months = ['April', 'May', 'June']\n",
    "\n",
    "elif filename[35:42] == 'may_sep': # 153 days, 5th period\n",
    "    period = '(01 May - 30 Sep)'\n",
    "    id = '5'\n",
    "    months = ['May', 'June', 'July', 'August', 'September']\n",
    "   \n",
    "ds = xr.open_dataset(filename)\n",
    "ds0 = ds # For the regional plot\n",
    "\n",
    "# Low resolution\n",
    "\n",
    "# ds = ds.isel(y=(np.arange(ds.y[0], ds.y[-1], 5)), \n",
    "#     x=(np.arange(ds.x[0], ds.x[-1], 5)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bathy = xr.open_dataset('/home/sallen/MEOPAR/grid/bathymetry_202108.nc')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 9))\n",
    "mycmap = cm.deep\n",
    "mycmap.set_bad('grey')\n",
    "ax.pcolormesh(ds0[name][0], cmap=mycmap)\n",
    "sa_vi.set_aspect(ax)\n",
    "\n",
    "SoG_north = [650, 730, 100, 200]\n",
    "plot_box(ax, SoG_north, 'g')\n",
    "SoG_center = [450, 550, 200, 300]\n",
    "plot_box(ax, SoG_center, 'b')\n",
    "Fraser_plume = [380, 460, 260, 330]\n",
    "plot_box(ax, Fraser_plume, 'm')\n",
    "SoG_south = [320, 380, 280, 350]\n",
    "plot_box(ax, SoG_south, 'k')\n",
    "Haro_Boundary = [290, 350, 210, 280]\n",
    "plot_box(ax, Haro_Boundary, 'm')\n",
    "JdF_west = [250, 425, 25, 125]\n",
    "plot_box(ax, JdF_west, 'c')\n",
    "JdF_east = [200, 290, 150, 260]\n",
    "plot_box(ax, JdF_east, 'w')\n",
    "PS_all = [0, 200, 80, 320]\n",
    "plot_box(ax, PS_all, 'm')\n",
    "PS_main = [20, 150, 200, 280]\n",
    "plot_box(ax, PS_main, 'r')\n",
    "\n",
    "boxnames = ['GN','GC','FP','GS', 'HB', 'JdFW', 'JdFE', 'PSA', 'PSM']\n",
    "fig.legend(boxnames)\n",
    "\n",
    "boxes = [SoG_north,SoG_center,Fraser_plume,SoG_south,Haro_Boundary,JdF_west,JdF_east,PS_all,PS_main]\n",
    "\n",
    "regions0 = np.full((len(ds0.y),len(ds0.x)),np.nan)\n",
    "for i in range (0, len(boxes)):\n",
    "    regions0[boxes[i][0]:boxes[i][1], boxes[i][2]:boxes[i][3]] = i\n",
    "\n",
    "regions0 = xr.DataArray(regions0,dims = ['y','x'])\n",
    "\n",
    "# Low resolution\n",
    "\n",
    "# temp = []\n",
    "# for i in boxes:\n",
    "\n",
    "#     temp.append([x//5 for x in i])\n",
    "\n",
    "# boxes = temp\n",
    "\n",
    "# regions0 = regions0.isel(y=(np.arange(regions0.y[0], regions0.y[-1], 5)), \n",
    "#     x=(np.arange(regions0.x[0], regions0.x[-1], 5)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds.sel(time_counter = slice('2007', '2020'))\n",
    "\n",
    "labels = np.unique(dataset.time_counter.dt.strftime('%d %b'))\n",
    "indx_labels = np.argsort(pd.to_datetime(labels, format='%d %b'))\n",
    "labels = labels[indx_labels]\n",
    "\n",
    "inputs, targets, indx = datasets_preparation(dataset, name, inputs_names)\n",
    "\n",
    "regr, r_inputs = regressor(inputs, targets, n_bins, drivers, spatial, inputs_names)\n",
    "\n",
    "print('Metrics between input features and '+name)\n",
    "temp = pd.DataFrame(r_inputs, index=inputs_names, columns=[period])\n",
    "display(temp)\n",
    "\n",
    "predictions = regr.predict(inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds.sel(time_counter = slice('2021', '2024'))\n",
    "r_importance, rms_importance = importance(dataset, regr, name, inputs_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_s = []\n",
    "names = []\n",
    "\n",
    "path = '/data/ibougoudis/MOAD/files/results/' + name + '/bootstraps/' + name[0:4].lower() + '_pr_hist1_3_boot_100/'\n",
    "with open(path + 'test_metrics.pkl', 'rb') as f:\n",
    "    test_s.append(dill.load(f))\n",
    "names.append('current')\n",
    "\n",
    "path = '/data/ibougoudis/MOAD/files/results/' + name + '/bootstraps/' + name[0:4].lower() + '_pr_hist1_5_boot_100/'\n",
    "with open(path + 'test_metrics.pkl', 'rb') as f:\n",
    "    test_s.append(dill.load(f))\n",
    "names.append('- TP')\n",
    "\n",
    "path = '/data/ibougoudis/MOAD/files/results/' + name + '/bootstraps/' + name[0:4].lower() + '_pr_hist1_7_boot_100/'\n",
    "with open(path + 'test_metrics.pkl', 'rb') as f:\n",
    "    test_s.append(dill.load(f))\n",
    "names.append('- SWR')\n",
    "\n",
    "path = '/data/ibougoudis/MOAD/files/results/' + name + '/bootstraps/' + name[0:4].lower() + '_pr_hist1_9_boot_100/'\n",
    "with open(path + 'test_metrics.pkl', 'rb') as f:\n",
    "    test_s.append(dill.load(f))\n",
    "names.append('- Lat')\n",
    "\n",
    "path = '/data/ibougoudis/MOAD/files/results/' + name + '/bootstraps/' + name[0:4].lower() + '_pr_hist1_10_boot_100/'\n",
    "with open(path + 'test_metrics.pkl', 'rb') as f:\n",
    "    test_s.append(dill.load(f))\n",
    "names.append('- Day')\n",
    "\n",
    "path = '/data/ibougoudis/MOAD/files/results/' + name + '/bootstraps/' + name[0:4].lower() + '_pr_hist1_8_boot_100/'\n",
    "with open(path + 'test_metrics.pkl', 'rb') as f:\n",
    "    test_s.append(dill.load(f))\n",
    "names.append('- Lon')\n",
    "\n",
    "path = '/data/ibougoudis/MOAD/files/results/' + name + '/bootstraps/' + name[0:4].lower() + '_pr_hist1_4_boot_100/'\n",
    "with open(path + 'test_metrics.pkl', 'rb') as f:\n",
    "    test_s.append(dill.load(f))\n",
    "names.append('- WS')\n",
    "\n",
    "path = '/data/ibougoudis/MOAD/files/results/' + name + '/bootstraps/' + name[0:4].lower() + '_pr_hist1_6_boot_100/'\n",
    "with open(path + 'test_metrics.pkl', 'rb') as f:\n",
    "    test_s.append(dill.load(f))\n",
    "names.append('- AT')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_b = []\n",
    "\n",
    "path = '/data/ibougoudis/MOAD/files/results/' + name + '/bootstraps/' + name[0:4].lower() + '_pr_hist1_boxes_0_boot_100/'\n",
    "with open(path + 'test_metrics.pkl', 'rb') as f:\n",
    "    test_b.append(dill.load(f))\n",
    "\n",
    "path = '/data/ibougoudis/MOAD/files/results/' + name + '/bootstraps/' + name[0:4].lower() + '_pr_hist1_boxes_4_boot_100/'\n",
    "with open(path + 'test_metrics.pkl', 'rb') as f:\n",
    "    test_b.append(dill.load(f))\n",
    "\n",
    "path = '/data/ibougoudis/MOAD/files/results/' + name + '/bootstraps/' + name[0:4].lower() + '_pr_hist1_boxes_7_boot_100/'\n",
    "with open(path + 'test_metrics.pkl', 'rb') as f:\n",
    "    test_b.append(dill.load(f))\n",
    "\n",
    "path = '/data/ibougoudis/MOAD/files/results/' + name + '/bootstraps/' + name[0:4].lower() + '_pr_hist1_boxes_9_boot_100/'\n",
    "with open(path + 'test_metrics.pkl', 'rb') as f:\n",
    "    test_b.append(dill.load(f))\n",
    "\n",
    "path = '/data/ibougoudis/MOAD/files/results/' + name + '/bootstraps/' + name[0:4].lower() + '_pr_hist1_boxes_1_boot_100/'\n",
    "with open(path + 'test_metrics.pkl', 'rb') as f:\n",
    "    test_b.append(dill.load(f))\n",
    "\n",
    "path = '/data/ibougoudis/MOAD/files/results/' + name + '/bootstraps/' + name[0:4].lower() + '_pr_hist1_boxes_8_boot_100/'\n",
    "with open(path + 'test_metrics.pkl', 'rb') as f:\n",
    "    test_b.append(dill.load(f))\n",
    "\n",
    "path = '/data/ibougoudis/MOAD/files/results/' + name + '/bootstraps/' + name[0:4].lower() + '_pr_hist1_boxes_2_boot_100/'\n",
    "with open(path + 'test_metrics.pkl', 'rb') as f:\n",
    "    test_b.append(dill.load(f))\n",
    "\n",
    "path = '/data/ibougoudis/MOAD/files/results/' + name + '/bootstraps/' + name[0:4].lower() + '_pr_hist1_boxes_3_boot_100/'\n",
    "with open(path + 'test_metrics.pkl', 'rb') as f:\n",
    "    test_b.append(dill.load(f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_s = np.zeros((len(names), len(boxnames)))\n",
    "r_b = np.zeros((len(names), len(boxnames)))\n",
    "\n",
    "rms_s = np.zeros((len(names), len(boxnames)))\n",
    "rms_b = np.zeros((len(names), len(boxnames)))\n",
    "\n",
    "for i in range (0, len(names)):\n",
    "\n",
    "    r_s[i,:] = np.nanmean(test_s[i][3], axis=0)\n",
    "    r_b[i,:] = np.nanmean(test_b[i][3], axis=0)\n",
    "\n",
    "    rms_s[i,:] = np.nanmean(test_s[i][1], axis=0)\n",
    "    rms_b[i,:] = np.nanmean(test_b[i][1], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radar Plot (R Testing no Seasonality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['(a)','(b)','(c)','(d)','(e)','(f)','(g)','(h)','(i)']\n",
    "\n",
    "k,l = 0,0\n",
    "fig, ax = plt.subplots(2, 5, figsize=(15, 7), layout='constrained', subplot_kw={'projection': 'polar'})\n",
    "\n",
    "for i in range (0, len(boxes)):\n",
    "\n",
    "    theta = np.arange(len(names) + 1) / float(len(names)) * 2 * np.pi\n",
    "\n",
    "    values = np.append(r_s[:,i], r_s[:,i][0])\n",
    "    values2 = np.append(r_b[:,i], r_b[:,i][0])\n",
    "\n",
    "    ax[k,l].plot(theta, values, marker='o', label ='Single')\n",
    "    ax[k,l].plot(theta, values2, marker='o', label = 'Boxes')\n",
    "    ax[k,l].plot(np.linspace(0, 2*np.pi, 100), np.full(100, values[0]), ls = '--')\n",
    "\n",
    "    ax[k,l].annotate(labels[i], (0.02, 1.2), xycoords='axes fraction', fontsize=14)\n",
    "\n",
    "    ax[k,l].set_theta_zero_location('N')\n",
    "    ax[k,l].set_rmax(np.maximum(np.max(values)+0.05, np.max(values2)+0.05))\n",
    "    ax[k,l].set_rmin(np.minimum(np.min(values)-0.05, np.min(values2)-0.05)) \n",
    "    ax[k,l].set_rticks(np.round(np.linspace(np.round(np.minimum(np.min(values)-0.05, np.min(values2)-0.05),1), np.round(np.maximum(np.max(values)+0.05, np.max(values2)+0.05),1), 3), 2))\n",
    "\n",
    "    ax[k,l].set_rlabel_position(230)\n",
    "    ax[k,l].tick_params(pad = 7)\n",
    "\n",
    "    ax[k,l].set_xticks(theta[:-1], names)\n",
    "    ax[k,l].set_title(boxnames[i], x=0.50, y=1.15)\n",
    "\n",
    "    l=l+1\n",
    "    if l==5:\n",
    "        l=0\n",
    "        k=k+1\n",
    "\n",
    "fig.legend(['Single', 'Boxes'])\n",
    "fig.suptitle('Importances of Input Features on DPR (R Testing no Seasonality)')\n",
    "\n",
    "ax[k,l].remove()\n",
    "ax[k,l] = fig.add_subplot(2,5,10)\n",
    "\n",
    "ax[k,l].annotate('(j)', (0.00, 1.2), xycoords='axes fraction', fontsize=14)\n",
    "r_importance.plot.barh(ax=ax[k,l])\n",
    "\n",
    "ax[k, l].set_title('Input Feature Importance (Single)')\n",
    "ax[k,l].set_xlabel('Mean accuracy decrease')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radar Plot (RMS Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['(a)','(b)','(c)','(d)','(e)','(f)','(g)','(h)','(i)']\n",
    "\n",
    "k,l = 0,0\n",
    "fig, ax = plt.subplots(2, 5, figsize=(15, 7), layout='constrained', subplot_kw={'projection': 'polar'})\n",
    "\n",
    "for i in range (0, len(boxes)):\n",
    "\n",
    "    theta = np.arange(len(names) + 1) / float(len(names)) * 2 * np.pi\n",
    "\n",
    "    values = np.append(rms_s[:,i], rms_s[:,i][0])\n",
    "    values2 = np.append(rms_b[:,i], rms_b[:,i][0])\n",
    "\n",
    "    ax[k,l].plot(theta, values, marker='o', label ='Single')\n",
    "    # ax[k,l].plot(theta, values2, marker='o', label = 'Boxes')\n",
    "    ax[k,l].plot(np.linspace(0, 2*np.pi, 100), np.full(100, values[0]), ls = '--')\n",
    "\n",
    "    ax[k,l].annotate(labels[i], (0.02, 1.2), xycoords='axes fraction', fontsize=14)\n",
    "\n",
    "    ax[k,l].set_theta_zero_location('N')\n",
    "    # ax[k,l].set_rmax(np.maximum(np.max(values)+0.05, np.max(values2)+0.05))\n",
    "    # ax[k,l].set_rmin(np.minimum(np.min(values)-0.05, np.min(values2)-0.05)) \n",
    "    # ax[k,l].set_rticks(np.round(np.linspace(np.round(np.minimum(np.min(values)-0.05, np.min(values2)-0.05),1), np.round(np.maximum(np.max(values)+0.05, np.max(values2)+0.05),1), 4), 2))\n",
    "\n",
    "    ax[k,l].set_rlabel_position(230)\n",
    "    ax[k,l].tick_params(pad = 7)\n",
    "\n",
    "    ax[k,l].set_xticks(theta[:-1], names)\n",
    "    ax[k,l].set_title(boxnames[i], x=0.50, y=1.15)\n",
    "\n",
    "    l=l+1\n",
    "    if l==5:\n",
    "        l=0\n",
    "        k=k+1\n",
    "\n",
    "fig.legend(['Single', 'Boxes'])\n",
    "fig.suptitle('Importances of Input Features on DPR (RMS Testing)')\n",
    "\n",
    "ax[k,l].remove()\n",
    "ax[k,l] = fig.add_subplot(2,5,10)\n",
    "\n",
    "ax[k,l].annotate('(j)', (0.00, 1.2), xycoords='axes fraction', fontsize=14)\n",
    "rms_importance.plot.barh(ax=ax[k,l])\n",
    "\n",
    "ax[k, l].set_title('Input Feature Importance (Single)')\n",
    "ax[k,l].set_xlabel('Mean accuracy decrease')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/ibougoudis/MOAD/files/results/' + name + '/single_runs/' + name[0:4].lower() + '_pr_hist' + id + '_f_im/'\n",
    "\n",
    "os.makedirs(path, exist_ok=True)\n",
    "with lzma.open(path + 'regr.xz', 'wb') as f:   \n",
    "    dill.dump(regr, f)\n",
    "\n",
    "with open(path + 'r_inputs.pkl', 'wb') as f:\n",
    "    dill.dump(r_inputs, f)\n",
    "\n",
    "with open(path + 'importances.pkl', 'wb') as f:\n",
    "    dill.dump([r_importance, rms_importance], f)\n",
    "\n",
    "with open(path + 'metrics.pkl', 'wb') as f:\n",
    "    dill.dump([boxnames, names, r_s, r_b, rms_s, rms_b], f)\n",
    "\n",
    "with open(path + 'readme.txt', 'w') as f:\n",
    "    f.write ('name: ' + name)\n",
    "    f.write('\\n')\n",
    "    f.write('period: ' + filename[35:42])\n",
    "    f.write ('\\n')\n",
    "    f.write ('input_features: ')\n",
    "    f.write (str([i for i in inputs_names]))\n",
    "    f.write ('\\n')\n",
    "    f.write('n_bins: ' + str(n_bins))\n",
    "    f.write ('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis-ilias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
