{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Diatom concentration with forecasting regression based on the oceanographic boxes (spatial means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xskillscore as xs\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import r_regression\n",
    "\n",
    "from skforecast.recursive import ForecasterRecursive\n",
    "from skforecast.direct import ForecasterDirect\n",
    "from skforecast.preprocessing import RollingFeatures\n",
    "\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error as rmse\n",
    "\n",
    "import os\n",
    "import lzma\n",
    "import dill\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cmocean.cm as cm\n",
    "import salishsea_tools.viz_tools as sa_vi\n",
    "\n",
    "np.warnings.filterwarnings('ignore') # For the nan mean warning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the training - testing datasets\n",
    "def datasets_preparation(dataset, dataset2, regions, name, inputs_names):\n",
    "    \n",
    "    indx = np.where((dataset.time_counter.dt.month==2) & (dataset.time_counter.dt.day==29))\n",
    "    \n",
    "    targets = dataset[name].to_numpy().reshape(*dataset[name].to_numpy().shape[:1],-1)\n",
    "\n",
    "    inputs = []\n",
    "    \n",
    "    for i in inputs_names:\n",
    "        inputs.append(dataset2[i].to_numpy().reshape(*dataset2[i].to_numpy().shape[:1],-1))\n",
    "\n",
    "    inputs = np.array(inputs)\n",
    "\n",
    "    # Deleting 29 of February\n",
    "    inputs = np.delete(inputs,indx,axis=1)\n",
    "    targets = np.delete(targets,indx,axis=0)\n",
    "\n",
    "    # Splitting in years\n",
    "    inputs = np.split(inputs,len(np.unique(dataset.time_counter.dt.year)),axis=1)\n",
    "    targets = np.split(targets,len(np.unique(dataset.time_counter.dt.year)),axis=0)\n",
    "\n",
    "    # Means\n",
    "    inputs = np.nanmean(inputs,axis=0)\n",
    "    targets = np.nanmean(targets,axis=0)\n",
    "\n",
    "    x =  np.tile(dataset2.x, len(dataset2.y))\n",
    "    y =  np.tile(np.repeat(dataset2.y, len(dataset2.x)),1)\n",
    "\n",
    "    indx = np.where((~np.isnan(targets).any(axis=0)) & (x>10) & ((x>100) | (y<880)))\n",
    "    inputs = inputs[:,:,indx[0]]\n",
    "    targets = targets[:,indx[0]]\n",
    "\n",
    "    regions = np.tile(np.ravel(regions), len(dataset.time_counter))\n",
    "    regions = regions[indx[0]]\n",
    "\n",
    "    return(inputs, targets, indx, regions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_creation(path, variable, name):\n",
    "\n",
    "    temp = variable.to_dataset(name=name)\n",
    "    temp.to_netcdf(path = path + 'targets_predictions.nc', mode='a', encoding={name:{\"zlib\": True, \"complevel\": 9}})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(dates,targets, predictions, name):\n",
    "\n",
    "    indx = pd.DatetimeIndex(dates[0:75]) # From the first year\n",
    "\n",
    "    # compute slope m and intercept b\n",
    "    m, b = np.polyfit(targets, predictions, deg=1)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    scatter = ax.scatter(targets,predictions, s = 10, c= indx.month)\n",
    "\n",
    "    lims = [np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()])]\n",
    "\n",
    "    # plot fitted y = m*x + b\n",
    "    ax.axline(xy1=(0, b), slope=m, color='r')\n",
    "\n",
    "    ax.set_xlabel('targets')\n",
    "    ax.set_ylabel('predictions')\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.legend(handles=scatter.legend_elements()[0], labels=['February','March','April'])\n",
    "\n",
    "    ax.plot(lims, lims,linestyle = '--',color = 'k')\n",
    "\n",
    "    fig.suptitle(name)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_training(dataset,dataset2,boxes,regions0,name,inputs_names):\n",
    "\n",
    "    np.warnings.filterwarnings('ignore') # For the nan mean warning\n",
    "\n",
    "    regions_indiv_t = np.zeros((len(np.unique(dataset.time_counter.dt.dayofyear))-1,len(np.unique(dataset.time_counter.dt.year)),len(boxes)))\n",
    "    regions_indiv_d = np.zeros((len(inputs_names),len(np.unique(dataset.time_counter.dt.dayofyear))-1,len(np.unique(dataset.time_counter.dt.year)),len(boxes)))\n",
    "\n",
    "    ds = dataset\n",
    "    ds2 = dataset2\n",
    "\n",
    "    for i in range(0, len(np.unique(ds.time_counter.dt.year))):\n",
    "\n",
    "        dataset = ds.sel(time_counter = slice(str(np.unique(ds.time_counter.dt.year)[i]), str(np.unique(ds.time_counter.dt.year)[i])))\n",
    "        dataset2 = ds2.sel(time_counter = slice(str(np.unique(ds2.time_counter.dt.year)[i]), str(np.unique(ds2.time_counter.dt.year)[i])))\n",
    "\n",
    "        inputs, targets, indx, _ = datasets_preparation(dataset, dataset2, regions0, name, inputs_names)\n",
    "\n",
    "        regions1 = np.ravel(regions0)[indx]\n",
    "\n",
    "        for j in range (0,len(boxes)):\n",
    "\n",
    "            temp = xr.where(regions1==j, inputs, np.nan)\n",
    "            regions_indiv_d[:,:,i,j] = np.nanmean(temp,axis=2)\n",
    "\n",
    "            temp = xr.where(regions1==j, targets, np.nan)\n",
    "            regions_indiv_t[:,i,j] = np.nanmean(temp,axis=1)\n",
    "\n",
    "    return(regions_indiv_d,regions_indiv_t,indx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting (Mean Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_mean_values(dates,boxes,targets,predictions,r_train,rms_train,slope_train,category,units,region,boxnames):\n",
    "\n",
    "    years = np.unique(dates.year)\n",
    "    \n",
    "    ticks = []\n",
    "    for i in range (0,targets.shape[0],75):\n",
    "        ticks.append(i)\n",
    "    \n",
    "    targets_masked = np.ma.array(targets)\n",
    "    predictions_masked = np.ma.array(predictions)\n",
    "\n",
    "    targets_masked[ticks] = np.ma.masked\n",
    "    predictions_masked[ticks] = np.ma.masked\n",
    "\n",
    "    for i in range (0,len(boxes)):\n",
    "\n",
    "        fig, _ = plt.subplots(figsize=(19,5))\n",
    "\n",
    "        temp = pd.DataFrame(np.vstack((r_train[i],rms_train[i],slope_train[i])).transpose(),index=[boxnames[i]],columns=['r','rms','slope'])\n",
    "        display(temp)\n",
    "\n",
    "        plt.plot(targets_masked[:,i], label = 'targets')\n",
    "        plt.plot(predictions_masked[:,i], label = 'predictions')\n",
    "        plt.xlabel('Years')\n",
    "        plt.xticks(ticks,years)\n",
    "        plt.suptitle('Mean '+category + ' ' +units + ' (15 Feb - 30 Apr) ' + region + ' ' + boxnames[i])\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting (Mean Differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_mean_differences(dates,boxes,targets,predictions,category,units,region,boxnames):\n",
    "\n",
    "    years = np.unique(dates.year)\n",
    "    \n",
    "    ticks = []\n",
    "    for i in range (0,targets.shape[0]*targets.shape[1],targets.shape[0]):\n",
    "        ticks.append(i)\n",
    "\n",
    "    targets = np.reshape(targets,(targets.shape[0]*targets.shape[1],targets.shape[2]), order = 'F')\n",
    "    predictions = np.reshape(predictions,(predictions.shape[0]*predictions.shape[1],predictions.shape[2]), order = 'F')\n",
    "    \n",
    "    targets_masked = np.ma.array(targets)\n",
    "    predictions_masked = np.ma.array(predictions)\n",
    "\n",
    "    targets_masked[ticks] = np.ma.masked\n",
    "    predictions_masked[ticks] = np.ma.masked\n",
    "\n",
    "    for i in range (0,len(boxes)):\n",
    "\n",
    "        fig, _ = plt.subplots(figsize=(19,5))\n",
    "\n",
    "        plt.plot(targets_masked[:,i], label = 'targets')\n",
    "        plt.plot(predictions_masked[:,i], label = 'predictions')\n",
    "        plt.xlabel('Years')\n",
    "        plt.xticks(ticks,years)\n",
    "        plt.suptitle('Mean '+category + ' ' +units + ' (15 Feb - 30 Apr) ' + region + ' ' + boxnames[i])\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_training(dates,boxes,targets,predictions,category,units,region,boxnames):\n",
    "\n",
    "    r_train = np.full(len(boxes),np.nan)\n",
    "    rms_train = np.full(len(boxes),np.nan)\n",
    "    slope_train = np.full(len(boxes),np.nan)\n",
    "\n",
    "    for i in range (0,len(boxes)):\n",
    "\n",
    "        r_train[i] = np.round(np.corrcoef(np.ravel(targets[:,i]),np.ravel(predictions[:,i]))[0][1],3)\n",
    "        rms_train[i] = rmse(np.ravel(targets[:,i]),np.ravel(predictions[:,i]))\n",
    "        m,_ = np.polyfit(np.ravel(targets[:,i]),np.ravel(predictions[:,i]), deg=1)\n",
    "        slope_train[i] = np.round(m,3)\n",
    "    \n",
    "    plotting_mean_values(dates,boxes,targets,predictions,r_train,rms_train,slope_train,category,units,region,boxnames)\n",
    "\n",
    "    return(r_train,rms_train,slope_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting (regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(ax, corn, colour):\n",
    "\n",
    "    ax.plot([corn[2], corn[3], corn[3], corn[2], corn[2]], \n",
    "    [corn[0], corn[0], corn[1], corn[1], corn[0]], '-', color=colour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Diatom'\n",
    "units = '[mmol m-2]'\n",
    "category = 'Concentrations'\n",
    "\n",
    "if name == 'Diatom':\n",
    "    inputs_names = ['Summation_of_solar_radiation','Mean_wind_speed','Mean_air_temperature']\n",
    "    lags = [13,13,4,11,30,22,29,19,3]\n",
    "else:\n",
    "    inputs_names = ['Summation_of_solar_radiation','Mean_air_temperature','Mean_pressure', 'Mean_precipitation', 'Mean_specific_humidity']\n",
    "    lags = [28,4,4,3,30,8,12,11,24]\n",
    "\n",
    "ds = xr.open_dataset('/data/ibougoudis/MOAD/files/integrated_original.nc')\n",
    "ds2 = xr.open_dataset('/data/ibougoudis/MOAD/files/external_inputs.nc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 9))\n",
    "mycmap = cm.deep\n",
    "mycmap.set_bad('grey')\n",
    "ax.pcolormesh(ds['Diatom'][0], cmap=mycmap)\n",
    "sa_vi.set_aspect(ax)\n",
    "\n",
    "SoG_north = [650, 730, 100, 200]\n",
    "plot_box(ax, SoG_north, 'g')\n",
    "SoG_center = [450, 550, 200, 300]\n",
    "plot_box(ax, SoG_center, 'b')\n",
    "Fraser_plume = [380, 460, 260, 330]\n",
    "plot_box(ax, Fraser_plume, 'm')\n",
    "SoG_south = [320, 380, 280, 350]\n",
    "plot_box(ax, SoG_south, 'k')\n",
    "Haro_Boundary = [290, 350, 210, 280]\n",
    "plot_box(ax, Haro_Boundary, 'm')\n",
    "JdF_west = [250, 425, 25, 125]\n",
    "plot_box(ax, JdF_west, 'c')\n",
    "JdF_east = [200, 290, 150, 260]\n",
    "plot_box(ax, JdF_east, 'w')\n",
    "PS_all = [0, 200, 80, 320]\n",
    "plot_box(ax, PS_all, 'm')\n",
    "PS_main = [20, 150, 200, 280]\n",
    "plot_box(ax, PS_main, 'r')\n",
    "\n",
    "boxnames = ['SoG_north','SoG_center','Fraser_plume','SoG_south', 'Haro_Boundary', 'JdF_west', 'JdF_east', 'PS_all', 'PS_main']\n",
    "fig.legend(boxnames)\n",
    "\n",
    "boxes = [SoG_north,SoG_center,Fraser_plume,SoG_south,Haro_Boundary,JdF_west,JdF_east,PS_all,PS_main]\n",
    "\n",
    "regions0 = np.full((len(ds.y),len(ds.x)),np.nan)\n",
    "\n",
    "for i in range (0, len(boxes)):\n",
    "    regions0[boxes[i][0]:boxes[i][1], boxes[i][2]:boxes[i][3]] = i\n",
    "\n",
    "regions0 = xr.DataArray(regions0,dims = ['y','x'])\n",
    "\n",
    "# # Low resolution\n",
    "# temp = []\n",
    "\n",
    "# for i in boxes:\n",
    "#     temp.append([x//5 for x in i])\n",
    "\n",
    "# boxes = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low resolution\n",
    "\n",
    "# ds = ds.isel(y=(np.arange(ds.y[0], ds.y[-1], 5)), \n",
    "#     x=(np.arange(ds.x[0], ds.x[-1], 5)))\n",
    "\n",
    "# ds2 = ds2.isel(y=(np.arange(ds2.y[0], ds2.y[-1], 5)), \n",
    "#     x=(np.arange(ds2.x[0], ds2.x[-1], 5)))\n",
    "\n",
    "# regions0 = regions0.isel(y=(np.arange(regions0.y[0], regions0.y[-1], 5)), \n",
    "#     x=(np.arange(regions0.x[0], regions0.x[-1], 5)))\n",
    "\n",
    "dataset = ds.sel(time_counter = slice('2007', '2020'))\n",
    "dataset2 = ds2.sel(time_counter = slice('2007', '2020'))\n",
    "\n",
    "years = np.unique(dataset.time_counter.dt.year)\n",
    "\n",
    "r_inputs = np.zeros((len(boxnames), len(inputs_names)))\n",
    "\n",
    "inputs0,targets0,indx = pre_training(dataset,dataset2,boxes,regions0,name,inputs_names)\n",
    "\n",
    "inputs = np.reshape(inputs0,(len(inputs_names),targets0.shape[0]*targets0.shape[1],len(boxes)),order='F')\n",
    "targets = np.reshape(targets0,(targets0.shape[0]*targets0.shape[1],len(boxes)),order='F')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds.sel(time_counter = slice('2007', '2020'))\n",
    "dates = pd.DatetimeIndex(dataset['time_counter'].values)\n",
    "indx2 = ~((dataset.time_counter.dt.month==2) & (dataset.time_counter.dt.day==29))\n",
    "dates = dates[indx2]\n",
    "\n",
    "day = dataset.time_counter.dt.dayofyear[indx2].values\n",
    "\n",
    "day = np.tile(day,len(boxes))\n",
    "day = np.reshape(day, (len(dates),len(boxes)), order='F')\n",
    "day = np.expand_dims(day, axis=0)\n",
    "\n",
    "inputs_names2=list(inputs_names) # For the Dataframes \n",
    "\n",
    "inputs_names2.append('day')\n",
    "inputs = np.vstack((inputs,day))\n",
    "\n",
    "inputs_training = []\n",
    "targets_training = []\n",
    "\n",
    "regr_all = []\n",
    "predictions = np.full(targets.shape,np.nan)\n",
    "\n",
    "for i in range (0,len(boxnames)):\n",
    "    \n",
    "    temp = pd.DataFrame(inputs[:,:,i].transpose(),dates,columns=inputs_names2)\n",
    "    temp.rename_axis('date')\n",
    "    inputs_training.append(temp)\n",
    "\n",
    "    temp = pd.DataFrame({name:targets[:,i]},dates)\n",
    "    temp.rename_axis('date')\n",
    "    targets_training.append(temp)\n",
    "\n",
    "    forecaster = ForecasterRecursive(regressor= BaggingRegressor(estimator=HistGradientBoostingRegressor(categorical_features=['day']), n_estimators=12), lags=lags[i])\n",
    "    forecaster.fit(y=targets_training[i][name], exog=inputs_training[i])\n",
    "    regr_all.append(forecaster)\n",
    "\n",
    "    predictions[:,i] = regr_all[i].predict(steps=len(dates), exog=inputs_training[i], check_inputs=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-series (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_train,rms_train,slope_train = post_training(dates,boxes,targets,predictions,units,category,' ',boxnames)\n",
    "\n",
    "season = np.mean(targets0,axis=1)\n",
    "\n",
    "season_train = np.tile(season,len(np.unique(dates.year))) # Broadcasting season to all training years\n",
    "season_train = np.reshape(season_train,targets0.shape)\n",
    "season_train = np.reshape(season_train,targets.shape,order='F')\n",
    "\n",
    "plt.plot(season)\n",
    "plt.legend(boxnames)\n",
    "plt.suptitle('Long-term seasonalities (2007-2020, targets)')\n",
    "plt.show()\n",
    "\n",
    "r_train_season,_,slope_train_season = post_training(dates,boxes,targets-season_train,predictions-season_train,units,category,'(removed seasonality)',boxnames)\n",
    "\n",
    "# Differences for the testing time-series\n",
    "diff = np.zeros(len(boxes))\n",
    "\n",
    "for i in range (0, len(boxes)):\n",
    "    mean = np.mean(targets0[:,:,i])\n",
    "    std = np.mean(targets0[:,:,i])\n",
    "    diff[i] = mean + 0*std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds.sel(time_counter = slice('2021', '2024'))\n",
    "dataset2 = ds2.sel(time_counter = slice('2021', '2024'))\n",
    "\n",
    "dates = pd.DatetimeIndex(dataset['time_counter'].values)\n",
    "indx = ~((dataset.time_counter.dt.month==2) & (dataset.time_counter.dt.day==29))\n",
    "dates = dates[indx]\n",
    "\n",
    "years = np.unique(dataset.time_counter.dt.year)\n",
    "\n",
    "inputs0_test,targets0_test,indx_test = pre_training(dataset,dataset2,boxes,regions0,name,inputs_names)\n",
    "\n",
    "inputs_test = np.reshape(inputs0_test, (len(inputs_names),targets0.shape[0]*len(years),len(boxnames)), order='F')\n",
    "targets_test = np.reshape(targets0_test, (targets0.shape[0]*len(years),len(boxnames)), order='F')\n",
    "\n",
    "day = dataset.time_counter.dt.dayofyear[indx].values\n",
    "\n",
    "day = np.tile(day,len(boxes))\n",
    "day = np.reshape(day, (len(dates),len(boxes)), order='F')\n",
    "day = np.expand_dims(day,axis=0)\n",
    "\n",
    "inputs_test = np.vstack((inputs_test,day))\n",
    "\n",
    "season_test = np.tile(season,len(years)) # Broadcasting season to all testing years\n",
    "season0_test = np.reshape(season_test, targets0_test.shape) # Needed for the annual calculations\n",
    "season_test = np.reshape(season0_test, targets_test.shape, order='F')\n",
    "\n",
    "inputs_testing = []\n",
    "\n",
    "predictions_test = np.full(targets_test.shape,np.nan)\n",
    "\n",
    "for i in range (0,len(boxnames)):\n",
    "    \n",
    "    temp = pd.DataFrame(inputs_test[:,:,i].transpose(),dates,columns=inputs_names2)\n",
    "    temp.rename_axis('date')\n",
    "    inputs_testing.append(temp)\n",
    "\n",
    "    predictions_test[:,i] = regr_all[i].predict(steps=len(dates), exog=inputs_testing[i], check_inputs=False)\n",
    "\n",
    "predictions0_test = predictions_test.reshape(targets0_test.shape, order='F')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-series (Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_test,rms_test,slope_test = np.zeros(len(boxes)), np.zeros(len(boxes)), np.zeros(len(boxes))\n",
    "\n",
    "r_test_season, slope_test_season = np.zeros(len(boxes)), np.zeros(len(boxes))\n",
    "\n",
    "targets_sum, predictions_sum = np.zeros((len(boxes),len(years))), np.zeros((len(boxes),len(years)))\n",
    "\n",
    "targets_mean, predictions_mean = np.zeros((len(boxes),len(years))), np.zeros((len(boxes),len(years)))\n",
    "\n",
    "targets_diff, predictions_diff = np.zeros((len(boxes),targets0_test.shape[0],len(years))), np.zeros((len(boxes),targets0_test.shape[0],len(years)))\n",
    "\n",
    "rss = np.zeros(len(boxes))\n",
    "\n",
    "r_test_season,_,slope_test_season = post_training(dates,boxes,targets_test-season_test,predictions_test-season_test,units,category,'(removed Seasonality)',boxnames)\n",
    "\n",
    "for i in range (0,len(boxes)):\n",
    "\n",
    "    r_test[i] = np.round(np.corrcoef(np.ravel(targets_test[:,i]),np.ravel(predictions_test[:,i]))[0][1],3)\n",
    "    rms_test[i] = rmse(np.ravel(targets_test[:,i]),np.ravel(predictions_test[:,i]))\n",
    "    m,_ = np.polyfit(np.ravel(targets_test[:,i]),np.ravel(predictions_test[:,i]), deg=1)\n",
    "    slope_test[i] = np.round(m,3)\n",
    "\n",
    "    rss[i] = np.sum((np.ravel(targets_test[:,i])-np.ravel(predictions_test[:,i]))**2) # Similar to rms, is not affected by the seasonality\n",
    "\n",
    "    for j in range (0, len(years)):\n",
    "\n",
    "        targets_sum[i,j] = np.sum(targets0_test[:,j,i]-season0_test[:,j,i])\n",
    "        predictions_sum[i,j] = np.sum(predictions0_test[:,j,i]-season0_test[:,j,i])\n",
    "\n",
    "        targets_mean[i,j] = np.mean(targets0_test[:,j,i]-season0_test[:,j,i])\n",
    "        predictions_mean[i,j] = np.mean(predictions0_test[:,j,i]-season0_test[:,j,i])\n",
    "\n",
    "        targets_diff[i,:,j] = np.where(targets0_test[:,j,i]>diff[i],targets0_test[:,j,i], np.nan)\n",
    "        predictions_diff[i,:,j] = np.where(predictions0_test[:,j,i]>diff[i],predictions0_test[:,j,i], np.nan)\n",
    "\n",
    "targets_diff = np.transpose(targets_diff,(1,2,0))\n",
    "predictions_diff = np.transpose(predictions_diff,(1,2,0))\n",
    "plotting_mean_differences(dates,boxes,targets_diff,predictions_diff,category,units,'Differences',boxnames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/data/ibougoudis/MOAD/files/results/' + name + '/for_reg_boxes_s3/'\n",
    "\n",
    "# os.makedirs(path, exist_ok=True)\n",
    "# with lzma.open(path + 'regr_all.xz', 'wb') as f:\n",
    "    \n",
    "#     dill.dump(regr_all, f)\n",
    "\n",
    "# with open(path + 'train_metrics.pkl', 'wb') as f:\n",
    "#     dill.dump([r_train,rms_train,slope_train,r_train_season,slope_train_season,season.transpose()], f)\n",
    "\n",
    "# with open(path + 'test_metrics.pkl', 'wb') as f:\n",
    "#     dill.dump([r_test,rms_test,slope_test,r_test_season,slope_test_season,targets_sum,predictions_sum,targets_mean,predictions_mean,targets_diff,predictions_diff,rss], f)\n",
    "\n",
    "# with open(path + 'targets-predictions.pkl', 'wb') as f:\n",
    "#     dill.dump([targets0_test,predictions0_test], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
