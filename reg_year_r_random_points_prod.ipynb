{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "import os\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import dill\n",
    "import random\n",
    "\n",
    "import salishsea_tools.viz_tools as sa_vi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets_preparation ():\n",
    "    \n",
    "     ds_name = ('/results2/SalishSea/nowcast-green.202111/' + i + '/SalishSea_1d_' + '20' + str(i[5:7]) + str(dict_month[i[2:5]])+str(i[0:2]) + '_' + '20' + str(i[5:7]) + str(dict_month[i[2:5]]) + str(i[0:2]) + '_grid_T.nc')\n",
    "     ds_bio_name = ('/results2/SalishSea/nowcast-green.202111/' + i + '/SalishSea_1d_'  + '20' + str(i[5:7]) + str(dict_month[i[2:5]])+str(i[0:2]) + '_' + '20' + str(i[5:7]) + str(dict_month[i[2:5]]) + str(i[0:2]) + '_biol_T.nc')\n",
    "     ds_prod_name = ('/results2/SalishSea/nowcast-green.202111/' + i + '/SalishSea_1d_'  + '20' + str(i[5:7]) + str(dict_month[i[2:5]])+str(i[0:2]) + '_' + '20' + str(i[5:7]) + str(dict_month[i[2:5]]) + str(i[0:2]) + '_prod_T.nc')\n",
    "\n",
    "     ds = xr.open_dataset (ds_name)\n",
    "     ds_bio = xr. open_dataset (ds_bio_name)\n",
    "     ds_prod = xr.open_dataset(ds_prod_name)\n",
    "\n",
    "     date = pd.DatetimeIndex(ds['time_counter'].values)\n",
    "\n",
    "     temp_i1 = (ds.votemper.where(mask==1)[0,0:15] * ds.e3t.where(mask==1)\n",
    "          [0,0:15]).sum('deptht', skipna = True, min_count = 15) / mesh.gdepw_0[0,15]\n",
    "     temp_i2 = (ds.votemper.where(mask==1)[0,15:27] * ds.e3t.where(mask==1)\n",
    "          [0,15:27]).sum('deptht', skipna = True, min_count = 12) / (mesh.gdepw_0[0,27] - mesh.gdepw_0[0,14])\n",
    "     saline_i1 = (ds.vosaline.where(mask==1)[0,0:15] * ds.e3t.where(mask==1)\n",
    "          [0,0:15]).sum('deptht', skipna = True, min_count = 15) / mesh.gdepw_0[0,15]\n",
    "     saline_i2 = (ds.vosaline.where(mask==1)[0,15:27] * ds.e3t.where(mask==1)\n",
    "          [0,15:27]).sum('deptht', skipna = True, min_count = 12) / (mesh.gdepw_0[0,27] - mesh.gdepw_0[0,14])\n",
    "\n",
    "     diat_i = ((ds_prod.PPDIAT.where(mask==1)[0,0:27] * ds.e3t.where(mask==1)\n",
    "          [0,0:27]).sum('deptht', skipna = True, min_count = 27) / mesh.gdepw_0[0,27]) / ((ds_bio.diatoms.where(mask==1)[0,0:27] * ds.e3t.where(mask==1)\n",
    "          [0,0:27]).sum('deptht', skipna = True, min_count = 27) / mesh.gdepw_0[0,27])\n",
    "     # flag_i = (ds_bio.flagellates.where(mask==1)[0,0:27] * ds.e3t.where(mask==1)\n",
    "     #      [0,0:27]).sum('deptht', skipna = True, min_count = 27) / mesh.gdepw_0[0,27]\n",
    "\n",
    "     return (date, temp_i1, temp_i2, saline_i1, saline_i2, diat_i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor (inputs, targets):\n",
    "    \n",
    "    inputs = inputs.transpose()\n",
    "    \n",
    "    # Regressor\n",
    "    scale = preprocessing.StandardScaler()\n",
    "    inputs = scale.fit_transform(inputs)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(inputs, targets, train_size=0.35)\n",
    "\n",
    "    drivers_all = np.array([[],[],[],[]])\n",
    "    diat_all = np.array([])\n",
    "    inputs = np.array([[],[],[],[]])\n",
    "    targets = np.array([])\n",
    "\n",
    "    model = MLPRegressor(hidden_layer_sizes=200, alpha=0.002)\n",
    "    regr = BaggingRegressor(model, n_estimators=12, n_jobs=4).fit(X_train, y_train) \n",
    "\n",
    "    return (regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printing (targets, outputs, m):\n",
    "\n",
    "    print ('The amount of data points is', outputs.size)\n",
    "    print ('The slope of the best fitting line is ', np.round(m,3))\n",
    "    print ('The correlation coefficient is:', np.round(np.corrcoef(targets, outputs)[0][1],3))\n",
    "    print (' The mean square error is:', np.round(mse(targets,outputs),5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(targets, outputs, variable_name):\n",
    "\n",
    "    # compute slope m and intercept b\n",
    "    m, b = np.polyfit(targets, outputs, deg=1)\n",
    "\n",
    "    printing(targets, outputs, m)\n",
    "\n",
    "    fig, ax = plt.subplots(2, figsize=(5,10), layout='constrained')\n",
    "\n",
    "    ax[0].scatter(targets,outputs, alpha = 0.2, s = 10)\n",
    "\n",
    "    lims = [np.min([ax[0].get_xlim(), ax[0].get_ylim()]),\n",
    "        np.max([ax[0].get_xlim(), ax[0].get_ylim()]),]\n",
    "\n",
    "    # plot fitted y = m*x + b\n",
    "    ax[0].axline(xy1=(0, b), slope=m, color='r')\n",
    "\n",
    "    ax[0].set_xlabel('targets')\n",
    "    ax[0].set_ylabel('outputs')\n",
    "    ax[0].set_xlim(lims)\n",
    "    ax[0].set_ylim(lims)\n",
    "    ax[0].set_aspect('equal')\n",
    "\n",
    "    ax[0].plot(lims, lims,linestyle = '--',color = 'k')\n",
    "\n",
    "    h = ax[1].hist2d(targets,outputs, bins=100, cmap='jet', \n",
    "        range=[lims,lims], cmin=0.1, norm='log')\n",
    "    \n",
    "    ax[1].plot(lims, lims,linestyle = '--',color = 'k')\n",
    "\n",
    "    # plot fitted y = m*x + b\n",
    "    ax[1].axline(xy1=(0, b), slope=m, color='r')\n",
    "\n",
    "    ax[1].set_xlabel('targets')\n",
    "    ax[1].set_ylabel('outputs')\n",
    "    ax[1].set_aspect('equal')\n",
    "\n",
    "    fig.colorbar(h[3],ax=ax[1], location='bottom')\n",
    "\n",
    "    fig.suptitle(variable_name)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return (m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(variable, name):\n",
    "\n",
    "    plt.plot(years,variable, marker = '.', linestyle = '')\n",
    "    plt.legend(['diatom','flagellate'])\n",
    "    plt.xlabel('Years')\n",
    "    plt.ylabel(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting2(variable,title):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    scatter= ax.scatter(dates,variable, marker='.', c=pd.DatetimeIndex(dates).month)\n",
    "\n",
    "    ax.legend(handles=scatter.legend_elements()[0], labels=['February','March','April'])\n",
    "    fig.suptitle('Daily ' + title + ' (15 Feb - 30 Apr)')\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting3(targets, model, variable, variable_name):\n",
    "\n",
    "    fig, ax = plt.subplots(2,2, figsize = (10,15))\n",
    "\n",
    "    cmap = plt.get_cmap('cubehelix')\n",
    "    cmap.set_bad('gray')\n",
    "\n",
    "    variable.plot(ax=ax[0,0], cmap=cmap, vmin = targets.min(), vmax =targets.max(), cbar_kwargs={'label': variable_name + ' Concentration  [mmol m-2]'})\n",
    "    model.plot(ax=ax[0,1], cmap=cmap, vmin = targets.min(), vmax = targets.max(), cbar_kwargs={'label': variable_name + ' Concentration  [mmol m-2]'})\n",
    "    ((variable-model) / variable * 100).plot(ax=ax[1,0], cmap=cmap, cbar_kwargs={'label': variable_name + ' Concentration  [percentage]'})\n",
    "\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "        bottom=0.1, \n",
    "        right=0.95, \n",
    "        top=0.95, \n",
    "        wspace=0.35, \n",
    "        hspace=0.35)\n",
    "\n",
    "    sa_vi.set_aspect(ax[0,0])\n",
    "    sa_vi.set_aspect(ax[0,1])\n",
    "    sa_vi.set_aspect(ax[1,0])\n",
    "\n",
    "\n",
    "    ax[0,0].title.set_text(variable_name + ' (targets)')\n",
    "    ax[0,1].title.set_text(variable_name + ' (outputs)')\n",
    "    ax[1,0].title.set_text('targets - outputs')\n",
    "    ax[1,1].axis('off')\n",
    "\n",
    "    fig.suptitle(str(date.date[0]))\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressor 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor2 (inputs, targets, variable_name):\n",
    "    \n",
    "    inputs = inputs.transpose()\n",
    "    \n",
    "    # Regressor\n",
    "    scale = preprocessing.StandardScaler()\n",
    "    inputs2 = scale.fit_transform(inputs)\n",
    "\n",
    "    outputs_test = regr.predict(inputs2)\n",
    "   \n",
    "    m = scatter_plot(targets, outputs_test, variable_name) \n",
    "    r = np.round(np.corrcoef(targets, outputs_test)[0][1],3)\n",
    "    rms = np.round(mse(targets, outputs_test),4)\n",
    "\n",
    "    return (r, rms, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressor 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor3 (inputs, targets, variable_name):\n",
    "    \n",
    "    inputs = inputs.transpose()\n",
    "    \n",
    "    # Regressor\n",
    "    scale = preprocessing.StandardScaler()\n",
    "    inputs2 = scale.fit_transform(inputs)\n",
    "\n",
    "    outputs = regr.predict(inputs2)\n",
    "\n",
    "    # Post processing\n",
    "    indx2 = np.full((898*398),np.nan)\n",
    "    indx2[indx[0]] = outputs\n",
    "    model = np.reshape(indx2,(898,398)) \n",
    "\n",
    "    m = scatter_plot(targets, outputs, variable_name + str(date.date[0])) \n",
    "\n",
    "    # Preparation of the dataarray \n",
    "    model = xr.DataArray(model,\n",
    "        coords = {'y': diat_i.y, 'x': diat_i.x},\n",
    "        dims = ['y','x'],\n",
    "        attrs=dict( long_name = variable_name + \" Concentration\",\n",
    "        units=\"mmol m-2\"),)\n",
    "                        \n",
    "    plotting3(targets, model, diat_i, variable_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressor 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor4 (inputs, targets, variable_name):\n",
    "    \n",
    "    inputs = inputs.transpose()\n",
    "    \n",
    "    # Regressor\n",
    "    scale = preprocessing.StandardScaler()\n",
    "    inputs2 = scale.fit_transform(inputs)\n",
    "\n",
    "    outputs_test = regr.predict(inputs2)\n",
    "   \n",
    "    # compute slope m and intercept b\n",
    "    m, b = np.polyfit(targets, outputs_test, deg=1)\n",
    "    \n",
    "    r = np.round(np.corrcoef(targets, outputs_test)[0][1],3)\n",
    "    rms = np.round(mse(targets, outputs_test),4)\n",
    "\n",
    "    return (r, rms, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (Random Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering days for the model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9db958934246f4b63dfe414f9948fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGathering days for the model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(folders):\n\u001b[0;32m---> 31\u001b[0m     date, temp_i1, temp_i2, saline_i1, saline_i2, diat_i \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets_preparation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     drivers \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([np\u001b[38;5;241m.\u001b[39mravel(temp_i1), np\u001b[38;5;241m.\u001b[39mravel(temp_i2), np\u001b[38;5;241m.\u001b[39mravel(saline_i1), np\u001b[38;5;241m.\u001b[39mravel(saline_i2)])\n\u001b[1;32m     34\u001b[0m     indx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39misnan(drivers)\u001b[38;5;241m.\u001b[39many(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m, in \u001b[0;36mdatasets_preparation\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m temp_i1 \u001b[38;5;241m=\u001b[39m (ds\u001b[38;5;241m.\u001b[39mvotemper\u001b[38;5;241m.\u001b[39mwhere(mask\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m15\u001b[39m] \u001b[38;5;241m*\u001b[39m ds\u001b[38;5;241m.\u001b[39me3t\u001b[38;5;241m.\u001b[39mwhere(mask\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m      [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m15\u001b[39m])\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeptht\u001b[39m\u001b[38;5;124m'\u001b[39m, skipna \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, min_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m) \u001b[38;5;241m/\u001b[39m mesh\u001b[38;5;241m.\u001b[39mgdepw_0[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m15\u001b[39m]\n\u001b[1;32m     15\u001b[0m temp_i2 \u001b[38;5;241m=\u001b[39m (ds\u001b[38;5;241m.\u001b[39mvotemper\u001b[38;5;241m.\u001b[39mwhere(mask\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m15\u001b[39m:\u001b[38;5;241m27\u001b[39m] \u001b[38;5;241m*\u001b[39m ds\u001b[38;5;241m.\u001b[39me3t\u001b[38;5;241m.\u001b[39mwhere(mask\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m      [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m15\u001b[39m:\u001b[38;5;241m27\u001b[39m])\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeptht\u001b[39m\u001b[38;5;124m'\u001b[39m, skipna \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, min_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m) \u001b[38;5;241m/\u001b[39m (mesh\u001b[38;5;241m.\u001b[39mgdepw_0[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m27\u001b[39m] \u001b[38;5;241m-\u001b[39m mesh\u001b[38;5;241m.\u001b[39mgdepw_0[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m14\u001b[39m])\n\u001b[0;32m---> 17\u001b[0m saline_i1 \u001b[38;5;241m=\u001b[39m (\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvosaline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m15\u001b[39m] \u001b[38;5;241m*\u001b[39m ds\u001b[38;5;241m.\u001b[39me3t\u001b[38;5;241m.\u001b[39mwhere(mask\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     18\u001b[0m      [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m15\u001b[39m])\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeptht\u001b[39m\u001b[38;5;124m'\u001b[39m, skipna \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, min_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m) \u001b[38;5;241m/\u001b[39m mesh\u001b[38;5;241m.\u001b[39mgdepw_0[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m15\u001b[39m]\n\u001b[1;32m     19\u001b[0m saline_i2 \u001b[38;5;241m=\u001b[39m (ds\u001b[38;5;241m.\u001b[39mvosaline\u001b[38;5;241m.\u001b[39mwhere(mask\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m15\u001b[39m:\u001b[38;5;241m27\u001b[39m] \u001b[38;5;241m*\u001b[39m ds\u001b[38;5;241m.\u001b[39me3t\u001b[38;5;241m.\u001b[39mwhere(mask\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     20\u001b[0m      [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m15\u001b[39m:\u001b[38;5;241m27\u001b[39m])\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeptht\u001b[39m\u001b[38;5;124m'\u001b[39m, skipna \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, min_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m) \u001b[38;5;241m/\u001b[39m (mesh\u001b[38;5;241m.\u001b[39mgdepw_0[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m27\u001b[39m] \u001b[38;5;241m-\u001b[39m mesh\u001b[38;5;241m.\u001b[39mgdepw_0[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m14\u001b[39m])\n\u001b[1;32m     22\u001b[0m diat_i \u001b[38;5;241m=\u001b[39m ((ds_prod\u001b[38;5;241m.\u001b[39mPPDIAT\u001b[38;5;241m.\u001b[39mwhere(mask\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m27\u001b[39m] \u001b[38;5;241m*\u001b[39m ds\u001b[38;5;241m.\u001b[39me3t\u001b[38;5;241m.\u001b[39mwhere(mask\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     23\u001b[0m      [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m27\u001b[39m])\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeptht\u001b[39m\u001b[38;5;124m'\u001b[39m, skipna \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, min_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m27\u001b[39m) \u001b[38;5;241m/\u001b[39m mesh\u001b[38;5;241m.\u001b[39mgdepw_0[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m27\u001b[39m]) \u001b[38;5;241m/\u001b[39m ((ds_bio\u001b[38;5;241m.\u001b[39mdiatoms\u001b[38;5;241m.\u001b[39mwhere(mask\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m27\u001b[39m] \u001b[38;5;241m*\u001b[39m ds\u001b[38;5;241m.\u001b[39me3t\u001b[38;5;241m.\u001b[39mwhere(mask\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     24\u001b[0m      [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m27\u001b[39m])\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeptht\u001b[39m\u001b[38;5;124m'\u001b[39m, skipna \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, min_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m27\u001b[39m) \u001b[38;5;241m/\u001b[39m mesh\u001b[38;5;241m.\u001b[39mgdepw_0[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m27\u001b[39m])\n",
      "File \u001b[0;32m~/conda_envs/analysis-ilias/lib/python3.11/site-packages/xarray/core/common.py:1184\u001b[0m, in \u001b[0;36mDataWithCoords.where\u001b[0;34m(self, cond, other, drop)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mindexers)\n\u001b[1;32m   1182\u001b[0m     cond \u001b[38;5;241m=\u001b[39m cond\u001b[38;5;241m.\u001b[39misel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mindexers)\n\u001b[0;32m-> 1184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda_envs/analysis-ilias/lib/python3.11/site-packages/xarray/core/ops.py:178\u001b[0m, in \u001b[0;36mwhere_method\u001b[0;34m(self, cond, other)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# alignment for three arguments is complicated, so don't support it yet\u001b[39;00m\n\u001b[1;32m    177\u001b[0m join \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m other \u001b[38;5;129;01mis\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39mNA \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexact\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_ufunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mduck_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_join\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallowed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda_envs/analysis-ilias/lib/python3.11/site-packages/xarray/core/computation.py:1267\u001b[0m, in \u001b[0;36mapply_ufunc\u001b[0;34m(func, input_core_dims, output_core_dims, exclude_dims, vectorize, join, dataset_join, dataset_fill_value, keep_attrs, kwargs, dask, output_dtypes, output_sizes, meta, dask_gufunc_kwargs, on_missing_core_dim, *args)\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;66;03m# feed DataArray apply_variable_ufunc through apply_dataarray_vfunc\u001b[39;00m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(a, DataArray) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[0;32m-> 1267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_dataarray_vfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariables_vfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;66;03m# feed Variables directly through apply_variable_ufunc\u001b[39;00m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(a, Variable) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args):\n",
      "File \u001b[0;32m~/conda_envs/analysis-ilias/lib/python3.11/site-packages/xarray/core/computation.py:315\u001b[0m, in \u001b[0;36mapply_dataarray_vfunc\u001b[0;34m(func, signature, join, exclude_dims, keep_attrs, *args)\u001b[0m\n\u001b[1;32m    310\u001b[0m result_coords, result_indexes \u001b[38;5;241m=\u001b[39m build_output_coords_and_indexes(\n\u001b[1;32m    311\u001b[0m     args, signature, exclude_dims, combine_attrs\u001b[38;5;241m=\u001b[39mkeep_attrs\n\u001b[1;32m    312\u001b[0m )\n\u001b[1;32m    314\u001b[0m data_vars \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mgetattr\u001b[39m(a, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable\u001b[39m\u001b[38;5;124m\"\u001b[39m, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m--> 315\u001b[0m result_var \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m out: \u001b[38;5;28mtuple\u001b[39m[DataArray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m|\u001b[39m DataArray\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signature\u001b[38;5;241m.\u001b[39mnum_outputs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/conda_envs/analysis-ilias/lib/python3.11/site-packages/xarray/core/computation.py:733\u001b[0m, in \u001b[0;36mapply_variable_ufunc\u001b[0;34m(func, signature, exclude_dims, dask, output_dtypes, vectorize, keep_attrs, dask_gufunc_kwargs, *args)\u001b[0m\n\u001b[1;32m    728\u001b[0m broadcast_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    729\u001b[0m     dim \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m dim_sizes \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m signature\u001b[38;5;241m.\u001b[39mall_core_dims\n\u001b[1;32m    730\u001b[0m )\n\u001b[1;32m    731\u001b[0m output_dims \u001b[38;5;241m=\u001b[39m [broadcast_dims \u001b[38;5;241m+\u001b[39m out \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m signature\u001b[38;5;241m.\u001b[39moutput_core_dims]\n\u001b[0;32m--> 733\u001b[0m input_data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbroadcast_compat_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbroadcast_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcore_dims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVariable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcore_dims\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_core_dims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(is_chunked_array(array) \u001b[38;5;28;01mfor\u001b[39;00m array \u001b[38;5;129;01min\u001b[39;00m input_data):\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforbidden\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/conda_envs/analysis-ilias/lib/python3.11/site-packages/xarray/core/computation.py:734\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    728\u001b[0m broadcast_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    729\u001b[0m     dim \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m dim_sizes \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m signature\u001b[38;5;241m.\u001b[39mall_core_dims\n\u001b[1;32m    730\u001b[0m )\n\u001b[1;32m    731\u001b[0m output_dims \u001b[38;5;241m=\u001b[39m [broadcast_dims \u001b[38;5;241m+\u001b[39m out \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m signature\u001b[38;5;241m.\u001b[39moutput_core_dims]\n\u001b[1;32m    733\u001b[0m input_data \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 734\u001b[0m     \u001b[43mbroadcast_compat_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbroadcast_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcore_dims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, Variable)\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m arg\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg, core_dims \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(args, signature\u001b[38;5;241m.\u001b[39minput_core_dims)\n\u001b[1;32m    738\u001b[0m ]\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(is_chunked_array(array) \u001b[38;5;28;01mfor\u001b[39;00m array \u001b[38;5;129;01min\u001b[39;00m input_data):\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforbidden\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/conda_envs/analysis-ilias/lib/python3.11/site-packages/xarray/core/computation.py:656\u001b[0m, in \u001b[0;36mbroadcast_compat_data\u001b[0;34m(variable, broadcast_dims, core_dims)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbroadcast_compat_data\u001b[39m(\n\u001b[1;32m    652\u001b[0m     variable: Variable,\n\u001b[1;32m    653\u001b[0m     broadcast_dims: \u001b[38;5;28mtuple\u001b[39m[Hashable, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m],\n\u001b[1;32m    654\u001b[0m     core_dims: \u001b[38;5;28mtuple\u001b[39m[Hashable, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m],\n\u001b[1;32m    655\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 656\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mvariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\n\u001b[1;32m    658\u001b[0m     old_dims \u001b[38;5;241m=\u001b[39m variable\u001b[38;5;241m.\u001b[39mdims\n\u001b[1;32m    659\u001b[0m     new_dims \u001b[38;5;241m=\u001b[39m broadcast_dims \u001b[38;5;241m+\u001b[39m core_dims\n",
      "File \u001b[0;32m~/conda_envs/analysis-ilias/lib/python3.11/site-packages/xarray/core/variable.py:416\u001b[0m, in \u001b[0;36mVariable.data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, indexing\u001b[38;5;241m.\u001b[39mExplicitlyIndexed):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/conda_envs/analysis-ilias/lib/python3.11/site-packages/xarray/core/indexing.py:699\u001b[0m, in \u001b[0;36mMemoryCachedArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 699\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mget_duck_array()\n",
      "File \u001b[0;32m~/conda_envs/analysis-ilias/lib/python3.11/site-packages/xarray/core/indexing.py:693\u001b[0m, in \u001b[0;36mMemoryCachedArray._ensure_cached\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ensure_cached\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray \u001b[38;5;241m=\u001b[39m as_indexable(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/conda_envs/analysis-ilias/lib/python3.11/site-packages/xarray/core/indexing.py:667\u001b[0m, in \u001b[0;36mCopyOnWriteArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 667\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda_envs/analysis-ilias/lib/python3.11/site-packages/xarray/core/indexing.py:554\u001b[0m, in \u001b[0;36mLazilyIndexedArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 554\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;66;03m# self.array[self.key] is now a numpy array when\u001b[39;00m\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;66;03m# self.array is a BackendArray subclass\u001b[39;00m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;66;03m# and self.key is BasicIndexer((slice(None, None, None),))\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;66;03m# so we need the explicit check for ExplicitlyIndexed\u001b[39;00m\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(array, ExplicitlyIndexed):\n",
      "File \u001b[0;32m~/conda_envs/analysis-ilias/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:99\u001b[0m, in \u001b[0;36mNetCDF4ArrayWrapper.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplicit_indexing_adapter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexingSupport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOUTER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda_envs/analysis-ilias/lib/python3.11/site-packages/xarray/core/indexing.py:861\u001b[0m, in \u001b[0;36mexplicit_indexing_adapter\u001b[0;34m(key, shape, indexing_support, raw_indexing_method)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Support explicit indexing by delegating to a raw indexing method.\u001b[39;00m\n\u001b[1;32m    840\u001b[0m \n\u001b[1;32m    841\u001b[0m \u001b[38;5;124;03mOuter and/or vectorized indexers are supported by indexing a second time\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;124;03mIndexing result, in the form of a duck numpy-array.\u001b[39;00m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    860\u001b[0m raw_key, numpy_indices \u001b[38;5;241m=\u001b[39m decompose_indexer(key, shape, indexing_support)\n\u001b[0;32m--> 861\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mraw_indexing_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_key\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtuple\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_indices\u001b[38;5;241m.\u001b[39mtuple:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;66;03m# index the loaded np.ndarray\u001b[39;00m\n\u001b[1;32m    864\u001b[0m     result \u001b[38;5;241m=\u001b[39m NumpyIndexingAdapter(result)[numpy_indices]\n",
      "File \u001b[0;32m~/conda_envs/analysis-ilias/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:112\u001b[0m, in \u001b[0;36mNetCDF4ArrayWrapper._getitem\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatastore\u001b[38;5;241m.\u001b[39mlock:\n\u001b[1;32m    111\u001b[0m         original_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_array(needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 112\u001b[0m         array \u001b[38;5;241m=\u001b[39m getitem(original_array, key)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# Catch IndexError in netCDF4 and return a more informative\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# error message.  This is most often called when an unsorted\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# indexer is used before the data is loaded from disk.\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe indexing operation you are attempting to perform \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not valid on netCDF4.Variable object. Try loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data into memory first by calling .load().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dict_month = {'jan': '01',\n",
    "         'feb': '02',\n",
    "         'mar': '03',\n",
    "         'apr': '04',\n",
    "         'may': '05',\n",
    "         'jun': '06',\n",
    "         'jul': '07',\n",
    "         'aug': '08',\n",
    "         'sep': '09',\n",
    "         'oct': '10',\n",
    "         'nov': '11',\n",
    "         'dec': '12'}\n",
    "\n",
    "path = os.listdir('/results2/SalishSea/nowcast-green.202111/')\n",
    "\n",
    "# Open the mesh mask\n",
    "mesh = xr.open_dataset('/home/sallen/MEOPAR/grid/mesh_mask202108.nc')\n",
    "mask = mesh.tmask.to_numpy()\n",
    "\n",
    "folders = [x for x in path if ((x[2:5]=='mar' or x[2:5]=='apr' or (x[2:5]=='feb' and x[0:2] > '14')) and (x[5:7]<'24'))]\n",
    "indx_dates=(np.argsort(pd.to_datetime(folders, format=\"%d%b%y\")))\n",
    "folders = [folders[i] for i in indx_dates]\n",
    "\n",
    "drivers_all = np.array([[],[],[],[]])\n",
    "diat_all = np.array([])\n",
    "\n",
    "print ('Gathering days for the model')\n",
    "\n",
    "for i in tqdm(folders):\n",
    "\n",
    "    date, temp_i1, temp_i2, saline_i1, saline_i2, diat_i = datasets_preparation()\n",
    "\n",
    "    drivers = np.stack([np.ravel(temp_i1), np.ravel(temp_i2), np.ravel(saline_i1), np.ravel(saline_i2)])\n",
    "    indx = np.where(~np.isnan(drivers).any(axis=0))\n",
    "    drivers = drivers[:,indx[0]]\n",
    "    drivers_all = np.concatenate((drivers_all,drivers),axis=1)\n",
    "\n",
    "    diat = np.ravel(diat_i)\n",
    "    diat = diat[indx[0]]\n",
    "    diat_all = np.concatenate((diat_all,diat))\n",
    "\n",
    "print ('Done gathering, building the prediction model')\n",
    "print ('\\n')\n",
    "\n",
    "regr = regressor(drivers_all, diat_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Years (Anually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range (2007,2024)\n",
    "\n",
    "r_all = []\n",
    "rms_all = []\n",
    "slope_all = []\n",
    "\n",
    "for year in range (2007,2024):\n",
    "\n",
    "    year_str = str(year)[2:4]\n",
    "\n",
    "    folders = [x for x in path if ((x[2:5]=='mar' or x[2:5]=='apr' or (x[2:5]=='feb' and x[0:2] > '14')) and (x[5:7]==year_str))]\n",
    "    indx_dates=(np.argsort(pd.to_datetime(folders, format=\"%d%b%y\")))\n",
    "    folders = [folders[i] for i in indx_dates]\n",
    "\n",
    "    drivers_all = np.array([[],[],[],[]])\n",
    "    diat_all = np.array([])\n",
    "\n",
    "    print ('Gathering days for year ' + str(year))\n",
    "    for i in tqdm(folders):\n",
    "\n",
    "        date, temp_i1, temp_i2, saline_i1, saline_i2, diat_i = datasets_preparation()\n",
    "\n",
    "        drivers = np.stack([np.ravel(temp_i1), np.ravel(temp_i2), np.ravel(saline_i1), np.ravel(saline_i2)])\n",
    "        indx = np.where(~np.isnan(drivers).any(axis=0))\n",
    "        drivers = drivers[:,indx[0]]\n",
    "        drivers_all = np.concatenate((drivers_all,drivers),axis=1)\n",
    "\n",
    "        diat = np.ravel(diat_i)\n",
    "        diat = diat[indx[0]]\n",
    "        diat_all = np.concatenate((diat_all,diat))\n",
    "\n",
    "    r, rms, m = regressor2(drivers_all, diat_all, 'Diatom ' + str(year))\n",
    "    \n",
    "    r_all.append(r)\n",
    "    rms_all.append(rms)\n",
    "    slope_all.append(m)\n",
    "    \n",
    "plotting(np.transpose(r_all), 'Correlation Coefficient')\n",
    "plotting(np.transpose(rms_all), 'Mean Square Error')\n",
    "plotting (np.transpose(slope_all), 'Slope of the best fitting line')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Years (Daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = np.array([])\n",
    "r_all2 = np.array([])\n",
    "rms_all2 = np.array([])\n",
    "slope_all2 = np.array([])\n",
    "\n",
    "folders = [x for x in path if ((x[2:5]=='mar' or x[2:5]=='apr' or (x[2:5]=='feb' and x[0:2] > '14')) and (x[5:7]<'24'))]\n",
    "indx_dates=(np.argsort(pd.to_datetime(folders, format=\"%d%b%y\")))\n",
    "folders = [folders[i] for i in indx_dates]\n",
    "\n",
    "for i in tqdm(folders, colour = 'green'):\n",
    "    \n",
    "    date, temp_i1, temp_i2, saline_i1, saline_i2, diat_i, = datasets_preparation()\n",
    "\n",
    "    drivers = np.stack([np.ravel(temp_i1), np.ravel(temp_i2), np.ravel(saline_i1), np.ravel(saline_i2)])\n",
    "    indx = np.where(~np.isnan(drivers).any(axis=0))\n",
    "    drivers = drivers[:,indx[0]]\n",
    "\n",
    "    diat = np.ravel(diat_i)\n",
    "    diat = diat[indx[0]]\n",
    "\n",
    "    r, rms, m = regressor4(drivers, diat, 'Diatom')\n",
    "\n",
    "    dates = np.append(dates,date.date) \n",
    "    r_all2 = np.append(r_all2,r)\n",
    "    rms_all2 = np.append(rms_all2,rms)\n",
    "    slope_all2 = np.append(slope_all2,m)\n",
    "\n",
    "plotting2(r_all2, 'Correlation Coefficients')\n",
    "plotting2(rms_all2, 'Mean Square Errors')\n",
    "plotting2(slope_all2, 'Slope of the best fitting line')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = random.sample(folders,10)\n",
    "\n",
    "for i in tqdm(maps):\n",
    "\n",
    "    date, temp_i1, temp_i2, saline_i1, saline_i2, diat_i, = datasets_preparation()\n",
    "\n",
    "    drivers = np.stack([np.ravel(temp_i1), np.ravel(temp_i2), np.ravel(saline_i1), np.ravel(saline_i2)])\n",
    "    indx = np.where(~np.isnan(drivers).any(axis=0))\n",
    "    drivers = drivers[:,indx[0]]\n",
    "\n",
    "    diat = np.ravel(diat_i)\n",
    "    diat = diat[indx[0]]\n",
    "\n",
    "    regressor3(drivers, diat, 'Diatom')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis-ilias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
